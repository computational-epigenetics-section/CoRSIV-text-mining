{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Wen-Jou Chang\n",
    "Baylor College of Medicine\n",
    "\n",
    "This script is used to generate the main figures in the paper.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Initialization\n",
    "\"\"\"\n",
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from collections import defaultdict\n",
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import importlib, util\n",
    "\n",
    "PROJECT_PATH = \"YOUR_PATH\"\n",
    "FIGURE_PATH = \"YOUR_PATH\"\n",
    "os.chdir(PROJECT_PATH)\n",
    "importlib.reload(util)\n",
    "from util import CATEGORY_NAMES, COLOR_TEMPLATE, CORSIV_PROBE_LIST, CONTROLS, read_in_probes, calculate_points, plot_enrichment, breakdown, export_paper\n",
    "\n",
    "\n",
    "epic = pd.read_csv(\"../humanData/database/EPIC.hg38.txt\", sep=\"\\t\", header=None)\n",
    "epic_probe_list = set(epic.iloc[:,3])\n",
    "hm450 = pd.read_csv(\"../humanData/database/HM450.hg38.txt\", sep=\"\\t\", header=None)\n",
    "hm450_probe_list = set(hm450.iloc[:,3])\n",
    "illumina = epic_probe_list.union(hm450_probe_list)\n",
    "\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.linewidth'] = 2  # Thicker outer box\n",
    "plt.rcParams['xtick.major.width'] = 2  # Thicker x-axis ticks\n",
    "plt.rcParams['ytick.major.width'] = 2  # Thicker y-axis ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 1A: mesh hierarchy tree\n",
    "\n",
    "# Initialize mesh tree\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "\n",
    "def visualize(input_nodes, output_name=None):\n",
    "    input_nodes = {y:mesh_ctot[y] for y in input_nodes}\n",
    "    print(input_nodes)\n",
    "    dot = Digraph()\n",
    "    dot.attr(rankdir='LR')  # Keep layout horizontal (Left-to-Right)\n",
    "\n",
    "    edges = set()\n",
    "    nodes = {}\n",
    "    \n",
    "    for code in input_nodes:\n",
    "        if code.startswith(\"C23\"):\n",
    "            continue\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts) + 1):\n",
    "            partial_code = '.'.join(parts[:i])\n",
    "            if partial_code not in nodes and partial_code in mesh_ctot:\n",
    "                nodes[partial_code] = mesh_ctot[partial_code]\n",
    "\n",
    "    def add_code_edges(code):\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts)):\n",
    "            parent_code = '.'.join(parts[:i])\n",
    "            child_code = '.'.join(parts[:i+1])\n",
    "            edges.add((parent_code, child_code))\n",
    "            \n",
    "    def get_node_color(node):\n",
    "        for category, color in category_color_map.items():\n",
    "            if category == nodes[node]:\n",
    "                return color\n",
    "        return \"#000000\"  # Default color for nodes not in any category\n",
    "    \n",
    "    for code, term in nodes.items():\n",
    "        add_code_edges(code)\n",
    "\n",
    "    for n in nodes:\n",
    "        if \".\" not in n:\n",
    "            edges.add((n[0].capitalize(), n))\n",
    "    nodes[\"C\"] = \"Diseases\"\n",
    "    nodes[\"F\"] = \"Psychiatry and Psychology\"\n",
    "            \n",
    "    # Add nodes for each unique code with term name as label\n",
    "    for code, term in sorted(nodes.items(), key=lambda x :graph_order[x[1]]):\n",
    "        print(code, term)\n",
    "        node_color = get_node_color(code)\n",
    "        if node_color == \"#000000\":\n",
    "            dot.node(code, label=term, shape='box', fontname='Helvetica', align='right', penwidth='1.5')\n",
    "        else:\n",
    "            dot.node(code, label=term, shape='box', style='filled', fillcolor=node_color, fontname='Helvetica', fontcolor='white', rank='same', penwidth='1.5')\n",
    "\n",
    "    # Add edges for hierarchical relationships\n",
    "    for parent_code, child_code in edges:\n",
    "        dot.edge(parent_code, child_code, penwidth='1.5')\n",
    "        \n",
    "\n",
    "    dot.attr(splines='ortho')\n",
    "    dot.attr(nodesep='0.2', ranksep='0.5')\n",
    "    if output_name:\n",
    "        dot.render(output_name, format='svg')\n",
    "    else:\n",
    "        dot.view()\n",
    "\n",
    "categories = [[\"Neoplasms\"], [\"Cardiovascular Diseases\"], [\"Digestive System Diseases\"], [\"Endocrine System Diseases\"], [\"Hemic and Lymphatic Diseases\"], [\"Immune System Diseases\"], [\"Metabolic Diseases\"], [\"Mental Disorders\", \"Nervous System Diseases\"], [\"Obesity\"], [\"Respiratory Tract Diseases\"], [\"Urogenital Diseases\"]]\n",
    "graph_order = defaultdict(str)\n",
    "for i, c in enumerate(categories):\n",
    "    for cc in c:\n",
    "        graph_order[cc] = CATEGORY_NAMES[i]\n",
    "graph_order[\"Mental Disorders\"] = \"1\"\n",
    "graph_order[\"Psychiatry and Psychology\"] = \"2\"\n",
    "graph_order[\"Metabolic Diseases\"] = \"3\"\n",
    "graph_order[\"Nutrition Disorders\"] = \"4\"\n",
    "category_color_map = {}\n",
    "for category_list, color in zip(categories, COLOR_TEMPLATE):\n",
    "    for category in category_list:\n",
    "        category_color_map[category] = color\n",
    "nodes = set([y for clist in categories for c in clist for y in mesh_ttoc[c]])\n",
    "output_name = f\"{FIGURE_PATH}/Fig1/mesh_tree_hierarchy\"\n",
    "# Modify the visualize function call to adjust edge routing\n",
    "visualize(nodes, output_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 1C: number of studies per category\n",
    "\n",
    "articles = set()\n",
    "ilumina_studies = []\n",
    "\n",
    "for cat in CATEGORY_NAMES:\n",
    "    kw = \"metabolic_diseases\" if cat == \"metabolic\" else cat\n",
    "    probes = pd.read_csv(f\"probe/{kw}_all_probes.csv\")\n",
    "    papers = pd.read_csv(f\"pubmed_search/{kw}.csv\")\n",
    "    papers = papers[papers[\"PMCID\"].isin(probes[\"pmcid\"])]\n",
    "    qc = len(set(probes[\"pmcid\"]))\n",
    "    ilumina_studies.append(papers.shape[0])\n",
    "    articles |= set(papers[\"PMCID\"])\n",
    "print(len(articles))\n",
    "plt.figure()\n",
    "bars = plt.barh([c.capitalize() for c in CATEGORY_NAMES], ilumina_studies, color=COLOR_TEMPLATE)\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_width()+10, bar.get_y() + bar.get_height() / 2, f'{bar.get_width():,}', \n",
    "            va='center', ha='left', fontsize=14)\n",
    "plt.xlabel('Number of Papers Included')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.xlim(0, max(ilumina_studies) * 1.2)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(f\"{FIGURE_PATH}/Fig1/illumina_studies_num.svg\", format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 2A: cancer decay plot illustration\n",
    "\n",
    "c = read_in_probes(\"cancer\")\n",
    "\n",
    "paper_threshold_count = []\n",
    "i = 1\n",
    "max_probe_count = max(c.values())\n",
    "while i <= max_probe_count:\n",
    "    dummy_dict = {key:count for key, count in c.items() if count == i}\n",
    "    paper_threshold_count.append((i, len(dummy_dict)))\n",
    "    i += 1\n",
    "\n",
    "probe_cutoff = max_probe_count\n",
    "for i in range(paper_threshold_count[-1][0], 0, -1):\n",
    "    if paper_threshold_count[i-1][1] < 10:\n",
    "        continue\n",
    "    probe_cutoff = i\n",
    "    break\n",
    "paper_threshold_count = paper_threshold_count[:probe_cutoff]\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "     \n",
    "x_values, y_values = zip(*paper_threshold_count)\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-', color=COLOR_TEMPLATE[0])\n",
    "\n",
    "plt.title(\"Cancer\", fontsize=20)\n",
    "plt.ylabel('Number of Probes', fontsize=16)\n",
    "plt.xlabel('Number of Papers Reporting Probe', fontsize=16)\n",
    "# plt.yscale('log', subs=[])\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(10, 100000)\n",
    "plt.xticks(range(2, 11, 2), fontsize=16)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig(f\"{FIGURE_PATH}/Fig2/cancer_decay.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 2B: cancer disgenet results\n",
    "def get_color(actual_category, category_list):\n",
    "    colors = []\n",
    "    if not isinstance(category_list, str):\n",
    "        return '#D3D3D3'\n",
    "    ind = [i.lower().strip() for i in category_list.split(\",\")]\n",
    "    for i in ind:\n",
    "        if i == actual_category:\n",
    "            return f\"{COLOR_TEMPLATE[CATEGORY_NAMES.index(i)]}50\"\n",
    "        if i in CATEGORY_NAMES:\n",
    "            colors.append(f\"{COLOR_TEMPLATE[CATEGORY_NAMES.index(i)]}50\")\n",
    "    return colors[0] if colors else '#D3D3D3'\n",
    "    \n",
    "ref = pd.read_csv(\"disgenet_terms_annotated.csv\", names=[\"Name\", \"Category\"], skiprows=1)\n",
    "category = \"cancer\"\n",
    "size = 4\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(size*2, 4))\n",
    "axes = [ax1, ax2]\n",
    "for k in range(1, 3):\n",
    "    df = pd.read_csv(f\"go_probe/go_results/manifest/{category}_all_{k}papers_unique.csv\")\n",
    "    df = df[df[\"Database\"] == \"DisGeNET\"]\n",
    "    df = df.merge(ref, on=\"Name\", how=\"left\")\n",
    "    df[\"Name\"] = df[\"Name\"].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x))\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df = df.sort_values([\"Adjusted p-value\", \"P-value\"], ascending=[True, True])\n",
    "    combined_top = df.head(10)\n",
    "    log_p = -np.log10(combined_top['Adjusted p-value'])\n",
    "    category_colors = combined_top['Category'].apply(lambda x: get_color(category, x))\n",
    "    \n",
    "    bars = axes[k-1].barh(range(len(combined_top)), log_p, height=0.8, \n",
    "                color=category_colors)\n",
    "    if k == 1:\n",
    "        threshold = -np.log10(0.05)\n",
    "        axes[k-1].axvline(x=threshold, color='black', linestyle='--', alpha=1)\n",
    "        for i, (_, row) in enumerate(combined_top.iterrows()):\n",
    "            axes[k-1].text(log_p[i]+0.5, i, f\"{row['Name']}\", ha='left', va='center', fontsize=12, color='black')\n",
    "    else:   \n",
    "        for i, (_, row) in enumerate(combined_top.iterrows()):\n",
    "            axes[k-1].text(1, i, f\"{row['Name']}\", ha='left', va='center', fontsize=12, color='black')\n",
    "    df2 = pd.read_csv(f\"heatmap/probe_based_heatmap_{k}papers.csv\", index_col=0)\n",
    "    unique_probes = len(set(df2[(df2[category] != 0) & (df2.drop(columns=[category]) == 0).all(axis=1)].index))\n",
    "\n",
    "    axes[k-1].set_title(f\"{unique_probes:,} Probes in ≥ {k} {category.capitalize()} Paper{'s' if k > 1 else ''}\", fontsize=16)\n",
    "    axes[k-1].set_xlabel('-log₁₀(Adjusted P-value)', fontsize=16)\n",
    "    \n",
    "    axes[k-1].set_ylabel('')\n",
    "    axes[k-1].set_yticks([])\n",
    "    axes[k-1].set_yticklabels([])\n",
    "    axes[k-1].invert_yaxis()\n",
    "    axes[k-1].set_yticks([])\n",
    "    axes[k-1].tick_params(axis='x', which='both', labelsize=16)\n",
    "    axes[k-1].set_xlim(0, 11)\n",
    "    axes[k-1].set_xticks(range(0, 30, 5))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIGURE_PATH}/Fig2/{category}_disgenet.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2C: probe based heatmap\n",
    "\n",
    "# Increase the recursion limit\n",
    "sys.setrecursionlimit(40000)\n",
    "paper_threshold = 2\n",
    "df = pd.read_csv(f\"probe_based_heatmap_{paper_threshold}papers_0107.csv\", index_col=0)\n",
    "\n",
    "# # Randomly select 100 rows\n",
    "# df = df.sample(n=2000, random_state=42)\n",
    "\n",
    "# Create a custom colormap\n",
    "colors = [(1, 1, 1),\n",
    "          (0, 0, 1)]\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_blue\", colors, N=100)\n",
    "g = sns.clustermap(df, method='ward', metric='euclidean', cmap=cmap, figsize=(8, 6), annot=False, vmax=10)\n",
    "\n",
    "# Remove existing colorbar\n",
    "g.ax_heatmap.collections[0].colorbar.remove()\n",
    "\n",
    "# Create new colorbar in upper right\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "ax_ins = inset_axes(g.ax_heatmap, width=\"8%\", height=\"40%\", loc='upper right', \n",
    "                    bbox_to_anchor=(0.15, 0.3, 1, 1), bbox_transform=g.ax_heatmap.transAxes)\n",
    "cbar = plt.colorbar(g.ax_heatmap.collections[0], cax=ax_ins, orientation='vertical')\n",
    "cbar.set_ticks([0, 5, 10])\n",
    "cbar.set_ticklabels(['0', '5', '≥10'])\n",
    "cbar.set_label(\"Number of\\nPapers\", rotation=90, fontsize=16, labelpad=10)\n",
    "\n",
    "g.ax_row_dendrogram.set_visible(False)\n",
    "for line in g.ax_col_dendrogram.collections:\n",
    "    line.set_linewidth(2)\n",
    "\n",
    "g.ax_heatmap.set_yticks([])\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=90, ha='center', va='top', fontsize=20)\n",
    "g.ax_heatmap.tick_params(axis='x', which='major', pad=10)\n",
    "g.figure.suptitle(f\"{len(df):,} Probes\\nReported in ≥ {paper_threshold} Papers\", y=0.8, fontsize=20, rotation=90, x=0.1)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f\"{FIGURE_PATH}/Fig2/heatmap.jpeg\", format=\"jpeg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.read_csv(\"go_probe/go_results/nonunique/disgenet_terms_annotated_2.csv\", names=[\"Name\", \"Category\"])\n",
    "ref[ref[\"Name\"] == \"Blood basophil count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_threshold = 2\n",
    "df2 = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "unique_probes = len(set(df2[(df2[\"cancer\"] != 0) & (df2.drop(columns=[\"cancer\"]) == 0).all(axis=1)].index))\n",
    "print(unique_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2D-F: disgenet results for neurological, immune, and cardiovascular\n",
    "\n",
    "ref = pd.read_csv(\"go_probe/go_results/manifest/disgenet_terms_annotated_2.csv\", names=[\"Name\", \"Category\"])\n",
    "# specific_categories = [\"cancer\", \"neurological\", \"immune\"]\n",
    "paper_threshold = 2\n",
    "for category in CATEGORY_NAMES:\n",
    "    df = pd.read_csv(f\"go_probe/go_results/manifest/{category}_all_{paper_threshold}papers_unique.csv\")\n",
    "    df = df[df[\"Database\"] == \"DisGeNET\"]\n",
    "    df[\"Name\"] = df[\"Name\"].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x).strip())\n",
    "    df = df.merge(ref, on=\"Name\", how=\"left\")\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df = df.sort_values([\"Adjusted p-value\", \"P-value\"], ascending=[True, True])\n",
    "    combined_top = df.head(10)\n",
    "    log_p = -np.log10(combined_top['Adjusted p-value'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4)) if category != \"metabolic\" else plt.subplots(figsize=(6, 2.5))\n",
    "    category_colors = combined_top['Category'].apply(lambda x: get_color(category, x))\n",
    "    \n",
    "    bars = ax.barh(range(len(combined_top)), log_p, height=0.8, \n",
    "                color=category_colors)\n",
    "\n",
    "    # # Add labels to the bars\n",
    "    for i, (_, row) in enumerate(combined_top.iterrows()):\n",
    "        x_pos = 0.05 * max(log_p)  # Calculate position based on max x-axis value\n",
    "        ax.text(x_pos, i, f\"{row['Name']}\", ha='left', va='center', fontsize=12)\n",
    "    df2 = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "    unique_probes = len(set(df2[(df2[category] != 0) & (df2.drop(columns=[category]) == 0).all(axis=1)].index))\n",
    "    # Customize the plot\n",
    "    ax.set_title(f\"{unique_probes:,} Probes in ≥ {paper_threshold} {category.capitalize()} Paper{'s' if paper_threshold>1 else ''}\", y=1.03, fontsize=20)\n",
    "    ax.set_xlabel('-log₁₀(Adjusted P-value)', fontsize=20)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.invert_yaxis()  # Invert y-axis to show highest significance at the top\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(axis='x', which='both', labelsize=20)\n",
    "    plt.tight_layout()\n",
    "    if category in [\"immune\", \"neurological\", \"cardiovascular\"]:\n",
    "        plt.savefig(f\"{FIGURE_PATH}/Fig2/{category}_{paper_threshold}papers_disgenet.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2G: gene region histograms\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "df = pd.read_csv(\"../humanData/corsiv_manifest.csv\")\n",
    "\n",
    "def parse_gene_group(row):\n",
    "    if row[\"UCSC_RefGene_Group\"] == \"Intergenic\":\n",
    "        return pd.Series([set([(\"_\", \"Intergenic\")]), set([(\"Intergenic\")])])\n",
    "    names = row[\"UCSC_RefGene_Name\"].split(\";\")\n",
    "    groups = row[\"UCSC_RefGene_Group\"].split(\";\")\n",
    "    gene_groups = set(zip(names, groups))\n",
    "    group_set = set(groups)\n",
    "    return pd.Series([gene_groups, group_set])\n",
    "\n",
    "def cleanup(row):\n",
    "    if len(row) > 1:\n",
    "        row.discard(\"Intergenic\")\n",
    "    return row\n",
    "\n",
    "df[[\"gene_groups\", \"groups\"]] = df.apply(parse_gene_group, axis=1)\n",
    "df = df[[\"corsiv_id\", \"Probe_ID\", \"gene_groups\", \"groups\"]]\n",
    "all_corsiv_df = df.groupby('corsiv_id')['groups'].apply(lambda x: set().union(*x)).reset_index()\n",
    "all_corsiv_df[\"groups\"] = all_corsiv_df[\"groups\"].apply(cleanup)\n",
    "illumina_covered_corsiv = all_corsiv_df.shape[0]\n",
    "all_corsiv_tally = {}\n",
    "for row in all_corsiv_df['groups']:\n",
    "    for group in row:\n",
    "        all_corsiv_tally[group] = all_corsiv_tally.get(group, 0) + 1\n",
    "if \"ExonBnd\" in all_corsiv_tally:\n",
    "    del all_corsiv_tally[\"ExonBnd\"]\n",
    "\n",
    "def tally_count(category, paper_threshold=2):\n",
    "    c = read_in_probes(category)\n",
    "    c = {k:v for k, v in c.items() if v >= paper_threshold}\n",
    "    cat_df = df[df[\"Probe_ID\"].isin(c)]\n",
    "    cat_df = cat_df.groupby('corsiv_id')['groups'].apply(lambda x: set().union(*x)).reset_index()\n",
    "    cat_df[\"groups\"] = cat_df[\"groups\"].apply(cleanup)\n",
    "    target_corsiv_tally = {}\n",
    "    for row in cat_df['groups']:\n",
    "        for group in row:\n",
    "            target_corsiv_tally[group] = target_corsiv_tally.get(group, 0) + 1\n",
    "    if \"ExonBnd\" in target_corsiv_tally:\n",
    "        del target_corsiv_tally[\"ExonBnd\"]\n",
    "    return target_corsiv_tally, cat_df.shape[0]\n",
    "\n",
    "def plot_gene_hist_all_categories(all_corsiv_tally, category_names, output_path=None, show_figure=True, format=\"pdf\", colors=COLOR_TEMPLATE):\n",
    "    keys = ['Intergenic', 'TSS1500', 'TSS200', \"5'UTR\", '1stExon', 'Body', \"3'UTR\"]\n",
    "    all_total = sum(all_corsiv_tally.values())\n",
    "    a_pct = [all_corsiv_tally[key] / all_total * 100 for key in keys]\n",
    "    tss_all = []\n",
    "    intergenic_all = []\n",
    "    tss_categories = []\n",
    "    intergenic_categories = []\n",
    "    category_data = []\n",
    "    for _, name in enumerate(CATEGORY_NAMES):\n",
    "        d, count = tally_count(name)\n",
    "        s_total = sum(d.values())\n",
    "        s_pct = [d.get(key, 0) / s_total * 100 for key in keys]\n",
    "        category_data.append((name, s_pct, count))\n",
    "        tss_categories.append(d.get(\"TSS200\", 0))\n",
    "        intergenic_categories.append(d.get(\"Intergenic\", 0))\n",
    "        tss_all.append(all_corsiv_tally.get(\"TSS200\", 0) * count / 1607)\n",
    "        intergenic_all.append(all_corsiv_tally.get(\"Intergenic\", 0) * count / 1607)\n",
    "    plt.figure(figsize=(15.5, 5))\n",
    "    bar_width = 0.07\n",
    "    index = np.arange(len(keys))\n",
    "    tss_categories = np.array(tss_categories)\n",
    "    intergenic_categories = np.array(intergenic_categories)\n",
    "    tss_all = np.array(tss_all)\n",
    "    intergenic_all = np.array(intergenic_all)\n",
    "    for i, (name, s_pct, count) in enumerate(category_data):\n",
    "        plt.bar(index+i*bar_width, s_pct, bar_width, color=colors[i], label=f'{name.capitalize()} CoRSIVs ({count})', align='edge')\n",
    "\n",
    "    for j, pct in enumerate(a_pct):\n",
    "        plt.plot([index[j], index[j] + len(category_names) * bar_width], \n",
    "                    [pct, pct], color='black', linestyle='dashed', linewidth=2, alpha=0.8, label=\"All CoRSIVs (1607)\" if j == 0 else \"\")\n",
    "    \n",
    "    chi2_stat = np.sum((tss_categories - tss_all)**2 / tss_all)\n",
    "    p_value = 1 - chi2.cdf(chi2_stat, df=len(CATEGORY_NAMES)-1)\n",
    "    print(f\"TSS200: {chi2_stat:.2f}, {p_value}\")\n",
    "    chi2_stat = np.sum((intergenic_categories - intergenic_all)**2 / intergenic_all)\n",
    "    p_value = 1 - chi2.cdf(chi2_stat, df=len(CATEGORY_NAMES)-1)\n",
    "    print(f\"Intergenic: {chi2_stat:.2f}, {p_value}\")\n",
    "    plt.xlabel('Gene Region', fontsize=26)\n",
    "    plt.ylabel('Percentage (%)', fontsize=26)\n",
    "    plt.xticks(index + bar_width * (len(category_names) / 2), keys, ha='center', fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "\n",
    "    # plt.legend(frameon=False, loc='upper left', fontsize=10, bbox_to_anchor=(0, 1), ncol=2)\n",
    "    plt.tight_layout()\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, format=format, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return\n",
    "    \n",
    "plot_categories = [\"cancer\", \"cardiovascular\", \"endocrine\", \"immune\", \"metabolic\", \"neurological\"]\n",
    "plot_colors = ['#e6194B','#f58231','#469990','#2f8e3b','#0db7dd','#4363d8']#, \"#000075\"]#'#8298e5'\n",
    "output_path = f\"{FIGURE_PATH}/Fig2/all_categories_histogram.svg\"\n",
    "\n",
    "# # Adjust plot style for thicker outer box and ticks\n",
    "with plt.rc_context({'axes.linewidth': 3, 'xtick.major.width': 3, 'ytick.major.width': 3}):\n",
    "    plot_gene_hist_all_categories(all_corsiv_tally, CATEGORY_NAMES, output_path, show_figure=True, format=\"svg\", colors=COLOR_TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3A-F: decay plots for each category\n",
    "\n",
    "cat_probes_dict = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    cat_probes_dict.append(read_in_probes(cat))\n",
    "    \n",
    "la = (0.15, 0.9)\n",
    "ra = (0.85, 0.9)\n",
    "box_placement = [la if i not in [1, 8, 9] else ra for i in range(11)]\n",
    "\n",
    "for i in [0, 3, 5, 6, 7, 10]:\n",
    "    output_path = f\"{FIGURE_PATH}/Fig3/{CATEGORY_NAMES[i]}.svg\"\n",
    "    l1, l2, l3, p, p2,_ = calculate_points(cat_probes_dict[i], CATEGORY_NAMES[i])\n",
    "    show_y_label = i in [0, 6]\n",
    "    show_legend = i == 0\n",
    "    paper, r = plot_enrichment([l1, l2, l3, p, p2], CATEGORY_NAMES[i], i, output=output_path if i==0 else None, show_figure=True, box_placement=box_placement[i], show_y_label=show_y_label, format=\"svg\", show_legend=show_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3A-F: decay plots for each category\n",
    "\n",
    "cat_probes_dict = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    cat_probes_dict.append(read_in_probes(cat))\n",
    "probes_ct = []\n",
    "ratios = []\n",
    "papers_ct = []\n",
    "\n",
    "for i in range(len(CATEGORY_NAMES)):\n",
    "    output_path = f\"{FIGURE_PATH}/Fig3/{CATEGORY_NAMES[i]}.svg\"\n",
    "    l1, l2, l3, p, p2, _ = calculate_points(cat_probes_dict[i], CATEGORY_NAMES[i])\n",
    "    paper, r = plot_enrichment([l1, l2, l3, p, p2], CATEGORY_NAMES[i], i, output=None, show_figure=True)\n",
    "    probes_ct.append(p)\n",
    "    ratios.append(r)\n",
    "    papers_ct.append(p2)\n",
    "\n",
    "df = pd.DataFrame({\"Categories\":CATEGORY_NAMES, \"Enrichment Ratio\":ratios, \"Probes\":probes_ct, \"Papers\":papers_ct})\n",
    "df\n",
    "# df.to_csv(f\"{FIGURE_PATH}/Fig3/category_enrichment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3G: cancer permuataion results histogram\n",
    "CLOSE_TO_ZERO = 0\n",
    "adjusted_threshold = 0.05 / 11\n",
    "pvals = [3.08e-38, 0.04, 0.3, CLOSE_TO_ZERO, 0.44, 5.73e-94, 3.23e-45, CLOSE_TO_ZERO, 1.4e-09, 0.05, 1.42e-64]\n",
    "enrcihment_ratios = [10.90, 4.69, 0.67, 53.48, 1.61, 10.08, 23.70, 25.66, 5.72, 2.24, 6.93]\n",
    "ylims = [(0, 15), (0, 23), (0, 25), (0, 68), (0, 19), (0, 13), (0, 31), (0, 33), (0, 14), (0,10), (0, 10)]\n",
    "yticks_list = [(0, 16, 5), (0, 24, 10), (0, 24, 10), (0, 61, 20), (0, 16, 5), (0, 14, 5), (0, 31, 10), (0, 31, 10), (0, 11, 5), (0, 10, 4), (0, 10, 4)]\n",
    "PT_DIR = \"../permutation_testing\"\n",
    "for i in range(11):\n",
    "    df = pd.read_csv(f\"{PT_DIR}/concatenated_results/{CATEGORY_NAMES[i]}_enrichment_after_permutations.bed\", sep=\"\\t\")[:]\n",
    "    df = df.sort_values(by=\"enrichment_ratio\", ascending=False)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    with plt.rc_context({'font.size': 30, 'axes.linewidth': 4, 'xtick.major.width': 4, 'ytick.major.width': 4, 'xtick.major.size': 10, 'ytick.major.size': 10}):\n",
    "        p_0_ratio = enrcihment_ratios[i]\n",
    "        plt.figure(figsize=(35, 6))\n",
    "        plt.bar(range(100000), df[\"enrichment_ratio\"], width=7, color=COLOR_TEMPLATE[i])\n",
    "        plt.xlim(-1000, 100000)\n",
    "        plt.xticks(range(0, 100001, 10000))\n",
    "        ylim_cap = max(df[\"enrichment_ratio\"].max(), p_0_ratio)\n",
    "        # offset = 5 if ylim_cap < 15 else 15\n",
    "        plt.ylim(ylims[i][0], ylims[i][1])\n",
    "        plt.yticks(range(*yticks_list[i]))\n",
    "        plt.axhline(y=p_0_ratio, color='black', linestyle='--', linewidth=4)\n",
    "        plt.text(3000, p_0_ratio+0.5, 'Actual enrichment ratio', verticalalignment='bottom', horizontalalignment='left', fontsize=35)\n",
    "        pval = pvals[i]\n",
    "        if pval == CLOSE_TO_ZERO:\n",
    "            annotated_text = \"P < 2.2e-308\" \n",
    "        elif pval >= adjusted_threshold:\n",
    "            annotated_text = \"Not Significant\"\n",
    "        else:\n",
    "            annotated_text = f'P = {pval:.1e}'\n",
    "        plt.annotate(annotated_text, \n",
    "                    xy=(0.97, 0.9), \n",
    "                    xycoords='axes fraction',\n",
    "                    horizontalalignment='right',\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"none\", ec=\"none\", lw=0))\n",
    "\n",
    "        plt.xlabel('Shuffled Set', fontsize=35)\n",
    "        plt.ylabel('Enrichment Ratio', fontsize=35)\n",
    "        plt.title(f'Enrichment ratios from 100k Permutations - {CATEGORY_NAMES[i].capitalize()}', fontsize=40)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()\n",
    "        plt.savefig(f\"{FIGURE_PATH}/Fig3/{CATEGORY_NAMES[i]}_100k_permutations.jpeg\", format=\"jpeg\", bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4B-D: neurological subcategory decay plots\n",
    "\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "neuro_mesh_tree = {}\n",
    "keywords = [\"Mental Disorders\", \"Nervous System Diseases\"]\n",
    "for kw in keywords:\n",
    "    neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "target_idx = 7\n",
    "neuro_df = pd.read_csv(f\"probe/neurological_all_probes.csv\")  \n",
    "neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "\n",
    "temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i in range(len(mesh_terms)):\n",
    "    m = mesh_terms[i]\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key) and count >= 14}\n",
    "mesh_count_by_study[\"Neurological\"] = len(set(neuro_df[\"pmcid\"]))\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "\n",
    "enriched_categories = []\n",
    "not_enriched_categories = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "probes = []\n",
    "papers_ct = []\n",
    "terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "for term in terms:\n",
    "    term = keywords if term == \"Neurological\" else [term]\n",
    "    show_y_label = term == [\"Neurodevelopmental Disorders\"]\n",
    "    show_legend = term == [\"Neurodevelopmental Disorders\"]\n",
    "    output_path = f\"{FIGURE_PATH}/Fig4/{term}.svg\"\n",
    "    p, paper, r, p2 = breakdown(neuro_df, term_pmcid_map, term, target_idx, show_figure=False, show_y_label=show_y_label, show_legend=show_legend)\n",
    "    probes.append(p)\n",
    "    d1.append(paper)\n",
    "    d2.append(r)\n",
    "    papers_ct.append(p2)\n",
    "    # break\n",
    "\n",
    "print(len(terms), len(d1), len(d2), len(probes), len(counts))\n",
    "df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"CoRSIV Probes\": probes, \"CoRSIV Papers\":papers_ct, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts})\n",
    "df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "df.index = df[\"Categories\"]\n",
    "df.drop(columns=[\"Categories\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4B-D: neurological subcategory decay plots\n",
    "\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "neuro_mesh_tree = {}\n",
    "keywords = [\"Metabolic Diseases\"]\n",
    "for kw in keywords:\n",
    "    neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "target_idx = 6\n",
    "neuro_df = pd.read_csv(f\"probe/metabolic_diseases_all_probes.csv\")  \n",
    "neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "\n",
    "temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i in range(len(mesh_terms)):\n",
    "    m = mesh_terms[i]\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "\n",
    "enriched_categories = []\n",
    "not_enriched_categories = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "probes = []\n",
    "terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "for term in terms:\n",
    "    output_path = f\"{FIGURE_PATH}/final/cancer/{term}.svg\"\n",
    "    p, paper, r = breakdown(neuro_df, term_pmcid_map, [term], target_idx, show_figure=True, show_y_label=True, show_legend=False, output=None)\n",
    "    probes.append(p)\n",
    "    d1.append(paper)\n",
    "    d2.append(r)\n",
    "    # break\n",
    "\n",
    "print(len(terms), len(d1), len(d2), len(probes), len(counts))\n",
    "df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"Number of Probes\": probes, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts})\n",
    "df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "df.index = df[\"Categories\"]\n",
    "df.drop(columns=[\"Categories\"], inplace=True)\n",
    "print(df.to_string())\n",
    "print(df[df[\"Enrichment Ratio\"]<= 1].to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4B-D: neurological subcategory decay plots\n",
    "\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "neuro_mesh_tree = {}\n",
    "keywords = [\"Neoplasms\"]\n",
    "for kw in keywords:\n",
    "    neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "target_idx = 0\n",
    "neuro_df = pd.read_csv(f\"probe/cancer_all_probes.csv\")  \n",
    "neuro_df = neuro_df[neuro_df['pmcid']!=\"PMC10275808\"]\n",
    "neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "\n",
    "temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i in range(len(mesh_terms)):\n",
    "    m = mesh_terms[i]\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "# mesh_count_by_study[\"Cancer\"] = len(set(neuro_df[\"pmcid\"]))\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "\n",
    "enriched_categories = []\n",
    "not_enriched_categories = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "probes = []\n",
    "terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "for term in terms:\n",
    "    if term != \"Prostatic Neoplasms\":\n",
    "        continue\n",
    "    output_path = f\"{FIGURE_PATH}/final/cancer/{term}_drop.svg\"\n",
    "    p, paper, r = breakdown(neuro_df, term_pmcid_map, [term], target_idx, show_figure=False, show_y_label=False, show_legend=False, output=None)\n",
    "    probes.append(p)\n",
    "    d1.append(paper)\n",
    "    d2.append(r)\n",
    "    # break\n",
    "\n",
    "print(len(terms), len(d1), len(d2), len(probes), len(counts))\n",
    "df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"Number of Probes\": probes, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts})\n",
    "df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "df.index = df[\"Categories\"]\n",
    "df.drop(columns=[\"Categories\"], inplace=True)\n",
    "print(df.to_string())\n",
    "print(df[df[\"Enrichment Ratio\"]<= 1].to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4A: neurological mesh hierarchy\n",
    "from graphviz import Digraph\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def visualize(input_nodes, output_name=None, format=\"svg\"):\n",
    "    input_nodes = {x for y in input_nodes for x in mesh_ttoc[y]}\n",
    "    dot = Digraph()\n",
    "    dot.attr(rankdir='LR')  # Keep layout horizontal (Left-to-Right)\n",
    "\n",
    "    edges = set()\n",
    "    nodes = {}\n",
    "    \n",
    "    for code in input_nodes:\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts) + 1):\n",
    "            partial_code = '.'.join(parts[:i])\n",
    "            if partial_code not in nodes and partial_code in mesh_ctot and (partial_code.startswith(\"F03\") or partial_code.startswith(\"C10\")):\n",
    "                nodes[partial_code] = mesh_ctot[partial_code]\n",
    "    def add_code_edges(code):\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts)):\n",
    "            parent_code = '.'.join(parts[:i])\n",
    "            child_code = '.'.join(parts[:i+1])\n",
    "            if parent_code in nodes and child_code in nodes:\n",
    "                edges.add((parent_code, child_code))\n",
    "            \n",
    "    def get_node_color(node):\n",
    "        term = nodes[node]\n",
    "        if term not in df.index:\n",
    "            return \"#FFFFFF\"  # White for nodes not in df\n",
    "        \n",
    "        highest_papers = df.loc[term, 'Highest Number of Papers']\n",
    "        enrichment_ratio = df.loc[term, 'Enrichment Ratio']\n",
    "        \n",
    "        if highest_papers < 2 or enrichment_ratio < 1:\n",
    "            return \"#FFFFFF\"  # White for nodes with low papers or enrichment\n",
    "        \n",
    "        color_rgb = mcolors.to_rgb(COLOR_TEMPLATE[target_idx])\n",
    "        intensity = min(1, enrichment_ratio / df['Enrichment Ratio'].max())  # Normalize to [0, 1]\n",
    "        scaled_color = tuple(1 - (1 - c) * intensity for c in color_rgb)  # Invert intensity calculation\n",
    "        return mcolors.to_hex(scaled_color)\n",
    "\n",
    "    \n",
    "    for code, term in nodes.items():\n",
    "        add_code_edges(code)  # Add edges between parent and child nodes\n",
    "    nodes[\"N\"] = \"Neurological\" \n",
    "    edges.add((\"N\", \"F03\"))\n",
    "    edges.add((\"N\", \"C10\"))\n",
    "    # Add nodes for each unique code with term name as label\n",
    "    for code, term in nodes.items():\n",
    "        node_color = get_node_color(code)\n",
    "        if term in df.index:\n",
    "            custom_label = f\"{term} ({df.loc[term, 'Total Number of Papers']})\"\n",
    "        else:\n",
    "            custom_label = term\n",
    "        dot.node(code, label=custom_label, shape='box', style='filled', fillcolor=node_color, fontname='Helvetica')\n",
    "    nodes[\"N\"] = \"Neurological\"\n",
    "    # Add edges for hierarchical relationships\n",
    "    for parent_code, child_code in edges:\n",
    "        dot.edge(parent_code, child_code)\n",
    "        \n",
    "\n",
    "    dot.attr(concentrate='true', splines='ortho')\n",
    "    dot.attr(nodesep='0.2', ranksep='0.5')\n",
    "    \n",
    "    # Create color legend\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [\"white\", COLOR_TEMPLATE[target_idx]])\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=df['Enrichment Ratio'].max())\n",
    "    cb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "                      cax=ax, orientation='horizontal', label='Enrichment Ratio')\n",
    "    \n",
    "    # Save legend as separate image\n",
    "    \n",
    "    # legend_path = f\"{FIGURE_PATH}/Fig4/legend.svg\"\n",
    "    # plt.savefig(legend_path, bbox_inches='tight')\n",
    "\n",
    "    if output_name:\n",
    "        dot.render(output_name, format=format, cleanup=True)\n",
    "    else:\n",
    "        dot.view()\n",
    "    return nodes\n",
    "\n",
    "output_name = f\"{FIGURE_PATH}/Fig4/neurological_hierarchy\"\n",
    "# Modify the visualize function call to adjust edge routing\n",
    "nodes = visualize(mesh_count_by_study.keys(), output_name=None, format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"iir_icc/Flanagan_median_15_probes_minimum_df.csv\")\n",
    "# df[(df[\"Number of Probes\"]<= 15) & (df[\"region_type\"] == \"CoRSIV\")]\n",
    "\n",
    "df[df[\"category\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import to_rgb\n",
    "\n",
    "# Figure 5A: median scatter plots on IIR and ICC for Flanagan dataset\n",
    "def plot_median_scatter(col1, col2, ax, category, cmap, min_papers, max_papers, show_legend=False):\n",
    "    region_markers = {\"CoRSIV\": \"D\", \"Non-CoRSIV\": \"o\"}\n",
    "    \n",
    "    for region_type, marker in region_markers.items():\n",
    "        region_df = df[(df[\"region_type\"] == region_type) & (df[\"category\"] == category)]\n",
    "    \n",
    "        \n",
    "        # Plot scatter points\n",
    "        for _, row in region_df.iterrows():\n",
    "            papers = row[\"papers\"]\n",
    "            color_intensity = (papers - min_papers) / (max_papers - min_papers + 1)\n",
    "            color = cmap(color_intensity)\n",
    "            # Plot main point with 3D effect\n",
    "            ax.scatter(row[col1], row[col2], c=[color], s=150, alpha=1, marker=marker, edgecolors='black', linewidth=1)\n",
    "    \n",
    "    # Add black star for all CoRSIVs\n",
    "    all_corsiv = df[(df[\"region_type\"] == \"CoRSIV\") & (df[\"category\"].isna())]\n",
    "    ax.scatter(all_corsiv[col1], all_corsiv[col2], c='black', s=300, marker='*')\n",
    "    \n",
    "    # Add hollow black star for all Non-CoRSIVs\n",
    "    all_non_corsiv = df[(df[\"region_type\"] == \"Non-CoRSIV\") & (df[\"category\"].isna())]\n",
    "    ax.scatter(all_non_corsiv[col1], all_non_corsiv[col2], facecolors='none', edgecolors='black', s=280, marker='*', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_xticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_xticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "    ax.set_yticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_yticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "    # ax.yaxis.set_tick_params(pad=2)  # Adjust the padding to move labels closer to the axis\n",
    "    zero_label = ax.yaxis.get_major_ticks()[0].label1\n",
    "    custom_va = 1.0  # This value can be adjusted as needed\n",
    "\n",
    "    zero_label.set_va('center')\n",
    "    zero_label.set_position((zero_label.get_position()[0], custom_va))    \n",
    "    ax.set_yticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20, length=5)\n",
    "    \n",
    "    # Add colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_papers, vmax=max_papers))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, cax=cax)\n",
    "    if category == \"cancer\":\n",
    "        cbar.set_label('≥ Number of Papers', rotation=90, labelpad=5, fontsize=18)\n",
    "    cbar.set_ticks(np.arange(int(min_papers), int(max_papers) + 1, 1))\n",
    "    cbar.ax.tick_params(size=5)  # Increase the length of the ticks\n",
    "    cbar.set_ticklabels(np.arange(int(min_papers), int(max_papers) + 1, 1), fontsize=16)\n",
    "    \n",
    "    if show_legend:\n",
    "        legend_elements = [plt.Line2D([0], [0], marker=marker, color='gray', label=region, markersize=8, linestyle='None')\n",
    "                           for region, marker in region_markers.items()]\n",
    "        legend_elements.extend([\n",
    "            plt.Line2D([0], [0], marker='*', color='black', label='All CoRSIVs', markersize=8, linestyle='None'),\n",
    "            plt.Line2D([0], [0], marker='*', markerfacecolor='none', markeredgecolor='black', label='All Non-CoRSIVs', markersize=8, linestyle='None')\n",
    "        ])\n",
    "\n",
    "# plot_categories = [\"cancer\", \"cardiovascular\", \"digestive\", \"endocrine\", \"immune\", \"metabolic\", \"neurological\", \"obesity\", \"respiratory\", \"urogenital\"]\n",
    "# plot_colors = ['#e6194B', '#f58231', '#f3c300', '#469990', '#2f8e3b', '#0db7dd', '#4363d8', '#800000', '#f032e6', '#911eb4']\n",
    "\n",
    "# category_names = plot_categories\n",
    "# color_template = plot_colors\n",
    "data = \"Flanagan\"\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10), gridspec_kw={'width_ratios': [1, 1, 1, 1], 'wspace': 0.1, 'hspace': 0.5})\n",
    "\n",
    "df = pd.read_csv(f\"iir_icc/{data}_median_15_probes_minimum_df.csv\")\n",
    "\n",
    "category_paper_ranges = {category: (df[df[\"category\"] == category][\"papers\"].min(), df[df[\"category\"] == category][\"papers\"].max()) for category in CATEGORY_NAMES}\n",
    "\n",
    "for i, category in enumerate(CATEGORY_NAMES):\n",
    "    row, col = divmod(i, 4)\n",
    "    \n",
    "    base_color = COLOR_TEMPLATE[i]\n",
    "    light_color = to_rgb(base_color)\n",
    "    dark_color = tuple(0.3 * c for c in to_rgb(base_color))\n",
    "    \n",
    "    min_papers, max_papers = category_paper_ranges[category]\n",
    "    \n",
    "    cmap = LinearSegmentedColormap.from_list('custom', [dark_color, light_color], N=100)\n",
    "    \n",
    "    ax = axes[row][col]\n",
    "    plot_median_scatter(\"Median iir1\", \"Median ICC\", ax, category, cmap, min_papers, max_papers, show_legend=(i == 0))\n",
    "    ax.set_title(category.capitalize(), fontsize=24, pad=10)\n",
    "    \n",
    "\n",
    "legend_elements = [plt.Line2D([0], [0], marker=marker, color='gray', label=region, markersize=14 if marker == 'D' else 16, linestyle='None')\n",
    "                   for region, marker in {\"CoRSIV\": \"D\", \"Non-CoRSIV\": \"o\"}.items()]\n",
    "legend_elements.extend([\n",
    "    plt.Line2D([0], [0], marker='*', color='black', label='All CoRSIVs', markersize=20, linestyle='None'),\n",
    "    plt.Line2D([0], [0], marker='*', markerfacecolor='none', markeredgecolor='black', label='All Non-CoRSIVs', markersize=20, linestyle='None', linewidth=2)\n",
    "])\n",
    "\n",
    "# Add legend to the main plot\n",
    "legend = axes[2,3].legend(handles=legend_elements, fontsize=20, frameon=False, bbox_to_anchor=(1.0, 1.0))\n",
    "# Hide last two subplots\n",
    "# axes[2, 2].axis('off')\n",
    "axes[2, 3].axis('off')\n",
    "\n",
    "# Add a vertical line\n",
    "x = 0.11\n",
    "fig.add_artist(plt.Line2D([x, x], [0.11, 0.88], transform=fig.transFigure, color='black', linestyle='-', linewidth=3))\n",
    "fig.text(x-0.025, 0.5, 'Median Intraclass Correlation Coefficient (ICC)', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0.05\n",
    "fig.add_artist(plt.Line2D([0.15, 0.88], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=3))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.4, y-0.035, r'Median IIR$_{2-98\\%}$ at Time 1', va='center', rotation='horizontal', fontsize=24)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(f\"{FIGURE_PATH}/Fig5/{data}_median_scatter.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f\"../permutation_testing/pt/urogenital/Prostatic Neoplasms_probes.csv\").iloc[:, 1:]\n",
    "df2 = pd.read_csv(f\"../permutation_testing/pt/cancer/Prostatic Neoplasms_probes.csv\").iloc[:, 1:]\n",
    "m = df1.merge(df2, how=\"outer\", indicator=True)\n",
    "# m[m[\"_merge\"] != \"both\"][\"pmcid\"].unique()\n",
    "m[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import to_rgb\n",
    "\n",
    "# Figure 5A: median scatter plots on IIR and ICC for Flanagan dataset\n",
    "def plot_median_scatter(col1, col2, ax, category, base_color, min_papers, max_papers, show_legend=False):\n",
    "    min_papers = 1  # Minimum number of papers\n",
    "    max_papers = 7  # Maximum number of papers\n",
    "    step_size = 30\n",
    "    min_size = 10\n",
    "    max_size = min_size+step_size*(max_papers-min_papers)\n",
    "    for region_type in [\"CoRSIV\", \"Non-CoRSIV\"]:\n",
    "        region_df = df[(df[\"region_type\"] == region_type) & (df[\"category\"] == category)]\n",
    "        # Plot scatter points\n",
    "        for _, row in region_df.iterrows():\n",
    "            papers = row[\"papers\"]\n",
    "            # Calculate marker size based on paper count\n",
    "            size = min_size + (max_size - min_size) * (papers - min_papers) / (max_papers - min_papers)\n",
    "            if region_type == \"CoRSIV\":\n",
    "                ax.scatter(row[col1], row[col2], c=base_color, s=size, alpha=1, marker='D', edgecolors='black')\n",
    "            else:\n",
    "                ax.scatter(row[col1], row[col2], c='gray', s=size, alpha=1, marker='o', edgecolors='black')\n",
    "    \n",
    "    # Add black star for all CoRSIVs\n",
    "    all_corsiv = df[(df[\"region_type\"] == \"CoRSIV\") & (df[\"category\"].isna())]\n",
    "    ax.scatter(all_corsiv[col1], all_corsiv[col2], c='black', s=300, marker='*')\n",
    "    \n",
    "    # Add hollow black star for all Non-CoRSIVs\n",
    "    all_non_corsiv = df[(df[\"region_type\"] == \"Non-CoRSIV\") & (df[\"category\"].isna())]\n",
    "    ax.scatter(all_non_corsiv[col1], all_non_corsiv[col2], facecolors='none', edgecolors='black', s=280, marker='*', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_xticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_xticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "    ax.set_yticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_yticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "    zero_label = ax.yaxis.get_major_ticks()[0].label1\n",
    "    custom_va = 1.0\n",
    "    zero_label.set_va('center')\n",
    "    zero_label.set_position((zero_label.get_position()[0], custom_va))    \n",
    "    ax.set_yticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20, length=5)\n",
    "    \n",
    "\n",
    "data = \"Flanagan\"\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10), gridspec_kw={'width_ratios': [1, 1, 1, 1], 'wspace': 0.1, 'hspace': 0.5})\n",
    "\n",
    "df = pd.read_csv(f\"iir_icc/{data}_median_15_probes_minimum_df.csv\")\n",
    "\n",
    "category_paper_ranges = {category: (df[df[\"category\"] == category][\"papers\"].min(), df[df[\"category\"] == category][\"papers\"].max()) for category in CATEGORY_NAMES}\n",
    "\n",
    "for i, category in enumerate(CATEGORY_NAMES):\n",
    "    row, col = divmod(i, 4)\n",
    "    base_color = COLOR_TEMPLATE[i]\n",
    "    min_papers, max_papers = category_paper_ranges[category]\n",
    "    \n",
    "    ax = axes[row][col]\n",
    "    plot_median_scatter(\"Median iir1\", \"Median ICC\", ax, category, base_color, min_papers, max_papers, show_legend=(i == 0))\n",
    "    ax.set_title(category.capitalize(), fontsize=24, pad=10)\n",
    "\n",
    "legend_elements = []\n",
    "legend_elements.extend([\n",
    "    plt.Line2D([0], [0], marker='*', color='black', label='All CoRSIVs', markersize=20, linestyle='None'),\n",
    "    plt.Line2D([0], [0], marker='*', markerfacecolor='none', markeredgecolor='black', label='All Non-CoRSIVs', markersize=20, linestyle='None', linewidth=2)\n",
    "])\n",
    "\n",
    "# Add legend to the main plot\n",
    "legend = axes[2,3].legend(handles=legend_elements, fontsize=20, frameon=False, bbox_to_anchor=(1.0, 1.0))\n",
    "# Hide last two subplots\n",
    "# axes[2, 2].axis('off')\n",
    "axes[2, 3].axis('off')\n",
    "\n",
    "# Add a vertical line\n",
    "x = 0.11\n",
    "fig.add_artist(plt.Line2D([x, x], [0.11, 0.88], transform=fig.transFigure, color='black', linestyle='-', linewidth=3))\n",
    "fig.text(x-0.025, 0.5, 'Median Intraclass Correlation Coefficient (ICC)', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0.05\n",
    "fig.add_artist(plt.Line2D([0.15, 0.88], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=3))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.4, y-0.035, r'Median IIR$_{2-98\\%}$ at Time 1', va='center', rotation='horizontal', fontsize=24)\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(f\"{FIGURE_PATH}/Fig5/{data}_median_scatter_2.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Figure 5A: median scatter plots on IIR and ICC for Flanagan dataset\n",
    "def plot_median_scatter(ax, category):\n",
    "    for region_type in [\"CoRSIV\", \"Non-CoRSIV\"]:\n",
    "        region_df = df[(df[\"region_type\"] == region_type) & (df[\"category\"] == category)]\n",
    "        color = COLOR_TEMPLATE[CATEGORY_NAMES.index(category)] if region_type == \"CoRSIV\" else \"gray\"\n",
    "        # Plot scatter points\n",
    "        X = np.array(region_df[\"Median iir1\"])\n",
    "        y = np.array(region_df[\"papers\"])\n",
    "        ax.scatter(X, y, c=color, s=150, alpha=1, marker=\"o\")\n",
    "        \n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "        ax.plot(X, model.predict(X_const), color=color, linestyle='--', linewidth=4, zorder=10, alpha=0.6)\n",
    "        if len(X) > 2:  \n",
    "            r_squared = round(model.rsquared, 3)\n",
    "            slope = round(model.params[1], 3)\n",
    "            f_pvalue = model.f_pvalue\n",
    "            annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2e}\"\n",
    "            pos =  2 if region_type == 'CoRSIV' else 0.1\n",
    "            ax.annotate(annotation_text, \n",
    "                xy=(0.85, pos),  # Use the last point of the data as the annotation position\n",
    "                xytext=(10, 0), \n",
    "                textcoords='offset points',\n",
    "                color=color,\n",
    "                fontsize=12,\n",
    "                ha='right', \n",
    "                va='bottom',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))  # Added weight parameter to make text bold\n",
    "\n",
    "        ax.set_ylim(0, region_df[\"papers\"].max()+1)\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_xticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_xticklabels(['0.0', '', '', '', '', '1.0'])\n",
    "data = \"Flanagan\"\n",
    "fig, axes = plt.subplots(3, 4, figsize=(14, 10), gridspec_kw={'width_ratios': [1, 1, 1, 1], 'wspace': 0.5, 'hspace': 0.5})\n",
    "\n",
    "df = pd.read_csv(f\"iir_icc/{data}_median_15_probes_minimum_df.csv\")\n",
    "\n",
    "category_paper_ranges = {category: (df[df[\"category\"] == category][\"papers\"].min(), df[df[\"category\"] == category][\"papers\"].max()) for category in CATEGORY_NAMES}\n",
    "\n",
    "for i, category in enumerate(CATEGORY_NAMES):\n",
    "    row, col = divmod(i, 4)\n",
    "    ax = axes[row][col]\n",
    "    plot_median_scatter(ax, category)\n",
    "    ax.set_title(category.capitalize(), fontsize=24, pad=10)\n",
    "\n",
    "\n",
    "\n",
    "axes[2, 3].axis('off')\n",
    "\n",
    "\n",
    "# plt.savefig(f\"{FIGURE_PATH}/Fig5/{data}_median_scatter.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5B: becon density plot\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cat_probes_dict = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    cat_probes_dict.append(read_in_probes(cat))\n",
    "    \n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "bins = [-1, 0, 1.0]\n",
    "target_col = \"Mean Cor All Brain\"\n",
    "df = pd.read_csv(\"becon/becon_all_probes.csv\")\n",
    "regions = list(zip([\"Non-CoRSIV\", \"CoRSIV\"], [non_corsiv_baseline, CORSIV_PROBE_LIST]))\n",
    "\n",
    "\n",
    "# Create a single subplot\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "catname = 'neurological'\n",
    "i = CATEGORY_NAMES.index(catname)\n",
    "\n",
    "dfs_for_plot = []\n",
    "max_papers = max(cat_probes_dict[i].values())\n",
    "papers_threshold = 2\n",
    "p = set(k for k, v in cat_probes_dict[i].items() if v >= papers_threshold)\n",
    "for rname, rset in regions:\n",
    "    probes_in_region = rset.intersection(p)\n",
    "    filtered_df = df[df[\"CpG ID\"].isin(probes_in_region)]\n",
    "    dfs_for_plot.append((filtered_df, rname))\n",
    "\n",
    "for j, (df_subset, rname) in enumerate(dfs_for_plot):\n",
    "    density = stats.gaussian_kde(df_subset[target_col])\n",
    "    xs = np.linspace(-1, 1, 200)\n",
    "    ys = density(xs)\n",
    "    color = COLOR_TEMPLATE[i] if rname == 'CoRSIV' else 'grey'\n",
    "    \n",
    "    ax.plot(xs, ys, \"-\", color=color, label=rname, linewidth=3)\n",
    "    median = df_subset[target_col].median()\n",
    "    ax.axvline(median, color=color, linestyle='--', linewidth=2, ymax=density(median)[0] / 2.1)\n",
    "    ax.text(median + 0.05, 0.5, f'median = {median:.2f}', rotation=90, color=\"black\", fontsize=16)\n",
    "    ax.fill_between(xs, ys, alpha=0.5, color=color)\n",
    "    peak_index = np.argmax(ys)\n",
    "    ax.text(xs[peak_index], ys[peak_index]+0.04, rname, fontsize=20, \n",
    "            verticalalignment='bottom', horizontalalignment='center', \n",
    "            color=color)\n",
    "\n",
    "# ax.set_aspect('equal')\n",
    "ax.set_xticks([-1, 0.0, 1.0])\n",
    "ax.tick_params(axis='both', which='major', labelsize=25, length=5)\n",
    "ax.set_yticks([0, 1.0, 2.0])\n",
    "ax.set_ylim(0, 2.1)\n",
    "ax.set_xlabel(\"Brain-Blood Correlation (BECon)\", fontsize=25)\n",
    "ax.set_ylabel('Density', fontsize=25)\n",
    "ax.set_title(f'Probes in ≥ {papers_threshold} Neurological Papers', fontsize=25, pad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "output = f\"{FIGURE_PATH}/Fig5/becon_kde_neurological.svg\"\n",
    "plt.savefig(output, format=\"svg\")\n",
    "# Only show the plot once\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5C: becon regression plot for neurological category\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "target_col = \"Mean Cor All Brain\"\n",
    "df = pd.read_csv(\"becon/becon_all_probes.csv\")\n",
    "regions = list(zip([\"CoRSIV\", \"Non-CoRSIV\"], [CORSIV_PROBE_LIST, non_corsiv_baseline]))\n",
    "\n",
    "# Read probes for neurological category\n",
    "neurological_probes = read_in_probes(\"neurological\")\n",
    "\n",
    "# Create a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "max_papers = max(neurological_probes.values())\n",
    "\n",
    "for rname, rset in regions:\n",
    "    medians = []\n",
    "    paper_counts = []\n",
    "    for pidx in range(1, max_papers + 1):\n",
    "        p = set(k for k, v in neurological_probes.items() if v == pidx)\n",
    "        probes_in_region = rset.intersection(p)\n",
    "        filtered_df = df[df[\"CpG ID\"].isin(probes_in_region)]\n",
    "        if len(filtered_df) < 15:\n",
    "            max_papers = pidx - 1\n",
    "            break\n",
    "        else:\n",
    "            medians.append(filtered_df[target_col].median())\n",
    "            paper_counts.append(pidx)\n",
    "    \n",
    "    X = np.array(medians)\n",
    "    y = np.array(paper_counts)\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "    color = COLOR_TEMPLATE[CATEGORY_NAMES.index(\"neurological\")] if rname == 'CoRSIV' else 'grey'\n",
    "    marker = 'D' if rname == 'CoRSIV' else 'o'\n",
    "    ax.scatter(X, y, color=color, label=rname, s=200, marker=marker)\n",
    "    ax.plot(X, model.predict(X_const), color=color, linestyle='--', linewidth=4, zorder=10, alpha=0.6)\n",
    "    r_squared = round(model.rsquared, 3)\n",
    "    slope = round(model.params[1], 3)\n",
    "    f_pvalue = round(model.f_pvalue, 3)\n",
    "    print(f\"Model p-value: {model.f_pvalue}\")\n",
    "    \n",
    "    pos = 0.75 if rname == 'CoRSIV' else 0.45\n",
    "    annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.3f}\"\n",
    "    \n",
    "    \n",
    "    # Add annotation\n",
    "    ax.annotate(annotation_text, \n",
    "                xy=(X[-1]-0.04, y[-1]/2),  # Use the last point of the data as the annotation position\n",
    "                xytext=(10, 0), \n",
    "                textcoords='offset points',\n",
    "                color=color,\n",
    "                fontsize=17,\n",
    "                ha='left', \n",
    "                va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))  # Added weight parameter to make text bold\n",
    "\n",
    "ax.set_xlabel(\"Median Brain-Blood Correlation (BECon)\", fontsize=22)\n",
    "ax.set_ylabel('Number of Papers', fontsize=18)\n",
    "ax.set_title(\"Neurological\", fontsize=25, pad=15)\n",
    "ax.set_xlim(-0.05, 0.6)\n",
    "ax.set_xticks(np.arange(0.0, 0.7, 0.1))\n",
    "ax.tick_params(axis='x', which='major', length=5)  # Increase the length of x-axis ticks\n",
    "# ax.set_xticklabels(['0.0', '', '0.2', '', '0.4', '', '0.6'])\n",
    "ax.set_yticks(range(1, max_papers + 1))\n",
    "ax.set_ylim(0, max_papers + 1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "# ax.legend(fontsize=14, frameon=False, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.close()\n",
    "output = f\"{FIGURE_PATH}/Fig5/becon_regression_neurological.svg\"\n",
    "plt.savefig(output, format=\"svg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
