{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Wen-Jou Chang\n",
    "Baylor College of Medicine\n",
    "\n",
    "This notebook analyzes the overlap between Illumina methylation array probes and CoRSIV regions. \n",
    "1. processes probe manifest files from both Zhou Lab and Illumina for different array types (HM450, EPIC, MSA)\n",
    "2. merge and pad different SIV regions to one unified set of CoRSIV regions\n",
    "3. filters for autosomal probes and identifies which probes overlap with CoRSIV regions for downstream analysis.\n",
    "4. annotated CoRSIV regions / probes\n",
    "\n",
    "We used two sets of probe manifest files:\n",
    "\n",
    "1. Zhou Lab manifest files for probe coordinates, ID, and Gencode annotations\n",
    "HM450: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/HM450/HM450.hg38.manifest.gencode.v36.tsv.gz\n",
    "EPIC: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/EPIC/EPIC.hg38.manifest.gencode.v36.tsv.gz\n",
    "MSA: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/MSA/MSA.hg38.manifest.gencode.v41.tsv.gz  \n",
    "\n",
    "\n",
    "2. Illumina manifest files for UCSC gene annotations\n",
    "HM450: https://webdata.illumina.com/downloads/productfiles/humanmethylation450/humanmethylation450_15017482_v1-2.csv\n",
    "EPIC: https://webdata.illumina.com/downloads/productfiles/methylationEPIC/infinium-methylationepic-v-1-0-b5-manifest-file-csv.zip\n",
    "MSA: https://support.illumina.com/content/dam/illumina-support/documents/downloads/productfiles/infiniummethylationscreening/MSA-48v1-0_20102838_A1.csv  \n",
    "\n",
    "Please download all files above and place them in ILLUMINA_DIR before running the code below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "\n",
    "import pandas as pd\n",
    "from pybedtools import BedTool\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "ILLUMINA_DIR = \"PUT YOUR DIRECTORY HERE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_autosome(array_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters probe list to only include probes on chr1-22. Limit probes to those starting with cg or ch.\n",
    "    \n",
    "    Args:\n",
    "        type (string):\"HM450\", \"EPIC\", \"MSA\"\n",
    "    \"\"\"\n",
    "    \n",
    "    autosome = [\"chr\"+str(i) for i in range(1,23)]\n",
    "    ver = \"36\" if array_type != \"MSA\" else \"41\"\n",
    "    df = pd.read_csv(f\"{ILLUMINA_DIR}/{array_type}.hg38.manifest.gencode.v{ver}.tsv\", header=0, sep=\"\\t\")\n",
    "    df = df[df[\"probeID\"].apply(lambda x: x.startswith(\"cg\") or x.startswith(\"ch.\"))]\n",
    "    df = df[df[\"CpG_chrm\"].apply(lambda x: x in autosome)]\n",
    "    df = df[[\"CpG_chrm\", \"CpG_beg\", \"CpG_end\", \"probeID\"]]\n",
    "    df[\"CpG_beg\"] = df[\"CpG_beg\"].astype(int)\n",
    "    df[\"CpG_end\"] = df[\"CpG_end\"].astype(int)\n",
    "\n",
    "    # sort by chr then start pos\n",
    "    chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "    df = df.sort_values(\n",
    "        by=['CpG_chrm', 'CpG_beg'],\n",
    "        key=lambda x: x.map(chr_order) if x.name == 'CpG_chrm' else x\n",
    "    )\n",
    "        \n",
    "    df.to_csv(f\"data/humanData/{array_type}.hg38.txt\", sep=\"\\t\", index=0, header=0)\n",
    "    return df\n",
    "\n",
    "for array_type in [\"HM450\", \"EPIC\"]:\n",
    "    filter_autosome(array_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## Merge Illumina HM450, EPIC, MSA probes\n",
    "cat HM450.hg38.txt  EPIC.hg38.txt | sort -k1,1 -k2,2n | bedtools merge -i - -d -1 -c 4 -o distinct > HM450_EPIC.clean.bed\n",
    "\n",
    "## Merge ME, SIV, ESS, CoRSIV regions. For ME,SIV,ESS regions, hg19 coordinates are converted to hg38 coordinates.\n",
    "cat corsiv2019.txt ESS.hg38.bed ME.hg38.bed SIV.hg38.bed | sort -k1,1 -k2,2n | bedtools merge -i - -d -1 -c 4 -o distinct > data/humanData/corsiv_control/all_corsiv_regions.merged.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for regions on chr1-chr22 then pad regions on both ends to have a size with multiple of 100\n",
    "df = pd.read_csv(\"data/humanData/corsiv_control/all_corsiv_regions.merged.bed\", sep=\"\\t\", names=[\"chr\", \"start\", 'end', \"id\"])\n",
    "# autosomes only\n",
    "autosome = [\"chr\"+str(i) for i in range(1,23)]\n",
    "df = df[df[\"chr\"].apply(lambda x: x in autosome)]\n",
    "\n",
    "df[\"new_id\"] = df.apply(lambda x: f\"{str(x['chr'])[3:]}_{x['start']}_{x['end']}\", axis=1)\n",
    "df[\"block_size\"] = df['end'] - df[\"start\"]\n",
    "\n",
    "# regions with new_id 19_40223366_40223480 and 19_40223493_40223693 will overlap after padding individually, so we merge them first\n",
    "merge_ids = ['19_40223366_40223480', '19_40223493_40223693']\n",
    "merge_rows = df[df['new_id'].isin(merge_ids)]\n",
    "new_start = merge_rows['start'].min()\n",
    "new_end = merge_rows['end'].max()\n",
    "new_id = f\"19_{new_start}_{new_end}\"\n",
    "merged_ids = ','.join(merge_rows['id'].tolist())\n",
    "\n",
    "new_row = {\n",
    "    'chr': 'chr19',\n",
    "    'start': new_start,\n",
    "    'end': new_end,\n",
    "    'new_id': new_id,\n",
    "    'id': merged_ids,\n",
    "    'block_size': new_end - new_start\n",
    "}\n",
    "\n",
    "df = df[~df['new_id'].isin(merge_ids)]\n",
    "df = df._append(new_row, ignore_index=True)\n",
    "  \n",
    "def pad_to_hundred(row):\n",
    "    \"\"\"\n",
    "    Pads each row (region) so that min(end-start) = 200 and (end-start) % 100 = 0.\n",
    "    \"\"\"\n",
    "    pad_size = (100 - (row['block_size'] % 100)) % 100\n",
    "    if row[\"block_size\"] + pad_size == 100:\n",
    "        pad_size += 100\n",
    "    row['start'] -= (pad_size // 2 + (pad_size % 2)) # pad start with one more bp if odd original block size\n",
    "    row[\"end\"] += pad_size // 2\n",
    "    row[\"block_size\"] = row[\"end\"] - row[\"start\"]\n",
    "    return row\n",
    "df = df.apply(pad_to_hundred, axis=1)\n",
    "\n",
    "# sort by chr then start pos\n",
    "chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "df = df.sort_values(\n",
    "    by=['chr', 'start'],\n",
    "    key=lambda x: x.map(chr_order) if x.name == 'chr' else x\n",
    ")\n",
    "df[[\"chr\", \"start\", \"end\", \"new_id\", \"id\"]].to_csv(\"data/humanData/corsiv_control/corsiv_regions_autosome_padded.bed\", sep=\"\\t\", index=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check on padded corsivs\n",
    "print(df[(df[\"block_size\"]%100!=0) | (df[\"block_size\"] < 200)].to_string()) \n",
    "temp = BedTool.from_dataframe(df[[\"chr\", \"start\", \"end\", \"new_id\"]])\n",
    "res = temp.intersect(temp, wa=True, c=True)\n",
    "res = res.to_dataframe(names=[\"chr\", \"start\", \"end\", \"new_id\", \"count\"])\n",
    "res[res[\"count\"]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corsiv_probe_df = pd.read_csv(\"data/humanData/corsiv_control/corsiv_HM450_EPIC_probes.bed\", sep=\"\\t\", names=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"CoRSIV_Chr\", \"CoRSIV_Start\", \"CoRSIV_End\", \"CoRSIV_ID1\", \"CoRSIV_ID2\"])\n",
    "\n",
    "hm450_manifest = pd.read_csv(f\"{ILLUMINA_DIR}/humanmethylation450_15017482_v1-2.csv\", skiprows=7)\n",
    "hm450_manifest = hm450_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group']]\n",
    "hm450_base = pd.read_csv(\"cleaned_data/illumina/HM450.hg38.bed\", sep=\"\\t\", names=[\"CHR_hg38\", \"Start_hg38\", \"End_hg38\", \"Name\"])\n",
    "hm450_manifest = hm450_manifest.merge(hm450_base, on=[\"Name\"])\n",
    "hm450_manifest = hm450_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group', 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "hm450_cleaned = pd.merge(hm450_manifest, corsiv_probe_df, left_on=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], right_on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "\n",
    "epic_manifest = pd.read_csv(f\"{ILLUMINA_DIR}/infinium-methylationepic-v-1-0-b5-manifest-file.csv\", skiprows=7)\n",
    "epic_manifest = epic_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group', 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "epic_cleaned = pd.merge(epic_manifest, corsiv_probe_df, left_on=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], right_on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "\n",
    "manifest_annotation = pd.concat([epic_cleaned, hm450_cleaned])\n",
    "manifest_annotation.drop_duplicates(inplace=True)\n",
    "manifest_annotation.loc[\n",
    "    (manifest_annotation[\"UCSC_RefGene_Name\"].isna()) & (manifest_annotation[\"UCSC_RefGene_Group\"].isna()),\n",
    "    \"UCSC_RefGene_Group\"\n",
    "] = \"Intergenic\"    \n",
    "manifest_annotation[\"Unique_UCSC_RefGene_Name\"] = manifest_annotation[\"UCSC_RefGene_Name\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "manifest_annotation[\"Unique_UCSC_RefGene_Group\"] = manifest_annotation[\"UCSC_RefGene_Group\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "manifest_annotation.drop(columns=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], inplace=True)\n",
    "\n",
    "\n",
    "epic_gencode = pd.read_csv(f\"{ILLUMINA_DIR}/EPIC.hg38.manifest.gencode.v36.tsv\", sep=\"\\t\")\n",
    "hm450_gencode = pd.read_csv(f\"{ILLUMINA_DIR}/HM450.hg38.manifest.gencode.v36.tsv\", sep=\"\\t\")\n",
    "gencode_annotation = pd.concat([epic_gencode, hm450_gencode])\n",
    "gencode_annotation.drop_duplicates(inplace=True)\n",
    "gencode_annotation.rename(columns={\"CpG_chrm\": \"Probe_Chr\", \"CpG_beg\": \"Probe_Start\", \"CpG_end\": \"Probe_End\", \"probeID\": \"Probe_ID\", 'genesUniq': \"Unique_GencodeV36_Name\"}, inplace=True)\n",
    "gencode_annotation = gencode_annotation[[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\", 'Unique_GencodeV36_Name']]\n",
    "corsiv_annotated = pd.merge(gencode_annotation, manifest_annotation, on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "corsiv_annotated['EPIC'] = corsiv_annotated.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, epic_cleaned[['CHR_hg38', 'Start_hg38', 'End_hg38', 'Name']].values)), axis=1)\n",
    "corsiv_annotated['HM450'] = corsiv_annotated.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, hm450_cleaned[['CHR_hg38', 'Start_hg38', 'End_hg38', 'Name']].values)), axis=1)\n",
    "\n",
    "# Create columns to store corresponding IDs from CoRSIV_ID2\n",
    "corsiv_annotated['ESS_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ESS']))\n",
    "corsiv_annotated['CoRSIV2019_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0].isnumeric()]))\n",
    "corsiv_annotated['ME_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ME']))\n",
    "corsiv_annotated['SIV_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'SIV']))\n",
    "\n",
    "# Display the updated dataframe\n",
    "corsiv_annotated = corsiv_annotated[['Probe_ID', 'Probe_Chr', 'Probe_Start', 'Probe_End',\n",
    "       'Unique_GencodeV36_Name', 'Unique_UCSC_RefGene_Name', 'Unique_UCSC_RefGene_Group',\n",
    "       'UCSC_RefGene_Name', 'UCSC_RefGene_Group',\n",
    "       'CoRSIV_Chr', 'CoRSIV_Start', 'CoRSIV_End', 'CoRSIV_ID1', 'EPIC',\n",
    "       'HM450', 'ME_ID', 'SIV_ID', 'ESS_ID', 'CoRSIV2019_ID']]\n",
    "corsiv_annotated.rename(columns={'CoRSIV_ID1': 'CoRSIV_ID'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame\n",
    "chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "corsiv_annotated = corsiv_annotated.sort_values(\n",
    "    by=['Probe_Chr', 'Probe_Start'],\n",
    "    key=lambda x: x.map(chr_order) if x.name == 'Probe_Chr' else x\n",
    ")\n",
    "corsiv_annotated.to_excel(\"data/humanData/corsiv_control/corsiv_annotated_manifest.xlsx\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# get gene body, tes, tss, cpg counts for each CoRSIV region, these information can be found in UCSC genome browser\n",
    "cd data/humanData\n",
    "\n",
    "bedtools intersect -a corsiv_control/corsiv_regions_autosome_padded.bed -b hg38_promoters_3kb.tab.txt hg38_gene_bodies.tab.txt hg38_three_prime_region_3kb.tab.txt hg38.CpG.bed.txt Illumina/HM450_EPIC.clean.bed -wa -C -names tss gb tes cpg probect > corsiv_control/corsiv_annotated.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define common column names and file paths\n",
    "col_names = [\"chr\", \"start\", \"end\", \"id\"]\n",
    "files = {\n",
    "    \"ME\": \"ME.hg38.bed\",\n",
    "    \"SIV\": \"SIV.hg38.bed\", \n",
    "    \"ESS\": \"ESS.hg38.bed\",\n",
    "    \"CoRSIV2019\": \"corsiv2019.txt\",\n",
    "}\n",
    "\n",
    "# Read files and add coordinates column\n",
    "dfs = {}\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path, sep=\"\\t\", names=col_names)\n",
    "    df[\"coords\"] = df[\"chr\"] + \":\" + df[\"start\"].astype(str) + \"-\" + df[\"end\"].astype(str)\n",
    "    dfs[name] = df\n",
    "\n",
    "# Create columns to store corresponding IDs from CoRSIV_ID2\n",
    "corsiv_bed = pd.read_csv(\"../data/humanData/corsiv_control/corsiv_annotated.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"CoRSIV_ID\", \"original_id\", \"dtype\", \"count\"])\n",
    "corsiv_bed = corsiv_bed.pivot(index=[\"chr\", \"start\", \"end\", \"CoRSIV_ID\", \"original_id\"], columns=\"dtype\", values=\"count\").reset_index()\n",
    "corsiv_bed[\"block_size\"] = corsiv_bed[\"end\"] - corsiv_bed[\"start\"]\n",
    "corsiv_bed['ME'] = corsiv_bed['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ME']))\n",
    "corsiv_bed['SIV'] = corsiv_bed['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'SIV']))\n",
    "corsiv_bed['ESS'] = corsiv_bed['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ESS']))\n",
    "corsiv_bed['CoRSIV2019'] = corsiv_bed['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0].isnumeric()]))\n",
    "\n",
    "corsiv_bed.drop(columns=[\"original_id\"], inplace=True)\n",
    "\n",
    "# Create new columns for coordinates from each dataset\n",
    "for name in ['ME', 'SIV', 'ESS', 'CoRSIV2019']:\n",
    "    corsiv_bed[f'{name}_COORDS'] = ''\n",
    "    \n",
    "    id_to_coords = {}\n",
    "    if name in dfs:\n",
    "        id_to_coords = dict(zip(dfs[name]['id'], dfs[name]['coords']))\n",
    "    \n",
    "    # Process all rows at once\n",
    "    corsiv_bed[f'{name}_COORDS'] = corsiv_bed[f'{name}'].apply(\n",
    "        lambda x: ','.join([id_to_coords.get(id, '') for id in x.split(',')]) if x else ''\n",
    "    )\n",
    "# Convert columns to boolean based on whether they contain ids or are empty\n",
    "corsiv_bed[['ME', 'SIV', 'ESS', 'CoRSIV2019']] = corsiv_bed[['ME', 'SIV', 'ESS', 'CoRSIV2019']].notna() & (corsiv_bed[['ME', 'SIV', 'ESS', 'CoRSIV2019']] != '')\n",
    "corsiv_bed = corsiv_bed[[\"CoRSIV_ID\", \"chr\", \"start\", \"end\", \"cpg\", \"block_size\", \"tss\", \"gb\", \"tes\", \"probect\", \"ME\", \"SIV\", \"ESS\", \"CoRSIV2019\", \"ME_COORDS\", \"SIV_COORDS\", \"ESS_COORDS\", \"CoRSIV2019_COORDS\"]]\n",
    "corsiv_bed.columns = [\"CoRSIV_ID\", \"Chromosome\", \"Start\", \"End\", \"Number of CpG\", \"Region Size (bp)\", \"TSS Counts\", \"Gene Body Counts\", \"TES Counts\", \"Probe Counts\", \"ME\", \"SIV\", \"ESS\", \"CoRSIV2019\", \"ME_COORDS\", \"SIV_COORDS\", \"ESS_COORDS\", \"CoRSIV2019_COORDS\"]\n",
    "corsiv_bed.to_csv(\"../data/humanData/corsiv_control/annotated_corsiv_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/humanData/corsiv_control/annotated_corsiv_all.csv\")\n",
    "cleaned_df = df[[\"CoRSIV_ID\", \"Chromosome\", \"Start\", \"End\", \"Number of CpG\", \"Region Size (bp)\", \"TSS Counts\", \"Gene Body Counts\", \"TES Counts\", \"Probe Counts\"]]\n",
    "cleaned_df.columns = ['CoRSIV_ID', 'chr', 'start', 'end', 'CpG_count', 'block_size', 'tss_count', 'Gene_body_count', 'tes_count', 'Union Count']\n",
    "cleaned_df.to_csv(\"../data/humanData/corsiv_control/annotated_corsiv_clean.csv\", index=False) # clean version for downstream"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
