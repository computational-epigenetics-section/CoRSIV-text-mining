{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Wen-Jou Chang\n",
    "Baylor College of Medicine\n",
    "\n",
    "This script is used to generate the supplementary figures in the paper, with the exception of following figures:\n",
    "- Figure S2 (permuation results histograms for all categories): in main_figure_code.ipynb, same code for fig. 3G\n",
    "- Figure S3 (annotated example): manual annotation\n",
    "- Figure S4 (decay plots for the 5 rest categories): in main_figure_code.ipynb, same code for fig. 3A-F\n",
    "- Figure S5 (power advantage scatter plot): in main_figure_code.ipynb, same code for fig. 3H\n",
    "- Figure S6 (neurological subcategory decay plots): in main_figure_code.ipynb, same code for fig. 4B-D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Initialization\n",
    "\"\"\"\n",
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib_venn import venn3\n",
    "from collections import Counter, defaultdict\n",
    "from graphviz import Digraph\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "import util\n",
    "\n",
    "from util import CATEGORY_NAMES, COLOR_TEMPLATE, CORSIV_PROBE_LIST, CONTROLS, CATEGORIES, read_in_probes, calculate_points, plot_enrichment, breakdown, export_paper\n",
    "\n",
    "SFIG_PATH = \"OUTPUT_FIGURE_PATH\"\n",
    "PROJECT_PATH = None\n",
    "if PROJECT_PATH:\n",
    "    os.chdir(PROJECT_PATH)\n",
    "\n",
    "\n",
    "epic = pd.read_csv(\"data/humanData/Illumina/EPIC.hg38.txt\", sep=\"\\t\", header=None)\n",
    "epic_probe_list = set(epic.iloc[:,3])\n",
    "hm450 = pd.read_csv(\"data/humanData/Illumina/HM450.hg38.txt\", sep=\"\\t\", header=None)\n",
    "hm450_probe_list = set(hm450.iloc[:,3])\n",
    "illumina = epic_probe_list.union(hm450_probe_list)\n",
    "\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.linewidth'] = 2  \n",
    "plt.rcParams['xtick.major.width'] = 2  \n",
    "plt.rcParams['ytick.major.width'] = 2  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S1: venn diagram of overlap between our results, ewas atlas, and ewas catalog\n",
    "ewas_atlas = set(pd.read_csv(\"data/supp/EWAS_Atlas_studies.tsv\", sep=\"\\t\")[\"PMID\"].astype(int)) # downloaded from ewas atlas\n",
    "ewas_catalog = pd.read_csv(\"data/supp/ewascatalog-studies.txt\", sep=\"\\t\") # downloaded from ewas catalog\n",
    "ewas_catalog = ewas_catalog[~ewas_catalog['PMID'].str.contains(r'\\D', na=True)]\n",
    "ewas_catalog = set(ewas_catalog[\"PMID\"].astype(int))\n",
    "our = pd.read_excel(\"data/2203_studies_info.xlsx\")\n",
    "our = set(our[\"PMID\"].astype(int))\n",
    "venn = venn3([our, ewas_catalog, ewas_atlas], ( \"Our Results\", \"EWAS Catalog\", \"EWAS Atlas\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S7B: adhd manual analysis\n",
    "import math\n",
    "\n",
    "manual = pd.read_csv(\"data/supp/all_ADHD_probes.csv\")\n",
    "manual = manual[manual[\"probeId\"].str.startswith(\"cg\") | manual[\"probeId\"].str.startswith(\"ch.\")]\n",
    "manual = manual[manual[\"probeId\"].isin(epic_probe_list) | manual[\"probeId\"].isin(hm450_probe_list)]\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if x in [\"<0.05\", \"pass\"]:\n",
    "            return 0.049\n",
    "        if x in [\"not pass\", \" \"]:\n",
    "            return math.nan\n",
    "        if x == \"> 0.1\":\n",
    "            return 0.11\n",
    "        if x == \"≤ 0.1\":\n",
    "            return 0.09\n",
    "        if x == \"≤ 0.05\":\n",
    "            return 0.049\n",
    "        if x == \"≤0.01\":\n",
    "            return 0.009\n",
    "        return x\n",
    "manual[\"p-value\"] = manual[\"p-value\"].apply(to_float)\n",
    "manual[\"q-value\"] = manual[\"q-value\"].apply(to_float)\n",
    "manual[\"adj-p-value\"] = manual[\"adj-p-value\"].apply(to_float)\n",
    "manual = manual.groupby(['pmcid', 'From']).filter(lambda x: len(x) <= 1000)\n",
    "\n",
    "\n",
    "keep = pd.read_csv(\"data/supp/all_ADHD_source.csv\")\n",
    "manual = pd.merge(manual, keep, on=[\"pmcid\", \"Notes\", \"From\", \"Title\"])\n",
    "manual = manual[manual[\"Keep\"]==1]\n",
    "manual = manual[(manual[\"p-value\"] < 0.05)]\n",
    "manual = manual.drop_duplicates(subset=[\"pmcid\", \"probeId\"])\n",
    "manual[[\"pmcid\",\"probeId\"]].to_csv(\"data/supp/adhd_manual_probes.csv\", index=False)\n",
    "\n",
    "c = Counter(manual[\"probeId\"])\n",
    "l1, l2, l3, p, p2, _ = calculate_points(c, manual)\n",
    "# output_path = f\"{SFIG_PATH}/adhd_manual_enrichment_nominal.svg\"\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], \"ADHD (Nominally Significant)\", 7, output=None, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S7A venn diagram\n",
    "manual = pd.read_csv(\"data/supp/adhd_manual_probes.csv\")\n",
    "automtated = pd.read_csv(\"data/probe/neurological_all_probes.csv\")\n",
    "automtated[\"Filtered Mesh Term\"] = automtated[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "automtated = automtated[automtated[\"Filtered Mesh Term\"].apply(lambda x: \"Attention Deficit Disorder with Hyperactivity\" in x)][[\"pmcid\", \"probeId\"]]\n",
    "m = pd.merge(manual, automtated, how=\"outer\", indicator=True)\n",
    "\n",
    "# Create counts for Venn diagram\n",
    "left_only = len(m[m['_merge'] == 'left_only'])\n",
    "right_only = len(m[m['_merge'] == 'right_only']) \n",
    "both = len(m[m['_merge'] == 'both'])\n",
    "\n",
    "# Create and plot Venn diagram\n",
    "plt.figure(figsize=(8,8))\n",
    "venn2(subsets=(left_only, right_only, both), \n",
    "      set_labels=('Manual', 'Automated'),\n",
    "      set_colors=('lightblue', 'lightgreen'))\n",
    "plt.title('Overlap between Manual and \\nAutomated Probe Instances', pad=20, fontsize=24)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S7B pie chart\n",
    "qc = pd.read_csv(\"data/supp/probes_unique_to_automated.csv\").iloc[:,-3:]\n",
    "# Calculate total counts for each column\n",
    "excluded_count = qc['Excluded'].sum()\n",
    "nonsig_count = qc['Nonsignificant'].sum() \n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.pie([excluded_count, nonsig_count], \n",
    "        labels=[f'Excluded\\n({excluded_count} probes)', f'Not Significant\\n({nonsig_count} probes)'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#fbb4ae', '#b3cde3'])\n",
    "plt.title('Reasons for Probe Mismatch \\nBetween Automated and Manual Approaches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common code to generate decay plots for subcategories\n",
    "current_category = \"metabolic\"\n",
    "target_idx = CATEGORY_NAMES.index(current_category)\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = 'data/humanData/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "neuro_mesh_tree = {}\n",
    "keywords = CATEGORIES[target_idx]\n",
    "for kw in keywords:\n",
    "    neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "if current_category != \"metabolic\":\n",
    "    neuro_df = pd.read_csv(f\"data/probe/{current_category}_all_probes.csv\")\n",
    "    if current_category != \"cancer\":\n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    else:\n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "else:\n",
    "    neuro_df = pd.read_csv(f\"data/probe/metabolic_diseases_all_probes.csv\")  \n",
    "    neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "\n",
    "temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i, m in enumerate(mesh_terms):\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "mesh_count_by_study[current_category.capitalize()] = len(set(neuro_df[\"pmcid\"]))\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "\n",
    "enriched_categories = []\n",
    "not_enriched_categories = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "probes = []\n",
    "papers_ct = []\n",
    "terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "paper_sets = []\n",
    "for term in terms:\n",
    "    output_path = f\"{SFIG_PATH}/{current_category if current_category != 'neurological' else 'neuro'}/{term}.svg\"\n",
    "    p, paper, r, p2, curr_paper_set = breakdown(neuro_df, term_pmcid_map, [term], target_idx, output=None, show_figure=False, format=\"svg\", export_all=True, show_y_label=True)\n",
    "    probes.append(p)\n",
    "    d1.append(paper)\n",
    "    d2.append(r)\n",
    "    papers_ct.append(p2)\n",
    "    paper_sets.append(curr_paper_set)\n",
    "\n",
    "df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"CoRSIV Probes\": probes, \"CoRSIV Papers\":papers_ct, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts, \"Paper Sets\": paper_sets})\n",
    "df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "df.index = df[\"Categories\"]\n",
    "df.drop(columns=[\"Categories\"], inplace=True)\n",
    "# df = df[(df[\"Enrichment Ratio\"] > 1) & (df[\"Highest Number of Papers\"]> 1) & (df.index!=current_category.capitalize())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common code for category specific mesh hierarchy\n",
    "from graphviz import Digraph\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def visualize(input_nodes, output_name=None, format=\"svg\", target=\"Enrichment Ratio\"):\n",
    "    input_nodes = {x for y in input_nodes for x in mesh_ttoc[y]}\n",
    "    dot = Digraph()\n",
    "    dot.attr(rankdir='LR')  # Keep layout horizontal (Left-to-Right)\n",
    "\n",
    "    edges = set()\n",
    "    nodes = {}\n",
    "    \n",
    "    for code in input_nodes:\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts) + 1):\n",
    "            partial_code = '.'.join(parts[:i])\n",
    "            if partial_code not in nodes and partial_code in mesh_ctot and any(partial_code.startswith(c) for k in keywords for c in mesh_ttoc[k]):\n",
    "                nodes[partial_code] = mesh_ctot[partial_code]\n",
    "    def add_code_edges(code):\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts)):\n",
    "            parent_code = '.'.join(parts[:i])\n",
    "            child_code = '.'.join(parts[:i+1])\n",
    "            if parent_code in nodes and child_code in nodes:\n",
    "                edges.add((parent_code, child_code))\n",
    "            \n",
    "    def get_node_color(node):\n",
    "        term = nodes[node]\n",
    "        if term not in df.index:\n",
    "            return \"#FFFFFF\"  # White for nodes not in df\n",
    "        \n",
    "        highest_papers = df.loc[term, 'Highest Number of Papers']\n",
    "        enrichment_ratio = df.loc[term, 'Enrichment Ratio']\n",
    "        \n",
    "        if enrichment_ratio < 1 or highest_papers < 2:\n",
    "            return \"#FFFFFF\"  # White for nodes with low papers or enrichment\n",
    "        \n",
    "        color_rgb = mcolors.to_rgb(COLOR_TEMPLATE[target_idx])\n",
    "        intensity = min(1, df.loc[term, target] / df[target].max())\n",
    "        scaled_color = tuple(1 - (1 - c) * intensity for c in color_rgb)  # Invert intensity calculation\n",
    "        return mcolors.to_hex(scaled_color)\n",
    "\n",
    "    \n",
    "    for code, term in nodes.items():\n",
    "        add_code_edges(code)  # Add edges between parent and child nodes\n",
    "    if current_category == \"neurological\":\n",
    "        nodes[\"N\"] = \"Neurological\" \n",
    "        edges.add((\"N\", \"F03\"))\n",
    "        edges.add((\"N\", \"C10\"))\n",
    "    # Add nodes for each unique code with term name as label\n",
    "    for code, term in nodes.items():\n",
    "        node_color = get_node_color(code)\n",
    "        if term in df.index:\n",
    "            custom_label = f\"{term} ({df.loc[term, 'Total Number of Papers']})\"\n",
    "        else:\n",
    "            custom_label = term\n",
    "        dot.node(code, label=custom_label, shape='box', style='filled', fillcolor=node_color, fontname='Helvetica')\n",
    "    for parent_code, child_code in edges:\n",
    "        dot.edge(parent_code, child_code)\n",
    "\n",
    "    dot.attr(concentrate='true', splines='ortho')\n",
    "    dot.attr(nodesep='0.2', ranksep='0.5')\n",
    "    \n",
    "    # Create color legend\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [\"white\", COLOR_TEMPLATE[target_idx]])\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=df[target].max())\n",
    "    cb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "                      cax=ax, orientation='horizontal', label=target)\n",
    "    \n",
    "    # Save legend as separate image\n",
    "\n",
    "    legend_path =f\"{SFIG_PATH}/hierarchy_plots/{current_category}_legend.svg\"\n",
    "    # plt.savefig(legend_path, bbox_inches='tight')\n",
    "\n",
    "    if output_name:\n",
    "        dot.render(output_name, format=format, cleanup=True)\n",
    "    else:\n",
    "        dot.view()\n",
    "    return nodes\n",
    "\n",
    "minimum_papers = 15\n",
    "output_name = f\"{SFIG_PATH}/hierarchy_plots/{current_category}_hierarchy_{minimum_papers}_papers\" if minimum_papers > 0 else f\"{SFIG_PATH}/hierarchy_plots/{current_category}_full_hierarchy\"\n",
    "# Modify the visualize function call to adjust edge routing\n",
    "tmp = {key:count for key, count in mesh_count_by_study.items() if count >= minimum_papers}\n",
    "\n",
    "nodes = visualize(tmp.keys(), output_name=None, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S9: heatmap of probes by subcategories for metabolic and endocrine\n",
    "\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "\n",
    "mesh_tree = {} #big category:set of subcategories\n",
    "file_path = 'data/humanData/mtrees2024.txt'\n",
    "\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "            \n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs} #code:term\n",
    "\n",
    "\n",
    "def next_layer(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix) and len(given_string) > len(prefix) and given_string[len(prefix)] == '.' and '.' not in given_string[len(prefix)+1:]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "keywords = [cc for c in CATEGORIES for cc in c]\n",
    "\n",
    "for kw in keywords:\n",
    "    mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if next_layer(c, mesh_ttoc[kw])])\n",
    "\n",
    "dfs = []\n",
    "for key_category in [\"metabolic\", \"endocrine\"]:\n",
    "    if key_category == \"metabolic\":\n",
    "        df = pd.read_csv(\"data/probe/metabolic_diseases_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"data/probe/{key_category}_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    target_categories = set([])\n",
    "    for c in CATEGORIES[CATEGORY_NAMES.index(key_category)]:\n",
    "        target_categories |= mesh_tree[c]\n",
    "    df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term for term in x if term in target_categories])\n",
    "    c = Counter(df[\"probeId\"])\n",
    "    c = {k:v for k, v in c.items() if v <= 5 and v >= 2 and k in CORSIV_PROBE_LIST}\n",
    "    df = df[df[\"probeId\"].isin(c)]\n",
    "    df = df.explode('Filtered Mesh Term')\n",
    "    dfs.append(df)\n",
    "    df_pivoted = df.groupby(['probeId', 'Filtered Mesh Term']).size().reset_index(name='count')\n",
    "    df_pivoted = df_pivoted.pivot(index='probeId', columns='Filtered Mesh Term', values='count').fillna(0)\n",
    "    df_pivoted.rename_axis(index=None, columns=None, inplace=True)\n",
    "    dfs.append(df_pivoted)\n",
    "    colors = [(1, 1, 1),\n",
    "            (0, 0, 1)]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_blue\", colors, N=100)\n",
    "    g = sns.clustermap(df_pivoted, method='ward', metric='euclidean', cmap=cmap, figsize=(8, 6), annot=False, vmax=5)\n",
    "    cbar = g.ax_heatmap.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 5])\n",
    "    cbar.set_ticklabels(['0', '5'])\n",
    "    g.ax_row_dendrogram.set_visible(False)\n",
    "    for line in g.ax_col_dendrogram.collections:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    cbar.set_label(\"Number of \\nPapers\", rotation=90, fontsize=16)\n",
    "    g.ax_heatmap.set_yticks([])\n",
    "    g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=90, ha='center', va='top', fontsize=20)\n",
    "    g.ax_heatmap.tick_params(axis='x', which='major', pad=10)\n",
    "    g.figure.suptitle(f\"{len(df_pivoted):,} CoRSIV Probes Reported in ≥2 {key_category.capitalize()} Papers\", y=1.05, fontsize=26)\n",
    "    # g.savefig(f\"{SFIG_PATH}/heatmap/{key_category}_subcategory_2papers.jpeg\", format=\"jpeg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S12 and S13A density plots\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "bins = [-1, 0, 1.0]\n",
    "\n",
    "idx = 0 # change idx here based on data type: becon / icc / iir\n",
    "target_cols = [\"Mean Cor All Brain\", \"ICC\", \"iir1\"]\n",
    "fnames = [\"data/humanData/becon_all_probes.csv\", \"data/humanData/Flanagan/Flanagan_icc_results.csv\", \"data/humanData/Flanagan/Flanagan_iir_results.csv\"]\n",
    "probe_cols = [\"CpG ID\", \"ID\", \"ID\"]\n",
    "xlabels = [\"Brain-Blood Correlation (BECon)\", \"Intraclass Correlation Coefficient (ICC)\", r\"IIR$_{2-98\\%}$\"]\n",
    "output_path = [\"becon\", \"icc\", \"iir\"]\n",
    "\n",
    "\n",
    "cat_probes_dict = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    cat_probes_dict.append(read_in_probes(cat))\n",
    "    \n",
    "    \n",
    "target_col = target_cols[idx]\n",
    "df = pd.read_csv(fnames[idx])\n",
    "colname = probe_cols[idx]\n",
    "regions = list(zip([\"Non-CoRSIV\", \"CoRSIV\"], [non_corsiv_baseline, CORSIV_PROBE_LIST]))\n",
    "xlabel = xlabels[idx]\n",
    "output_id = output_path[idx]\n",
    "\n",
    "# Create subplots with 3 rows and 4 columns\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.flatten()\n",
    "lst = [c for c in CATEGORY_NAMES if c != \"neurological\"] if idx == 0 else CATEGORY_NAMES\n",
    "\n",
    "for cat_idx, catname in enumerate(lst):\n",
    "    ax = axes[cat_idx]\n",
    "    i = CATEGORY_NAMES.index(catname)\n",
    "\n",
    "    dfs_for_plot = []\n",
    "    max_papers = max(cat_probes_dict[i].values())\n",
    "    papers_threshold = 2\n",
    "    p = set(k for k, v in cat_probes_dict[i].items() if v >= papers_threshold)\n",
    "    \n",
    "    for rname, rset in regions:\n",
    "        probes_in_region = rset.intersection(p)\n",
    "        filtered_df = df[df[colname].isin(probes_in_region)]\n",
    "        dfs_for_plot.append((filtered_df, rname))\n",
    "\n",
    "    for j, (df_subset, rname) in enumerate(dfs_for_plot):\n",
    "        density = stats.gaussian_kde(df_subset[target_col])\n",
    "        xs = np.linspace(-1, 1, 200)\n",
    "        ys = density(xs)\n",
    "        color = COLOR_TEMPLATE[i] if rname == 'CoRSIV' else 'grey'\n",
    "        ax.plot(xs, ys, \"-\", color=color, label=rname, linewidth=3)\n",
    "        ax.fill_between(xs, ys, alpha=0.5, color=color)\n",
    "        peak_index = np.argmax(ys)\n",
    "        ax.text(xs[peak_index], ys[peak_index]+0.04, f\"{rname}\", fontsize=15, #\\n(n={len(df_subset):,})\n",
    "                verticalalignment='bottom', horizontalalignment='center',\n",
    "                color=color)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16, length=5)\n",
    "    if idx == 2:\n",
    "        ax.set_xticks([0, 0.5, 1.0])\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "    elif idx == 1:\n",
    "        ax.set_xticks([-1, -0.5, 0.0, 0.5, 1.0])\n",
    "    else:\n",
    "        ax.set_yticks([0, 1.0, 2.0])\n",
    "        ax.set_ylim(0, 2.5)\n",
    "        ax.set_xticks([-1, 0.0, 1.0])\n",
    "    ax.set_title(catname.capitalize(), \n",
    "                 fontsize=20, pad=10)\n",
    "ax = axes[10] if idx == 0 else axes[11]\n",
    "\n",
    "dfs_for_plot = []\n",
    "\n",
    "for rname, rset in regions:\n",
    "    filtered_df = df[df[colname].isin(rset)]\n",
    "    dfs_for_plot.append((filtered_df, rname))\n",
    "\n",
    "for j, (df_subset, rname) in enumerate(dfs_for_plot):\n",
    "    density = stats.gaussian_kde(df_subset[target_col])\n",
    "    xs = np.linspace(-1, 1, 200)\n",
    "    ys = density(xs)\n",
    "    color = 'black' if rname == 'CoRSIV' else 'grey'\n",
    "    ax.plot(xs, ys, \"-\", color=color, label=rname, linewidth=3)\n",
    "    ax.fill_between(xs, ys, alpha=0.5, color=color)\n",
    "    peak_index = np.argmax(ys)\n",
    "    ax.text(xs[peak_index], ys[peak_index]+0.04, f\"{rname}\", fontsize=15, #\\n(n={len(df_subset):,})\n",
    "            verticalalignment='bottom', horizontalalignment='center',\n",
    "            color=color)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16, length=5)\n",
    "if idx == 2:\n",
    "    ax.set_xticks([0, 0.5, 1.0])\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "elif idx == 1:\n",
    "    ax.set_xticks([-1, -0.5, 0.0, 0.5, 1.0])\n",
    "else:\n",
    "    ax.set_yticks([0, 1.0, 2.0])\n",
    "    ax.set_ylim(0, 2.5)\n",
    "    ax.set_xticks([-1, 0.0, 1.0])\n",
    "    \n",
    "ax.set_title(\"All Probes\", \n",
    "                fontsize=20, pad=10)\n",
    "if idx == 0:\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "# Add a vertical line\n",
    "x = 0\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.04, 0.5, 'Density', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0\n",
    "fig.add_artist(plt.Line2D([0.04, 0.98], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.04, xlabel, ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# output = f\"{SFIG_PATH}/{output_id}_kde_all_categories.svg\"\n",
    "# plt.savefig(output, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S13B: becon regression plots for all categories except neurological\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "target_col = \"Mean Cor All Brain\"\n",
    "df = pd.read_csv(\"data/humanData/becon_all_probes.csv\")\n",
    "regions = list(zip([\"CoRSIV\", \"Non-CoRSIV\"], [CORSIV_PROBE_LIST, non_corsiv_baseline]))\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 11))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Plot each category except neurological\n",
    "plot_idx = 0\n",
    "for cat in [\"cancer\", \"endocrine\", \"immune\", \"metabolic\", \"urogenital\"]:\n",
    "    cat_probes = read_in_probes(cat)\n",
    "    ax = axs[plot_idx]\n",
    "    max_papers = max(cat_probes.values())\n",
    "\n",
    "    for rname, rset in regions:\n",
    "        medians = []\n",
    "        paper_counts = []\n",
    "        for pidx in range(1, max_papers + 1):\n",
    "            p = set(k for k, v in cat_probes.items() if v == pidx)\n",
    "            probes_in_region = rset.intersection(p)\n",
    "            filtered_df = df[df[\"CpG ID\"].isin(probes_in_region)]\n",
    "            if len(filtered_df) < 15:\n",
    "                max_papers = pidx - 1\n",
    "                break\n",
    "            else:\n",
    "                medians.append(filtered_df[target_col].median())\n",
    "                paper_counts.append(pidx)\n",
    "        \n",
    "        X = np.array(medians)\n",
    "        y = np.array(paper_counts)\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "        color = COLOR_TEMPLATE[CATEGORY_NAMES.index(cat)] if rname == 'CoRSIV' else 'grey'\n",
    "        marker = 'D' if rname == 'CoRSIV' else 'o'\n",
    "        ax.scatter(X, y, color=color, label=rname, s=200, marker=marker)\n",
    "        ax.plot(X, model.predict(X_const), color=color, linestyle='--', linewidth=4, zorder=10, alpha=0.6)\n",
    "        r_squared = round(model.rsquared, 3)\n",
    "        slope = round(model.params[1], 3)\n",
    "        f_pvalue = round(model.f_pvalue, 3)\n",
    "        \n",
    "        annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2f}\"\n",
    "        \n",
    "        # Add annotation\n",
    "        ax.annotate(annotation_text, \n",
    "                    xy=(X[-1]-0.04, y[-1]/2),\n",
    "                    xytext=(10, 0), \n",
    "                    textcoords='offset points',\n",
    "                    color=color,\n",
    "                    fontsize=20,\n",
    "                    ha='left', \n",
    "                    va='center',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))\n",
    "\n",
    "    # ax.set_xlabel(\"Median Brain-Blood Correlation (BECon)\", fontsize=22)\n",
    "    # ax.set_ylabel('Number of Papers', fontsize=18)\n",
    "    ax.set_title(cat.capitalize(), fontsize=28, pad=15)\n",
    "    ax.set_xlim(-0.05, 0.6)\n",
    "    ax.set_xticks(np.arange(0.0, 0.7, 0.1))\n",
    "    ax.tick_params(axis='x', which='major', length=5)\n",
    "    ax.set_yticks(range(1, max_papers + 1))\n",
    "    ax.set_ylim(0, max_papers + 1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "axs[-1].axis('off')\n",
    "# Add legend to the last subplot\n",
    "handles = [plt.Line2D([0], [0], marker='D', color='w', markerfacecolor=\"k\", \n",
    "                      label=\"CoRSIV\", markersize=15)]\n",
    "handles.append(plt.Line2D([0], [0], marker='o', color='w', label='Control', markersize=20, markerfacecolor='grey'))\n",
    "\n",
    "axs[-1].legend(handles=handles, loc='center', fontsize=24, frameon=False)\n",
    "\n",
    "x = 0\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.04, 0.5, 'Number of Papers', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0\n",
    "fig.add_artist(plt.Line2D([0.04, 0.96], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.04, \"Median Brain-Blood Correlation (BECon)\", ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "\n",
    "# output = f\"{SFIG_PATH}/becon_regression_all_categories.svg\"\n",
    "# plt.savefig(output, format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S14: distribution of papers by the number of probes reported\n",
    "dfs = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    df = pd.read_csv(f\"before_filter1000/{cat}_all_probes.csv\")\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df.drop_duplicates(subset=[\"pmcid\", \"probeId\"], inplace=True)\n",
    "ref = pd.read_excel(\"data/2203_studies_info.xlsx\")[\"PMCID\"]\n",
    "df = pd.merge(df, ref, right_on=\"PMCID\", left_on=\"pmcid\", how=\"left\")\n",
    "df = df[[\"pmcid\", \"probeId\"]]\n",
    "grouped_df = df.groupby('pmcid')['probeId'].nunique().reset_index()\n",
    "grouped_df.columns = ['pmcid', 'unique_probe_count']\n",
    "\n",
    "tmp = grouped_df[grouped_df['unique_probe_count'] < 10000]\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.hist(tmp['unique_probe_count'], bins=range(0, int(tmp['unique_probe_count'].max()) + 100, 100), edgecolor='black', color='skyblue')\n",
    "plt.axvline(x=1000, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Probes Reported', fontsize=24)\n",
    "plt.ylabel('Number of Papers', fontsize=24)\n",
    "plt.title('Distribution of Papers by the Number of Probes Reported', fontsize=24, pad=20)\n",
    "\n",
    "plt.xlim(0, 10000)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(f\"{SFIG_PATH}/supp_table_size_zoomedin.jpeg\", dpi=300, bbox_inches='tight')\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig. S15: control metrics\n",
    "control_info = pd.read_csv(\"data/humanData/corsiv_control/corsiv_control_matching.csv\")\n",
    "control_info.columns = [\"Control_ID\", \"Control Chr\", \"Control Start\", \"Control End\", \"Control Region Size (bp)\", \n",
    "                       \"Control CpG Count\", \"Control TSS Count\", \"Control Gene Body Count\", \"Control TES Count\", \n",
    "                       \"Control Probe Count\", \"CoRSIV_ID\", \"CoRSIV Chr\", \"CoRSIV Start\", \"CoRSIV End\", \n",
    "                       \"CoRSIV Region Size (bp)\", \"CoRSIV CpG Count\", \"CoRSIV TSS Count\", \"CoRSIV Gene Body Count\", \n",
    "                       \"CoRSIV TES Count\", \"CoRSIV Probe Count\"]\n",
    "control_info = control_info[control_info[\"CoRSIV Probe Count\"] > 0]\n",
    "metrics = [\"Region Size (bp)\", \"Probe Count\", \"CpG Count\", \"TSS Count\", \"Gene Body Count\", \"TES Count\"]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6), gridspec_kw={'hspace': 0.2, 'wspace':0.6})\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "for i, m in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    data = pd.DataFrame({\n",
    "        'x': control_info[f'CoRSIV {m}'],\n",
    "        'y': control_info[f'Control {m}']\n",
    "    })\n",
    "    data['frequency'] = data.groupby(['x', 'y'])['x'].transform('count')\n",
    "    reversed_Blues = plt.colormaps[\"Blues\"].reversed()\n",
    "    scatter = ax.scatter(data['x'], data['y'], \n",
    "                        c=data['frequency'], \n",
    "                        cmap='Blues',\n",
    "                        s=50, \n",
    "                        edgecolor='grey',\n",
    "                        alpha=0.8)\n",
    "    ax.set_aspect('equal')\n",
    "    max_val = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "    ax.set_xlim(0, max_val)\n",
    "    ax.set_ylim(0, max_val)\n",
    "    ax.set_title(m, fontsize=16)\n",
    "    ax.set_xticks(ax.get_yticks())\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_xlim(-1, max_val)\n",
    "    ax.set_ylim(-1, max_val)\n",
    "max_freq = max([data.groupby(['x', 'y'])['x'].count().max() for m in metrics])\n",
    "plt.subplots_adjust(right=0.88)\n",
    "norm = plt.Normalize(vmin=1, vmax=1000)\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=norm)\n",
    "sm.set_array([])\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax, label='Number of Regions')\n",
    "cbar.ax.set_ylabel('Number of Regions', fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "# Set colorbar ticks to be 1, 10, 100, 1000 (log scale)\n",
    "cbar.set_ticks(range(200, 1200, 200))\n",
    "labels = [str(i) if i < 1000 else \">1000\" for i in range(200, 1200, 200)]\n",
    "cbar.set_ticklabels(labels)\n",
    "\n",
    "for ax in axes:\n",
    "    scatter = ax.collections[0]\n",
    "    scatter.set_norm(norm)\n",
    "    \n",
    "x = 0.03\n",
    "fig.add_artist(plt.Line2D([x, x], [0.15,0.85], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.08, 0.5, 'Control', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "y = 0.05\n",
    "fig.add_artist(plt.Line2D([0.12, 0.88], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(0.5, y-0.08, \"CoRSIV\", ha='center', rotation='horizontal', fontsize=24)\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(f\"{SFIG_PATH}/control_metrics.jpeg\", dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
