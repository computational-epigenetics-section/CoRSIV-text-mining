{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Initialization\n",
    "\"\"\"\n",
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from collections import defaultdict\n",
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import importlib, util\n",
    "PROJECT_PATH = \"/Users/antata/Library/CloudStorage/OneDrive-BaylorCollegeofMedicine/text-mining/categories\"\n",
    "SFIG_PATH = \"/Users/antata/Library/CloudStorage/OneDrive-BaylorCollegeofMedicine/text-mining/manuscript/sfigs\"\n",
    "os.chdir(PROJECT_PATH)\n",
    "importlib.reload(util)\n",
    "from util import CATEGORY_NAMES, COLOR_TEMPLATE, CORSIV_PROBE_LIST, CONTROLS, CATEGORIES, read_in_probes, calculate_points, plot_enrichment, breakdown, export_paper\n",
    "\n",
    "\n",
    "epic = pd.read_csv(\"../humanData/database/EPIC.hg38.txt\", sep=\"\\t\", header=None)\n",
    "epic_probe_list = set(epic.iloc[:,3])\n",
    "hm450 = pd.read_csv(\"../humanData/database/HM450.hg38.txt\", sep=\"\\t\", header=None)\n",
    "hm450_probe_list = set(hm450.iloc[:,3])\n",
    "illumina = epic_probe_list.union(hm450_probe_list)\n",
    "\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.linewidth'] = 2  # Thicker outer box\n",
    "plt.rcParams['xtick.major.width'] = 2  # Thicker x-axis ticks\n",
    "plt.rcParams['ytick.major.width'] = 2  # Thicker y-axis ticks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    if cat == \"obesity\":\n",
    "        cat2 = \"anthropometric\"\n",
    "    elif cat == \"urogenital\":\n",
    "        cat2 = \"reproductive\"\n",
    "    else:\n",
    "        cat2 = cat\n",
    "    df = pd.read_csv(f\"probe/archive/before_filter1000/{cat2}_all_probes.csv\")\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df.drop_duplicates(subset=[\"pmcid\", \"probeId\"], inplace=True)\n",
    "ref = pd.read_csv(\"pubmed_search/all_studies_cleaned.csv\")[[\"PMCID\", \"Category\"]]\n",
    "df = pd.merge(df, ref, right_on=\"PMCID\", left_on=\"pmcid\", how=\"left\")\n",
    "df = df[[\"Category\", \"pmcid\", \"probeId\"]]\n",
    "grouped_df = df.groupby('pmcid')['probeId'].nunique().reset_index()\n",
    "grouped_df.columns = ['pmcid', 'unique_probe_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(grouped_df['unique_probe_count'], bins=20, edgecolor='black', color='skyblue')\n",
    "plt.xlabel('Number of Probes Reported')\n",
    "plt.ylabel('Number of Papers')\n",
    "plt.title('Distribution of Papers by the Number of Probes Reported')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(f\"{SFIG_PATH}/supp_table_size_all.jpeg\", dpi=300, bbox_inches='tight')\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = grouped_df[grouped_df['unique_probe_count'] < 10000]\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.hist(tmp['unique_probe_count'], bins=range(0, int(tmp['unique_probe_count'].max()) + 100, 100), edgecolor='black', color='skyblue')\n",
    "plt.axvline(x=1000, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Probes Reported', fontsize=24)\n",
    "plt.ylabel('Number of Papers', fontsize=24)\n",
    "plt.title('Distribution of Papers by the Number of Probes Reported', fontsize=24, pad=20)\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.xlim(0, 10000)\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(f\"{SFIG_PATH}/supp_table_size_zoomedin.jpeg\", dpi=300, bbox_inches='tight')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control_info = pd.read_excel(f\"../manuscript/supplementary_tables.xlsx\", sheet_name=\"S5\")\n",
    "\n",
    "control_info = control_info[control_info[\"CoRSIV Probe Count\"] > 0]\n",
    "metrics = [\"Region Size (bp)\", \"Probe Count\", \"CpG Count\", \"TSS Count\", \"Gene Body Count\", \"TES Count\"]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6), gridspec_kw={'hspace': 0.2, 'wspace':0.6})\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "for i, m in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    data = pd.DataFrame({\n",
    "        'x': control_info[f'CoRSIV {m}'],\n",
    "        'y': control_info[f'Control {m}']\n",
    "    })\n",
    "    data['frequency'] = data.groupby(['x', 'y'])['x'].transform('count')\n",
    "    reversed_Blues = plt.colormaps[\"Blues\"].reversed()\n",
    "    scatter = ax.scatter(data['x'], data['y'], \n",
    "                        c=data['frequency'], \n",
    "                        cmap='Blues',\n",
    "                        s=50, \n",
    "                        edgecolor='grey',\n",
    "                        alpha=0.8)\n",
    "    ax.set_aspect('equal')\n",
    "    max_val = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "    ax.set_xlim(0, max_val)\n",
    "    ax.set_ylim(0, max_val)\n",
    "    ax.set_title(m, fontsize=16)\n",
    "    ax.set_xticks(ax.get_yticks())\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_xlim(-1, max_val)\n",
    "    ax.set_ylim(-1, max_val)\n",
    "max_freq = max([data.groupby(['x', 'y'])['x'].count().max() for m in metrics])\n",
    "plt.subplots_adjust(right=0.88)\n",
    "norm = plt.Normalize(vmin=1, vmax=1000)\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=norm)\n",
    "sm.set_array([])\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax, label='Number of Regions')\n",
    "cbar.ax.set_ylabel('Number of Regions', fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "# Set colorbar ticks to be 1, 10, 100, 1000 (log scale)\n",
    "cbar.set_ticks(range(200, 1200, 200))\n",
    "labels = [str(i) if i < 1000 else \">1000\" for i in range(200, 1200, 200)]\n",
    "cbar.set_ticklabels(labels)\n",
    "\n",
    "for ax in axes:\n",
    "    scatter = ax.collections[0]\n",
    "    scatter.set_norm(norm)\n",
    "    \n",
    "x = 0.03\n",
    "fig.add_artist(plt.Line2D([x, x], [0.15,0.85], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.08, 0.5, 'Control', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "y = 0.05\n",
    "fig.add_artist(plt.Line2D([0.12, 0.88], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(0.5, y-0.08, \"CoRSIV\", ha='center', rotation='horizontal', fontsize=24)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f\"{SFIG_PATH}/control_metrics.jpeg\", dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3A-F: decay plots for each category\n",
    "\n",
    "cat_probes_dict = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "    if cat == \"cancer\":\n",
    "        df = pd.read_csv(f\"probe/{cat}_all_probes_backup.csv\")\n",
    "        probe_list = df[\"probeId\"].to_list()\n",
    "        c = dict(Counter(probe_list))\n",
    "        cat_probes_dict.append(c)\n",
    "    else:\n",
    "        cat_probes_dict.append(read_in_probes(cat))\n",
    "\n",
    "for i in [1,2,4,8,9]:\n",
    "    output_path = f\"{SFIG_PATH}/{CATEGORY_NAMES[i]}_decay_enrichment.svg\"\n",
    "    l1, l2, l3, p, p2, _ = calculate_points(cat_probes_dict[i], CATEGORY_NAMES[i])\n",
    "    show_y_label = i == 1\n",
    "    show_legend = i == 1\n",
    "    paper, r = plot_enrichment([l1, l2, l3, p, p2], CATEGORY_NAMES[i], i, output=None, show_figure=None, show_y_label=show_y_label, format=\"svg\", show_legend=show_legend, export_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_category = \"cancer\"\n",
    "target_idx = CATEGORY_NAMES.index(current_category)\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "neuro_mesh_tree = {}\n",
    "keywords = CATEGORIES[target_idx]\n",
    "for kw in keywords:\n",
    "    neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "if current_category != \"metabolic\":\n",
    "    neuro_df = pd.read_csv(f\"probe/{current_category}_all_probes.csv\")\n",
    "    if current_category != \"cancer\":\n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    else:\n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "else:\n",
    "    neuro_df = pd.read_csv(f\"probe/metabolic_diseases_all_probes.csv\")  \n",
    "    neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "# df = pd.read_csv(\"probe_main_table/cancer_main_probes.csv\")\n",
    "# probes_to_keep = df[df[\"pmcid\"] == \"PMC10275808\"][\"probeId\"].tolist()\n",
    "# neuro_df = neuro_df[(~(neuro_df[\"pmcid\"] == \"PMC10275808\")) | (neuro_df[\"probeId\"].isin(probes_to_keep))]\n",
    "\n",
    "# neuro_df = neuro_df[~neuro_df[\"pmcid\"].isin([\"PMC4222689\", \"PMC4913906\"])]\n",
    "\n",
    "temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i, m in enumerate(mesh_terms):\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "mesh_count_by_study[current_category.capitalize()] = len(set(neuro_df[\"pmcid\"]))\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "\n",
    "enriched_categories = []\n",
    "not_enriched_categories = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "probes = []\n",
    "papers_ct = []\n",
    "terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "paper_sets = []\n",
    "for term in terms:\n",
    "    if term != \"Genital Neoplasms, Male\":\n",
    "        continue\n",
    "    output_path = f\"{SFIG_PATH}/{current_category if current_category != 'neurological' else 'neuro'}/{term}.svg\"\n",
    "    p, paper, r, p2, curr_paper_set = breakdown(neuro_df, term_pmcid_map, [term], target_idx, output=None, show_figure=True, format=\"svg\", export_all=True, show_y_label=True)\n",
    "    probes.append(p)\n",
    "    d1.append(paper)\n",
    "    d2.append(r)\n",
    "    papers_ct.append(p2)\n",
    "    paper_sets.append(curr_paper_set)\n",
    "\n",
    "# df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"CoRSIV Probes\": probes, \"CoRSIV Papers\":papers_ct, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts, \"Paper Sets\": paper_sets})\n",
    "# df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "# df.index = df[\"Categories\"]\n",
    "# df.drop(columns=[\"Categories\"], inplace=True)\n",
    "# df = df[(df[\"Enrichment Ratio\"] > 1) & (df[\"Highest Number of Papers\"]> 1) & (df.index!=current_category.capitalize())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_studies = pd.read_csv(\"pubmed_search/all_studies_cleaned.csv\")[\"PMCID\"].tolist()\n",
    "def mqtl(text):\n",
    "    if type(text) is float:\n",
    "        return None\n",
    "    paragraphs = [p.get(\"text\") for p in json.loads(text)[\"documents\"][0][\"passages\"] if p.get(\"text\")]\n",
    "    allp = \" \".join(paragraphs)\n",
    "    return sum([allp.count(\"mQTL\"), allp.count(\"meQTL\"), allp.count(\"methylation quantitative trait loci\")])\n",
    "# mqtl_studies = set([])\n",
    "dfs = []\n",
    "for cat in CATEGORY_NAMES:\n",
    "\n",
    "    cat = \"anthropometric\" if cat == \"obesity\" else cat\n",
    "\n",
    "    df = pd.read_csv(f\"full_text/{cat}_full_text.csv\")\n",
    "    df = df[df[\"PMCID\"].isin(all_studies)]\n",
    "    df[\"mQTL\"] = df[\"Full Text\"].apply(mqtl)\n",
    "    df = df[df[\"PMCID\"].isin(all_studies)]\n",
    "    dfs.append(df[[\"PMCID\", \"mQTL\"]])\n",
    "dfs = pd.concat(dfs)\n",
    "dfs.drop_duplicates(subset=\"PMCID\", inplace=True)\n",
    "    # mqtl_studies.update(set(df[df[\"mQTL\"]==True][\"PMCID\"].tolist()))\n",
    "# len(mqtl_studies)\n",
    "dfs.to_csv(\"mqtl_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqtl_info = pd.read_csv(\"mqtl_counts.csv\")\n",
    "neuro_df = pd.read_csv(f\"probe/neurological_all_probes.csv\")  \n",
    "neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "adhd_studies = neuro_df[neuro_df[\"Filtered Mesh Term\"].apply(lambda x: \"Attention Deficit Disorder with Hyperactivity\" in x)][\"pmcid\"].tolist()\n",
    "mqtl_info[mqtl_info[\"PMCID\"].isin(adhd_studies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqtl_info = pd.read_csv(\"mqtl_counts.csv\")\n",
    "\n",
    "for j, current_category in enumerate(CATEGORY_NAMES):\n",
    "    keywords = CATEGORIES[j]\n",
    "    neuro_mesh_tree = {}\n",
    "    for kw in keywords:\n",
    "        neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "    if current_category != \"metabolic\":\n",
    "        neuro_df = pd.read_csv(f\"probe/{current_category}_all_probes.csv\")  \n",
    "        if current_category == \"cancer\":\n",
    "            neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "        else:\n",
    "            neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    else:\n",
    "        neuro_df = pd.read_csv(f\"probe/metabolic_diseases_all_probes.csv\")  \n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "\n",
    "    temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "    mesh_count_by_study = defaultdict(int)\n",
    "    mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "    pmcids = list(temp1[\"pmcid\"])\n",
    "    term_pmcid_map = defaultdict(set)\n",
    "    for i in range(len(mesh_terms)):\n",
    "        m = mesh_terms[i]\n",
    "        for t in m:\n",
    "            mesh_count_by_study[t] += 1\n",
    "            term_pmcid_map[t].add(pmcids[i])\n",
    "    mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "    mesh_count_by_study[current_category.capitalize()] = len(set(neuro_df[\"pmcid\"]))\n",
    "    mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "    categories = list(mesh_count_by_study.keys())\n",
    "    counts = list(mesh_count_by_study.values())\n",
    "\n",
    "    enriched_categories = []\n",
    "    not_enriched_categories = []\n",
    "\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    probes = []\n",
    "    papers_ct = []\n",
    "    terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "    paper_sets = []\n",
    "    for term in terms:\n",
    "        p, paper, r, p2, curr_paper_set = breakdown(neuro_df, term_pmcid_map, [term], j, output=None, show_figure=False, format=\"svg\", export_all=False)\n",
    "        probes.append(p)\n",
    "        d1.append(paper)\n",
    "        d2.append(r)\n",
    "        papers_ct.append(p2)\n",
    "        paper_sets.append(curr_paper_set)\n",
    "\n",
    "    df = pd.DataFrame({\"Categories\":terms, \"Enrichment Ratio\":d2, \"CoRSIV Probes\": probes, \"CoRSIV Papers\":papers_ct, \"Highest Number of Papers\": d1, \"Total Number of Papers\": counts, \"Paper Sets\": paper_sets})\n",
    "    df.sort_values(\"Enrichment Ratio\", ascending=False, inplace=True)\n",
    "    cutoff = 15 if current_category != \"cancer\" else 20\n",
    "    df = df[df[\"Total Number of Papers\"] >= cutoff]\n",
    "    df = df[[\"Categories\", \"Enrichment Ratio\"]]\n",
    "    \n",
    "    # Calculate average mQTL count for each category\n",
    "    df[\"mQTL\"] = df[\"Categories\"].apply(lambda x: mqtl_info[mqtl_info[\"PMCID\"].isin(term_pmcid_map[x])][\"mQTL\"].mean())\n",
    "    df = df[[\"Categories\", \"Enrichment Ratio\", \"mQTL\"]]\n",
    "    df.to_csv(f\"mqtl/mqtl_counts_{current_category}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs}\n",
    "\n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in neuro_mesh_tree.values())\n",
    "\n",
    "for current_category in ['cancer', 'endocrine', 'immune', 'metabolic', \"neurological\", 'urogenital', 'obesity']:\n",
    "    j = CATEGORY_NAMES.index(current_category)\n",
    "    keywords = CATEGORIES[j]\n",
    "    neuro_mesh_tree = {}\n",
    "    for kw in keywords:\n",
    "        neuro_mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if starts_with_any(c, mesh_ttoc[kw])])\n",
    "    if current_category != \"metabolic\":\n",
    "        neuro_df = pd.read_csv(f\"probe/{current_category}_all_probes.csv\")  \n",
    "        if current_category == \"cancer\":\n",
    "            neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "        else:\n",
    "            neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    else:\n",
    "        neuro_df = pd.read_csv(f\"probe/metabolic_diseases_all_probes.csv\")  \n",
    "        neuro_df[\"Filtered Mesh Term\"] = neuro_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "\n",
    "    temp1 = neuro_df.drop_duplicates(subset=\"pmcid\")\n",
    "    mesh_count_by_study = defaultdict(int)\n",
    "    mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "    pmcids = list(temp1[\"pmcid\"])\n",
    "    term_pmcid_map = defaultdict(set)\n",
    "    for i in range(len(mesh_terms)):\n",
    "        m = mesh_terms[i]\n",
    "        for t in m:\n",
    "            mesh_count_by_study[t] += 1\n",
    "            term_pmcid_map[t].add(pmcids[i])\n",
    "    mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key)}\n",
    "    mesh_count_by_study[current_category.capitalize()] = len(set(neuro_df[\"pmcid\"]))\n",
    "    mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "    categories = list(mesh_count_by_study.keys())\n",
    "    counts = list(mesh_count_by_study.values())\n",
    "\n",
    "\n",
    "    terms, counts = zip(*[(k, v) for k, v in mesh_count_by_study.items()])\n",
    "    paper_sets = []\n",
    "    for term in terms:\n",
    "        p, paper, r, p2, curr_paper_set = breakdown(neuro_df, term_pmcid_map, [term], j, output=None, show_figure=False, format=\"svg\", export_all=False)\n",
    "        paper_sets.append(curr_paper_set)\n",
    "\n",
    "    df = pd.DataFrame({\"Categories\":terms, \"Paper Sets\": paper_sets})\n",
    "    categories_we_want = pd.read_excel(f\"../permutation_testing/pt_results.xlsx\", sheet_name=current_category)\n",
    "    m = pd.merge(categories_we_want[\"Disease\"], df, left_on=\"Disease\", right_on=\"Categories\").iloc[:, 1:]\n",
    "    paper_df = pd.DataFrame(index=sorted(set().union(*m[\"Paper Sets\"])))\n",
    "    for cat, papers in zip(m[\"Categories\"], m[\"Paper Sets\"]):\n",
    "        paper_df[cat] = paper_df.index.isin(papers)\n",
    "    read_in_category = current_category if current_category != \"metabolic\" else \"metabolic_diseases\"\n",
    "    paper_details = pd.read_csv(f\"pubmed_search/{read_in_category}_final.csv\")[[\"PMID\", \"PMCID\", \"Journal\", \"Last Name\", \"Year\", \"Title\", \"Abstract\"]]\n",
    "    paper_details.columns = [\"PMID\", \"PMCID\", \"Journal\", \"First Author Last Name\", \"Year\", \"Title\", \"Abstract\"]\n",
    "    probes = pd.read_csv(f\"probe/{read_in_category}_all_probes.csv\")[[\"probeId\", \"pmcid\"]]\n",
    "    c = Counter(probes[\"probeId\"])\n",
    "    c = {k:v for k, v in c.items() if v > 1}\n",
    "    probes = probes[(probes[\"probeId\"].isin(CORSIV_PROBE_LIST)) & (probes[\"probeId\"].isin(c.keys()))]\n",
    "    probes = probes.groupby(\"pmcid\").agg({\"probeId\": lambda x: \",\".join(x)})\n",
    "    probes.columns = [\"CoRSIV Probes Reported\"]\n",
    "    paper_details = pd.merge(paper_details, probes, left_on=\"PMCID\", right_on=\"pmcid\")\n",
    "    # paper_details.drop(columns=[\"pmcid\"], inplace=True)\n",
    "    final_df = pd.merge(paper_details, paper_df, left_on=\"PMCID\", right_index=True)\n",
    "    final_df.to_csv(f\"../manuscript/stables/paper_details/{current_category}_paper_details_2.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"probe_main_table/cancer_main_probes.csv\")\n",
    "probes_to_keep = df[df[\"pmcid\"] == \"PMC10275808\"][\"probeId\"].tolist()\n",
    "cancer_df = pd.read_csv(\"probe/cancer_all_probes.csv\")\n",
    "cancer_df = cancer_df[(~(cancer_df[\"pmcid\"] == \"PMC10275808\")) | (cancer_df[\"probeId\"].isin(probes_to_keep))]\n",
    "cancer_df[\"Filtered Mesh Term\"] = cancer_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "term = \"Prostatic Neoplasms\"\n",
    "cancer_df = cancer_df[cancer_df[\"Filtered Mesh Term\"].  apply(lambda x: term in x)]\n",
    "c = Counter(cancer_df[\"probeId\"])\n",
    "l1, l2, l3, p, p2,_ = calculate_points(c, term)\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], term, 0, output=None, show_figure=True, box_placement=(0.15, 0.9), show_y_label=True, format=\"svg\", show_legend=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.read_csv(\"probe/cancer_all_probes.csv\")\n",
    "cancer_df[cancer_df[\"pmcid\"]== \"PMC10275808\"].shape\n",
    "# cancer_df.to_csv(\"probe/cancer_all_probes_corsiv.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_category = \"cancer\"\n",
    "categories_we_want = pd.read_excel(f\"../permutation_testing/pt_results.xlsx\", sheet_name=current_category)\n",
    "categories_we_want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "fig, axes = plt.subplots(3, 2, figsize=(6,9))\n",
    "axes = axes.flatten()\n",
    "fig_idx = 0\n",
    "for current_category in [\"cancer\", \"endocrine\", \"immune\", \"metabolic\", \"neurological\", \"urogenital\"]:\n",
    "    j = CATEGORY_NAMES.index(current_category)\n",
    "    df = pd.read_csv(f\"mqtl/mqtl_counts_{current_category}.csv\")\n",
    "    ax = axes[fig_idx]\n",
    "    X = np.array(df[\"mQTL\"])\n",
    "    y = np.array(df[\"Enrichment Ratio\"])\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "    ax.scatter(X, y, color=COLOR_TEMPLATE[j], s=50)\n",
    "    ax.plot(X, model.predict(X_const), color=COLOR_TEMPLATE[j], linestyle='solid', linewidth=4, alpha=0.6)\n",
    "    r_squared = model.rsquared\n",
    "    f_pvalue = model.f_pvalue\n",
    "    if current_category in [\"cancer\", \"endocrine\", \"urogenital\"]:\n",
    "        annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.1e}\"\n",
    "    else:\n",
    "        annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2g}\"\n",
    "    ax.annotate(annotation_text, \n",
    "                xy=(0.05, 0.85), # Position in axes coordinates\n",
    "                xycoords='axes fraction',\n",
    "                color=\"red\" if f_pvalue < 0.05 else \"black\",\n",
    "                fontsize=16,\n",
    "                ha='left', \n",
    "                va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))\n",
    "    ax.set_title(f\"{current_category.capitalize()}\", fontsize=20)\n",
    "    fig_idx += 1\n",
    "# Add a vertical line\n",
    "x = 0.02\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.07, 0.5, 'Enrichment Ratio', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0.02\n",
    "fig.add_artist(plt.Line2D([0.1, 0.95], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.07, \"Average mQTL Mentions\", ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f\"{SFIG_PATH}/mqtl_enrichment_ratio_enriched.svg\", format=\"svg\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6,6))\n",
    "axes = axes.flatten()\n",
    "fig_idx = 0\n",
    "for current_category in [\"cardiovascular\", \"digestive\", \"hematological\", \"respiratory\"]:\n",
    "    j = CATEGORY_NAMES.index(current_category)\n",
    "    df = pd.read_csv(f\"mqtl/mqtl_counts_{current_category}.csv\")\n",
    "    ax = axes[fig_idx]\n",
    "    X = np.array(df[\"mQTL\"])\n",
    "    y = np.array(df[\"Enrichment Ratio\"])\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "    ax.scatter(X, y, color=COLOR_TEMPLATE[j], s=50)\n",
    "    ax.plot(X, model.predict(X_const), color=COLOR_TEMPLATE[j], linestyle='solid', linewidth=4, alpha=0.6)\n",
    "    r_squared = model.rsquared\n",
    "    f_pvalue = model.f_pvalue\n",
    "    \n",
    "    annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2f}\"\n",
    "    ax.annotate(annotation_text, \n",
    "                xy=(0.55, 0.85), # Position in axes coordinates\n",
    "                xycoords='axes fraction',\n",
    "                color=\"red\" if f_pvalue < 0.05 else \"black\",\n",
    "                fontsize=16,\n",
    "                ha='left', \n",
    "                va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))\n",
    "    ax.set_title(f\"{current_category.capitalize()}\", fontsize=20)\n",
    "    fig_idx += 1\n",
    "# Add a vertical line\n",
    "x = 0.02\n",
    "fig.add_artist(plt.Line2D([x, x], [0.09,0.91], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.07, 0.5, 'Enrichment Ratio', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0.02\n",
    "fig.add_artist(plt.Line2D([0.1, 0.95], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.07, \"Average mQTL Mentions\", ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f\"{SFIG_PATH}/mqtl_enrichment_ratio_not_enriched.svg\", format=\"svg\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"probe/cancer_all_probes.csv\")\n",
    "# df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "# df = df[df[\"Filtered Mesh Term\"].apply(lambda x: \"Prostatic Neoplasms\" in x)]\n",
    "# df = df[df[\"probeId\"].isin(CORSIV_PROBE_LIST)]\n",
    "df[\"pmcid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5C: becon regression plots for all categories except neurological\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "target_col = \"Mean Cor All Brain\"\n",
    "df = pd.read_csv(\"becon/becon_all_probes.csv\")\n",
    "regions = list(zip([\"CoRSIV\", \"Non-CoRSIV\"], [CORSIV_PROBE_LIST, non_corsiv_baseline]))\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 11))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Plot each category except neurological\n",
    "plot_idx = 0\n",
    "for cat in [\"cancer\", \"endocrine\", \"immune\", \"metabolic\", \"urogenital\"]:\n",
    "    cat_probes = read_in_probes(cat)\n",
    "    ax = axs[plot_idx]\n",
    "    max_papers = max(cat_probes.values())\n",
    "\n",
    "    for rname, rset in regions:\n",
    "        medians = []\n",
    "        paper_counts = []\n",
    "        for pidx in range(1, max_papers + 1):\n",
    "            p = set(k for k, v in cat_probes.items() if v == pidx)\n",
    "            probes_in_region = rset.intersection(p)\n",
    "            filtered_df = df[df[\"CpG ID\"].isin(probes_in_region)]\n",
    "            if len(filtered_df) < 15:\n",
    "                max_papers = pidx - 1\n",
    "                break\n",
    "            else:\n",
    "                medians.append(filtered_df[target_col].median())\n",
    "                paper_counts.append(pidx)\n",
    "        \n",
    "        X = np.array(medians)\n",
    "        y = np.array(paper_counts)\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "        color = COLOR_TEMPLATE[CATEGORY_NAMES.index(cat)] if rname == 'CoRSIV' else 'grey'\n",
    "        marker = 'D' if rname == 'CoRSIV' else 'o'\n",
    "        ax.scatter(X, y, color=color, label=rname, s=200, marker=marker)\n",
    "        ax.plot(X, model.predict(X_const), color=color, linestyle='--', linewidth=4, zorder=10, alpha=0.6)\n",
    "        r_squared = round(model.rsquared, 3)\n",
    "        slope = round(model.params[1], 3)\n",
    "        f_pvalue = round(model.f_pvalue, 3)\n",
    "        \n",
    "        annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2f}\"\n",
    "        \n",
    "        # Add annotation\n",
    "        ax.annotate(annotation_text, \n",
    "                    xy=(X[-1]-0.04, y[-1]/2),\n",
    "                    xytext=(10, 0), \n",
    "                    textcoords='offset points',\n",
    "                    color=color,\n",
    "                    fontsize=20,\n",
    "                    ha='left', \n",
    "                    va='center',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))\n",
    "\n",
    "    # ax.set_xlabel(\"Median Brain-Blood Correlation (BECon)\", fontsize=22)\n",
    "    # ax.set_ylabel('Number of Papers', fontsize=18)\n",
    "    ax.set_title(cat.capitalize(), fontsize=28, pad=15)\n",
    "    ax.set_xlim(-0.05, 0.6)\n",
    "    ax.set_xticks(np.arange(0.0, 0.7, 0.1))\n",
    "    ax.tick_params(axis='x', which='major', length=5)\n",
    "    ax.set_yticks(range(1, max_papers + 1))\n",
    "    ax.set_ylim(0, max_papers + 1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "axs[-1].axis('off')\n",
    "# Add legend to the last subplot\n",
    "handles = [plt.Line2D([0], [0], marker='D', color='w', markerfacecolor=\"k\", \n",
    "                      label=\"CoRSIV\", markersize=15)]\n",
    "handles.append(plt.Line2D([0], [0], marker='o', color='w', label='Control', markersize=20, markerfacecolor='grey'))\n",
    "\n",
    "axs[-1].legend(handles=handles, loc='center', fontsize=24, frameon=False)\n",
    "\n",
    "x = 0\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.04, 0.5, 'Number of Papers', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0\n",
    "fig.add_artist(plt.Line2D([0.04, 0.96], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.04, \"Median Brain-Blood Correlation (BECon)\", ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "\n",
    "output = f\"{SFIG_PATH}/becon_regression_all_categories.svg\"\n",
    "plt.savefig(output, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_ratios = [10.90, 4.69, 0.67, 53.48, 1.61, 10.08, 23.70, 25.66, 5.72, 2.24, 6.93]\n",
    "mqtl_counts = []\n",
    "number_of_mqtl_studies = []\n",
    "mqtl_info = pd.read_csv(\"mqtl_counts.csv\")\n",
    "studies = pd.read_csv(\"../manuscript/stables/all_2203_studies.csv\")\n",
    "for cat in CATEGORY_NAMES:\n",
    "    paperid = studies[studies[cat.capitalize()]][\"PMCID\"].tolist()\n",
    "    current_mqtl = mqtl_info[mqtl_info[\"PMCID\"].isin(paperid)]\n",
    "    mqtl_counts.append(round(current_mqtl[\"mQTL\"].mean(), 2))\n",
    "    number_of_mqtl_studies.append(round(current_mqtl[current_mqtl[\"mQTL\"]>0].shape[0] / len(paperid), 2)*100)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(enrichment_ratios, mqtl_counts, c=COLOR_TEMPLATE, s=100)\n",
    "plt.xlabel(\"Enrichment Ratio\", fontsize=18)\n",
    "plt.ylabel(\"Average mQTL Count\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# axes[j].scatter(df[\"Enrichment Ratio\"], df[\"mQTL\"], c=COLOR_TEMPLATE[j])\n",
    "# axes[j].set_xlabel(\"Enrichment Ratio\", fontsize=18)\n",
    "# axes[j].set_ylabel(\"Average mQTL Count\", fontsize=18) \n",
    "# axes[j].set_title(f\"{current_category.capitalize()}\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(enrichment_ratios, number_of_mqtl_studies, c=COLOR_TEMPLATE, s=100)\n",
    "plt.xlabel(\"Enrichment Ratio\", fontsize=18)\n",
    "plt.ylabel(\"Percentage of Studies mentioning mQTL (%)\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"categories/probe/neurological_all_probes.csv\")\n",
    "df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [y.strip() for y in x.split(\"|\")])\n",
    "adhd_studies = set(df[df[\"Filtered Mesh Term\"].apply(lambda x: \"Attention Deficit Disorder with Hyperactivity\" in x)][\"pmcid\"].tolist())\n",
    "set(df[df[\"probeId\"].isin(corsiv_control_probes[\"probeId\"])][\"pmcid\"].tolist()).intersection(adhd_studies)\n",
    "# adhd_studies.difference(set(df[df[\"probeId\"].isin(corsiv_control_probes[\"probeId\"])][\"pmcid\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_categories = df[(df[\"Enrichment Ratio\"] > 1) & (df[\"Total Number of Papers\"]>= 20) & (df[\"Highest Number of Papers\"] > 1)].index.tolist()\n",
    "for catname in export_categories:\n",
    "    to_export_df = neuro_df[neuro_df[\"Filtered Mesh Term\"].apply(lambda x: catname in x)]\n",
    "    to_export_df.to_csv(f\"../permutation_testing/pt/{current_category}/{catname}_probes.csv\", index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of highest vs total papers\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(df[\"Total Number of Papers\"], df[\"Highest Number of Papers\"], \n",
    "           c=df[\"Enrichment Ratio\"].apply(lambda x: COLOR_TEMPLATE[target_idx] if x > 1 else \"grey\"),\n",
    "           alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Total Number of Papers Reporting a Probe\", fontsize=12)\n",
    "plt.ylabel(\"Highest Number of Papers Reporting a Probe\", fontsize=12)\n",
    "\n",
    "# Add 1:1 reference line\n",
    "max_val = max(df[\"Total Number of Papers\"].max(), df[\"Highest Number of Papers\"].max())\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 10)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{SFIG_PATH}/{current_category}/highest_vs_total_papers.jpeg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4A: neurological mesh hierarchy\n",
    "from graphviz import Digraph\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def visualize(input_nodes, output_name=None, format=\"svg\", target=\"Enrichment Ratio\"):\n",
    "    input_nodes = {x for y in input_nodes for x in mesh_ttoc[y]}\n",
    "    dot = Digraph()\n",
    "    dot.attr(rankdir='LR')  # Keep layout horizontal (Left-to-Right)\n",
    "\n",
    "    edges = set()\n",
    "    nodes = {}\n",
    "    \n",
    "    for code in input_nodes:\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts) + 1):\n",
    "            partial_code = '.'.join(parts[:i])\n",
    "            if partial_code not in nodes and partial_code in mesh_ctot and any(partial_code.startswith(c) for k in keywords for c in mesh_ttoc[k]):\n",
    "                nodes[partial_code] = mesh_ctot[partial_code]\n",
    "    def add_code_edges(code):\n",
    "        parts = code.split('.')\n",
    "        for i in range(1, len(parts)):\n",
    "            parent_code = '.'.join(parts[:i])\n",
    "            child_code = '.'.join(parts[:i+1])\n",
    "            if parent_code in nodes and child_code in nodes:\n",
    "                edges.add((parent_code, child_code))\n",
    "            \n",
    "    def get_node_color(node):\n",
    "        term = nodes[node]\n",
    "        if term not in df.index:\n",
    "            return \"#FFFFFF\"  # White for nodes not in df\n",
    "        \n",
    "        highest_papers = df.loc[term, 'Highest Number of Papers']\n",
    "        enrichment_ratio = df.loc[term, 'Enrichment Ratio']\n",
    "        \n",
    "        if enrichment_ratio < 1 or highest_papers < 2:\n",
    "            return \"#FFFFFF\"  # White for nodes with low papers or enrichment\n",
    "        \n",
    "        color_rgb = mcolors.to_rgb(COLOR_TEMPLATE[target_idx])\n",
    "        intensity = min(1, df.loc[term, target] / df[target].max())\n",
    "        scaled_color = tuple(1 - (1 - c) * intensity for c in color_rgb)  # Invert intensity calculation\n",
    "        return mcolors.to_hex(scaled_color)\n",
    "\n",
    "    \n",
    "    for code, term in nodes.items():\n",
    "        add_code_edges(code)  # Add edges between parent and child nodes\n",
    "    if current_category == \"neurological\":\n",
    "        nodes[\"N\"] = \"Neurological\" \n",
    "        edges.add((\"N\", \"F03\"))\n",
    "        edges.add((\"N\", \"C10\"))\n",
    "    # Add nodes for each unique code with term name as label\n",
    "    for code, term in nodes.items():\n",
    "        node_color = get_node_color(code)\n",
    "        if term in df.index:\n",
    "            custom_label = f\"{term} ({df.loc[term, 'Total Number of Papers']})\"\n",
    "        else:\n",
    "            custom_label = term\n",
    "        dot.node(code, label=custom_label, shape='box', style='filled', fillcolor=node_color, fontname='Helvetica')\n",
    "    for parent_code, child_code in edges:\n",
    "        dot.edge(parent_code, child_code)\n",
    "\n",
    "    dot.attr(concentrate='true', splines='ortho')\n",
    "    dot.attr(nodesep='0.2', ranksep='0.5')\n",
    "    \n",
    "    # Create color legend\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [\"white\", COLOR_TEMPLATE[target_idx]])\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=df[target].max())\n",
    "    cb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "                      cax=ax, orientation='horizontal', label=target)\n",
    "    \n",
    "    # Save legend as separate image\n",
    "    \n",
    "    legend_path =f\"{SFIG_PATH}/hierarchy_plots/{current_category}_legend.svg\"\n",
    "    plt.savefig(legend_path, bbox_inches='tight')\n",
    "\n",
    "    if output_name:\n",
    "        dot.render(output_name, format=format, cleanup=True)\n",
    "    else:\n",
    "        dot.view()\n",
    "    return nodes\n",
    "\n",
    "minimum_papers = 20\n",
    "output_name = f\"{SFIG_PATH}/hierarchy_plots/{current_category}_hierarchy_{minimum_papers}_papers\" if minimum_papers > 0 else f\"{SFIG_PATH}/hierarchy_plots/{current_category}_full_hierarchy\"\n",
    "# Modify the visualize function call to adjust edge routing\n",
    "tmp = {key:count for key, count in mesh_count_by_study.items() if count >= minimum_papers}\n",
    "\n",
    "nodes = visualize(tmp.keys(), output_name=None, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "manual = pd.read_csv(\"pubmed_search/archive/adhd_test/probes/all_ADHD_probes.csv\")\n",
    "manual = manual[manual[\"probeId\"].str.startswith(\"cg\") | manual[\"probeId\"].str.startswith(\"ch.\")]\n",
    "manual = manual[manual[\"probeId\"].isin(epic_probe_list) | manual[\"probeId\"].isin(hm450_probe_list)]\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if x == \"<0.05\":\n",
    "            return 0.049\n",
    "        if x == \"pass\":\n",
    "            return 0.049\n",
    "        if x == \"not pass\" or x == \" \":\n",
    "            return math.nan\n",
    "        if x == \"> 0.1\":\n",
    "            return 0.11\n",
    "        elif x == \"≤ 0.1\":\n",
    "            return 0.09\n",
    "        elif x == \"≤ 0.05\":\n",
    "            return 0.049\n",
    "        elif x == \"≤0.01\":\n",
    "            return 0.009\n",
    "        return x\n",
    "manual[\"p-value\"] = manual[\"p-value\"].str.replace(\"−\", \"-\").str.replace(\"‐\", \"-\").str.replace(\"–\", \"-\").str.replace(\" × E\", \"e\").apply(to_float)\n",
    "manual[\"q-value\"] = manual[\"q-value\"].str.replace(\"−\", \"-\").str.replace(\"‐\", \"-\").str.replace(\"–\", \"-\").str.replace(\" × E\", \"e\").apply(to_float)\n",
    "manual[\"adj-p-value\"] = manual[\"adj-p-value\"].str.replace(\"−\", \"-\").str.replace(\"‐\", \"-\").str.replace(\"–\", \"-\").str.replace(\" × E\", \"e\").apply(to_float)\n",
    "manual = manual.groupby(['pmcid', 'From']).filter(lambda x: len(x) <= 1000)\n",
    "\n",
    "\n",
    "keep = pd.read_csv(\"pubmed_search/archive/adhd_test/probes/all_ADHD_source.csv\")\n",
    "manual = pd.merge(manual, keep, on=[\"pmcid\", \"Notes\", \"From\", \"Title\"])\n",
    "manual = manual[manual[\"Keep1\"]==1]\n",
    "manual = manual[(manual[\"p-value\"] < 0.05)]\n",
    "\n",
    "# manual = manual[(manual[\"q-value\"] < 0.05) | (manual[\"adj-p-value\"] < 0.05) | (manual[\"p-value\"] < 1e-5)]\n",
    "manual = manual.drop_duplicates(subset=[\"pmcid\", \"probeId\"])\n",
    "print(manual.shape)\n",
    "c = Counter(manual[\"probeId\"])\n",
    "l1, l2, l3, p, p2 = calculate_points(c, manual)\n",
    "output_path = f\"{SFIG_PATH}/adhd_manual_enrichment.svg\"\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], \"ADHD (Manual)\", 7, output=None, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "manual = pd.read_csv(\"pubmed_search/adhd_test/probes/all_ADHD_probes_uptodate.csv\")\n",
    "manual = manual[manual[\"probeId\"].str.startswith(\"cg\") | manual[\"probeId\"].str.startswith(\"ch.\")]\n",
    "manual = manual[manual[\"probeId\"].isin(epic_probe_list) | manual[\"probeId\"].isin(hm450_probe_list)]\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if x == \"<0.05\":\n",
    "            return 0.049\n",
    "        if x == \"pass\":\n",
    "            return 0.049\n",
    "        if x == \"not pass\" or x == \" \":\n",
    "            return math.nan\n",
    "        if x == \"> 0.1\":\n",
    "            return 0.11\n",
    "        elif x == \"≤ 0.1\":\n",
    "            return 0.09\n",
    "        elif x == \"≤ 0.05\":\n",
    "            return 0.049\n",
    "        elif x == \"≤0.01\":\n",
    "            return 0.009\n",
    "        return x\n",
    "manual[\"p-value\"] = manual[\"p-value\"].apply(to_float)\n",
    "manual[\"q-value\"] = manual[\"q-value\"].apply(to_float)\n",
    "manual[\"adj-p-value\"] = manual[\"adj-p-value\"].apply(to_float)\n",
    "manual = manual.groupby(['pmcid', 'From']).filter(lambda x: len(x) <= 1000)\n",
    "\n",
    "\n",
    "keep = pd.read_csv(\"pubmed_search/adhd_test/probes/all_ADHD_source_uptodate.csv\")\n",
    "manual = pd.merge(manual, keep, on=[\"pmcid\", \"Notes\", \"From\", \"Title\"])\n",
    "manual = manual[manual[\"Keep1\"]==1]\n",
    "manual = manual[(manual[\"p-value\"] < 0.05)]\n",
    "# manual = manual[(manual[\"q-value\"] < 0.05) | (manual[\"adj-p-value\"] < 0.05) | (manual[\"p-value\"] < 1e-5)]\n",
    "manual = manual.drop_duplicates(subset=[\"pmcid\", \"probeId\"])\n",
    "# manual[[\"pmcid\",\"probeId\"]].to_csv(\"../permutation_testing/adhd_manual_probes.csv\", index=False)\n",
    "c = Counter(manual[\"probeId\"])\n",
    "l1, l2, l3, p, p2 = calculate_points(c, manual)\n",
    "output_path = f\"{SFIG_PATH}/adhd_manual_enrichment_nominal.svg\"\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], \"ADHD (Nominally Significant)\", 7, output=output_path, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../permutation_testing/adhd_manual_probes.csv\")\n",
    "print(df.shape)\n",
    "c = Counter(df[\"probeId\"])\n",
    "l1, l2, l3, p, p2, _ = calculate_points(c, manual)\n",
    "output_path = f\"{SFIG_PATH}/adhd_manual_enrichment_nominal.svg\"\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2, _], \"ADHD (Manual)\", 7, output=output_path, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"probe/cancer_all_probes.csv\")\n",
    "df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "df = df[df[\"Filtered Mesh Term\"].apply(lambda x: \"Prostatic Neoplasms\" in x)]\n",
    "prostate_cancer_pmcids = df[\"pmcid\"].unique()\n",
    "mqtl_info = pd.read_csv(\"mqtl_counts.csv\")\n",
    "mqtl_info = mqtl_info[mqtl_info[\"PMCID\"].isin(prostate_cancer_pmcids)]\n",
    "questionable_mqtl_papers = mqtl_info[mqtl_info[\"mQTL\"] > 0][\"PMCID\"].unique()\n",
    "df = pd.read_csv(\"probe/cancer_all_probes.csv\")\n",
    "df = df[df[\"pmcid\"].isin(questionable_mqtl_papers)]\n",
    "df.groupby(\"pmcid\")[\"probeId\"].nunique()\n",
    "# df[df[\"pmcid\"] == \"PMC7145271\"]\n",
    "# df[df[\"pmcid\"] == \"PMC7145271\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"probe/metabolic_diseases_all_probes.csv\")\n",
    "df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "df = df[df[\"Filtered Mesh Term\"].apply(lambda x: \"Diabetes Mellitus, Type 2\" in x)]\n",
    "prostate_cancer_pmcids = df[\"pmcid\"].unique()\n",
    "mqtl_info = pd.read_csv(\"mqtl_counts.csv\")\n",
    "mqtl_info = mqtl_info[mqtl_info[\"PMCID\"].isin(prostate_cancer_pmcids)]\n",
    "questionable_mqtl_papers = mqtl_info[mqtl_info[\"mQTL\"] > 0][\"PMCID\"].unique()\n",
    "df = pd.read_csv(\"probe/metabolic_diseases_all_probes.csv\")\n",
    "df = df[df[\"pmcid\"].isin(questionable_mqtl_papers)]\n",
    "df.groupby(\"pmcid\")[\"probeId\"].nunique()\n",
    "# df[df[\"pmcid\"] == \"PMC7145271\"]\n",
    "# df[df[\"pmcid\"] == \"PMC7145271\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.read_csv(\"probe/metabolic_diseases_all_probes.csv\")\n",
    "cancer_df[\"Filtered Mesh Term\"] = cancer_df[\"Filtered Mesh Term\"].apply(eval)\n",
    "term = \"Diabetes Mellitus, Type 2\"\n",
    "cancer_df = cancer_df[cancer_df[\"Filtered Mesh Term\"].apply(lambda x: term in x)]\n",
    "cancer_df = cancer_df[~cancer_df[\"pmcid\"].isin([\"PMC4222689\", \"PMC4913906\"])]\n",
    "c = Counter(cancer_df[\"probeId\"])\n",
    "l1, l2, l3, p, p2,_ = calculate_points(c, \"metabolic\")\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], \"metabolic\", 0, output=None, show_figure=True, box_placement=(0.15, 0.9), show_y_label=True, format=\"svg\", show_legend=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5B: becon density plot\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "bins = [-1, 0, 1.0]\n",
    "\n",
    "idx = 1\n",
    "target_cols = [\"Mean Cor All Brain\", \"ICC\", \"iir1\"]\n",
    "fnames = [\"becon/becon_all_probes.csv\", \"iir_icc/Flanagan_icc_results.csv\", \"iir_icc/Flanagan_iir_results.csv\"]\n",
    "probe_cols = [\"CpG ID\", \"ID\", \"ID\"]\n",
    "xlabels = [\"Brain-Blood Correlation (BECon)\", \"Intraclass Correlation Coefficient (ICC)\", r\"IIR$_{2-98\\%}$\"]\n",
    "output_path = [\"becon\", \"icc\", \"iir\"]\n",
    "\n",
    "target_col = target_cols[idx]\n",
    "df = pd.read_csv(fnames[idx])\n",
    "colname = probe_cols[idx]\n",
    "regions = list(zip([\"Non-CoRSIV\", \"CoRSIV\"], [non_corsiv_baseline, CORSIV_PROBE_LIST]))\n",
    "xlabel = xlabels[idx]\n",
    "output_id = output_path[idx]\n",
    "\n",
    "# Create subplots with 3 rows and 4 columns\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "axes = axes.flatten()\n",
    "lst = [c for c in CATEGORY_NAMES if c != \"neurological\"] if idx == 0 else CATEGORY_NAMES\n",
    "# Plot for each category\n",
    "for cat_idx, catname in enumerate(lst):\n",
    "    ax = axes[cat_idx]\n",
    "    i = CATEGORY_NAMES.index(catname)\n",
    "\n",
    "    dfs_for_plot = []\n",
    "    max_papers = max(cat_probes_dict[i].values())\n",
    "    papers_threshold = 2\n",
    "    p = set(k for k, v in cat_probes_dict[i].items() if v >= papers_threshold)\n",
    "    \n",
    "    for rname, rset in regions:\n",
    "        probes_in_region = rset.intersection(p)\n",
    "        filtered_df = df[df[colname].isin(probes_in_region)]\n",
    "        dfs_for_plot.append((filtered_df, rname))\n",
    "\n",
    "    for j, (df_subset, rname) in enumerate(dfs_for_plot):\n",
    "        density = stats.gaussian_kde(df_subset[target_col])\n",
    "        xs = np.linspace(-1, 1, 200)\n",
    "        ys = density(xs)\n",
    "        color = COLOR_TEMPLATE[i] if rname == 'CoRSIV' else 'grey'\n",
    "        ax.plot(xs, ys, \"-\", color=color, label=rname, linewidth=3)\n",
    "        ax.fill_between(xs, ys, alpha=0.5, color=color)\n",
    "        peak_index = np.argmax(ys)\n",
    "        ax.text(xs[peak_index], ys[peak_index]+0.04, f\"{rname}\", fontsize=15, #\\n(n={len(df_subset):,})\n",
    "                verticalalignment='bottom', horizontalalignment='center',\n",
    "                color=color)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16, length=5)\n",
    "    if idx == 2:\n",
    "        ax.set_xticks([0, 0.5, 1.0])\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "    elif idx == 1:\n",
    "        ax.set_xticks([-1, -0.5, 0.0, 0.5, 1.0])\n",
    "    else:\n",
    "        ax.set_yticks([0, 1.0, 2.0])\n",
    "        ax.set_ylim(0, 2.5)\n",
    "        ax.set_xticks([-1, 0.0, 1.0])\n",
    "    ax.set_title(catname.capitalize(), \n",
    "                 fontsize=20, pad=10)\n",
    "ax = axes[10] if idx == 0 else axes[11]\n",
    "\n",
    "dfs_for_plot = []\n",
    "\n",
    "for rname, rset in regions:\n",
    "    filtered_df = df[df[colname].isin(rset)]\n",
    "    dfs_for_plot.append((filtered_df, rname))\n",
    "\n",
    "for j, (df_subset, rname) in enumerate(dfs_for_plot):\n",
    "    density = stats.gaussian_kde(df_subset[target_col])\n",
    "    xs = np.linspace(-1, 1, 200)\n",
    "    ys = density(xs)\n",
    "    color = 'black' if rname == 'CoRSIV' else 'grey'\n",
    "    ax.plot(xs, ys, \"-\", color=color, label=rname, linewidth=3)\n",
    "    ax.fill_between(xs, ys, alpha=0.5, color=color)\n",
    "    peak_index = np.argmax(ys)\n",
    "    ax.text(xs[peak_index], ys[peak_index]+0.04, f\"{rname}\", fontsize=15, #\\n(n={len(df_subset):,})\n",
    "            verticalalignment='bottom', horizontalalignment='center',\n",
    "            color=color)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16, length=5)\n",
    "if idx == 2:\n",
    "    ax.set_xticks([0, 0.5, 1.0])\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "elif idx == 1:\n",
    "    ax.set_xticks([-1, -0.5, 0.0, 0.5, 1.0])\n",
    "else:\n",
    "    ax.set_yticks([0, 1.0, 2.0])\n",
    "    ax.set_ylim(0, 2.5)\n",
    "    ax.set_xticks([-1, 0.0, 1.0])\n",
    "    \n",
    "ax.set_title(\"All Probes\", \n",
    "                fontsize=20, pad=10)\n",
    "if idx == 0:\n",
    "    # Remove the last (empty) subplot\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "# Add a vertical line\n",
    "x = 0\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.04, 0.5, 'Density', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0\n",
    "fig.add_artist(plt.Line2D([0.04, 0.98], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.04, xlabel, ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "output = f\"{SFIG_PATH}/{output_id}_kde_all_categories.svg\"\n",
    "plt.savefig(output, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5C: becon regression plots for all categories except neurological\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "non_corsiv_baseline = illumina - CORSIV_PROBE_LIST\n",
    "target_col = \"Mean Cor All Brain\"\n",
    "df = pd.read_csv(\"becon/becon_all_probes.csv\")\n",
    "regions = list(zip([\"CoRSIV\", \"Non-CoRSIV\"], [CORSIV_PROBE_LIST, non_corsiv_baseline]))\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 11))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Plot each category except neurological\n",
    "plot_idx = 0\n",
    "for cat in [\"cancer\", \"endocrine\", \"immune\", \"metabolic\", \"urogenital\"]:\n",
    "    cat_probes = read_in_probes(cat)\n",
    "    ax = axs[plot_idx]\n",
    "    max_papers = max(cat_probes.values())\n",
    "\n",
    "    for rname, rset in regions:\n",
    "        medians = []\n",
    "        paper_counts = []\n",
    "        for pidx in range(1, max_papers + 1):\n",
    "            p = set(k for k, v in cat_probes.items() if v == pidx)\n",
    "            probes_in_region = rset.intersection(p)\n",
    "            filtered_df = df[df[\"CpG ID\"].isin(probes_in_region)]\n",
    "            if len(filtered_df) < 15:\n",
    "                max_papers = pidx - 1\n",
    "                break\n",
    "            else:\n",
    "                medians.append(filtered_df[target_col].median())\n",
    "                paper_counts.append(pidx)\n",
    "        \n",
    "        X = np.array(medians)\n",
    "        y = np.array(paper_counts)\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "        color = COLOR_TEMPLATE[CATEGORY_NAMES.index(cat)] if rname == 'CoRSIV' else 'grey'\n",
    "        marker = 'D' if rname == 'CoRSIV' else 'o'\n",
    "        ax.scatter(X, y, color=color, label=rname, s=200, marker=marker)\n",
    "        ax.plot(X, model.predict(X_const), color=color, linestyle='--', linewidth=4, zorder=10, alpha=0.6)\n",
    "        r_squared = round(model.rsquared, 3)\n",
    "        slope = round(model.params[1], 3)\n",
    "        f_pvalue = round(model.f_pvalue, 3)\n",
    "        \n",
    "        annotation_text = f\"R² = {r_squared:.2f}\\nP = {f_pvalue:.2f}\"\n",
    "        \n",
    "        # Add annotation\n",
    "        ax.annotate(annotation_text, \n",
    "                    xy=(X[-1]-0.04, y[-1]/2),\n",
    "                    xytext=(10, 0), \n",
    "                    textcoords='offset points',\n",
    "                    color=color,\n",
    "                    fontsize=20,\n",
    "                    ha='left', \n",
    "                    va='center',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', fc='none', ec='none', alpha=1))\n",
    "\n",
    "    # ax.set_xlabel(\"Median Brain-Blood Correlation (BECon)\", fontsize=22)\n",
    "    # ax.set_ylabel('Number of Papers', fontsize=18)\n",
    "    ax.set_title(cat.capitalize(), fontsize=28, pad=15)\n",
    "    ax.set_xlim(-0.05, 0.6)\n",
    "    ax.set_xticks(np.arange(0.0, 0.7, 0.1))\n",
    "    ax.tick_params(axis='x', which='major', length=5)\n",
    "    ax.set_yticks(range(1, max_papers + 1))\n",
    "    ax.set_ylim(0, max_papers + 1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "axs[-1].axis('off')\n",
    "# Add legend to the last subplot\n",
    "handles = [plt.Line2D([0], [0], marker='D', color='w', markerfacecolor=\"k\", \n",
    "                      label=\"CoRSIV\", markersize=15)]\n",
    "handles.append(plt.Line2D([0], [0], marker='o', color='w', label='Control', markersize=20, markerfacecolor='grey'))\n",
    "\n",
    "axs[-1].legend(handles=handles, loc='center', fontsize=24, frameon=False)\n",
    "\n",
    "x = 0\n",
    "fig.add_artist(plt.Line2D([x, x], [0.06,0.94], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "fig.text(x-0.04, 0.5, 'Number of Papers', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "# Add a horizontal line\n",
    "y = 0\n",
    "fig.add_artist(plt.Line2D([0.04, 0.96], [y, y], transform=fig.transFigure, color='black', linestyle='-', linewidth=2))\n",
    "# Add vertical text to the left of the vertical line\n",
    "fig.text(0.5, y-0.04, \"Median Brain-Blood Correlation (BECon)\", ha='center', rotation='horizontal', fontsize=24)\n",
    "plt.tight_layout()\n",
    "\n",
    "output = f\"{SFIG_PATH}/becon_regression_all_categories.svg\"\n",
    "plt.savefig(output, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_csv(\"../permutation_testing/adhd_manual_probes.csv\")\n",
    "automtated = pd.read_csv(\"probe/neurological_all_probes.csv\")\n",
    "automtated[\"Filtered Mesh Term\"] = automtated[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "automtated = automtated[automtated[\"Filtered Mesh Term\"].apply(lambda x: \"Attention Deficit Disorder with Hyperactivity\" in x)][[\"pmcid\", \"probeId\"]]\n",
    "# print(manual.shape, automtated.shape)\n",
    "# print(set(automtated[\"pmcid\"].unique()) - set(manual[\"pmcid\"].unique()))\n",
    "m = pd.merge(manual, automtated, how=\"outer\", indicator=True)\n",
    "# Create counts for Venn diagram\n",
    "left_only = len(m[m['_merge'] == 'left_only'])\n",
    "right_only = len(m[m['_merge'] == 'right_only']) \n",
    "both = len(m[m['_merge'] == 'both'])\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "# Create and plot Venn diagram\n",
    "plt.figure(figsize=(8,8))\n",
    "venn2(subsets=(left_only, right_only, both), \n",
    "      set_labels=('Manual', 'Automated'),\n",
    "      set_colors=('lightblue', 'lightgreen'))\n",
    "plt.title('Overlap between Manual and \\nAutomated Probe Instances', pad=20, fontsize=24)\n",
    "# plt.show()\n",
    "plt.savefig(f\"{SFIG_PATH}/venn_adhd.svg\", format=\"svg\")\n",
    "unique_to_automated = m[m[\"_merge\"] == \"right_only\"].iloc[:,0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_csv(\"pubmed_search/adhd_test/probes/all_ADHD_probes_uptodate.csv\")\n",
    "manual = manual[manual[\"probeId\"].str.startswith(\"cg\") | manual[\"probeId\"].str.startswith(\"ch.\")]\n",
    "manual = manual[manual[\"probeId\"].isin(epic_probe_list) | manual[\"probeId\"].isin(hm450_probe_list)]\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if x == \"<0.05\":\n",
    "            return 0.049\n",
    "        if x == \"pass\":\n",
    "            return 0.049\n",
    "        if x == \"not pass\" or x == \" \":\n",
    "            return math.nan\n",
    "        if x == \"> 0.1\":\n",
    "            return 0.11\n",
    "        elif x == \"≤ 0.1\":\n",
    "            return 0.09\n",
    "        elif x == \"≤ 0.05\":\n",
    "            return 0.049\n",
    "        elif x == \"≤0.01\":\n",
    "            return 0.009\n",
    "        return x\n",
    "manual[\"p-value\"] = manual[\"p-value\"].apply(to_float)\n",
    "manual[\"q-value\"] = manual[\"q-value\"].apply(to_float)\n",
    "manual[\"adj-p-value\"] = manual[\"adj-p-value\"].apply(to_float)\n",
    "keep = pd.read_csv(\"pubmed_search/adhd_test/probes/all_ADHD_source_uptodate.csv\")\n",
    "manual = pd.merge(manual, keep, on=[\"pmcid\", \"Notes\", \"From\", \"Title\"])\n",
    "# manual.drop_duplicates(subset=[\"pmcid\", \"probeId\"], inplace=True)\n",
    "\n",
    "qc = pd.merge(unique_to_automated, manual, on=[\"pmcid\", \"probeId\"], how=\"left\")\n",
    "# qc.to_csv(\"pubmed_search/adhd_test/probes/probes_unique_to_automated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_to_automated[unique_to_automated[\"pmcid\"]=='PMC5540511']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = pd.read_csv(\"pubmed_search/adhd_test/probes/probes_unique_to_automated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = pd.read_csv(\"pubmed_search/adhd_test/probes/probes_unique_to_automated.csv\").iloc[:,-3:]\n",
    "# Calculate total counts for each column\n",
    "excluded_count = qc['Excluded'].sum()\n",
    "nonsig_count = qc['Nonsignificant'].sum() \n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.pie([excluded_count, nonsig_count], \n",
    "        labels=[f'Excluded\\n({excluded_count} probes)', f'Not Significant\\n({nonsig_count} probes)'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#fbb4ae', '#b3cde3'])\n",
    "plt.title('Reasons for Probe Mismatch \\nBetween Automated and Manual Approaches')\n",
    "plt.savefig(f\"{SFIG_PATH}/probe_mismatch_reasons.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../permutation_testing/adhd_manual_probes.csv\")\n",
    "print(df.shape)\n",
    "c = Counter(df[\"probeId\"])\n",
    "l1, l2, l3, p, p2 = calculate_points(c, manual)\n",
    "paper, r = plot_enrichment([l1, l2, l3, p, p2], \"ADHD (Manual)\", 7, output=None, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from math import log10\n",
    "from statistics import mean\n",
    "from matplotlib import ticker\n",
    "\n",
    "def calculate_points(count_dictionary, input_cat):\n",
    "    paper_threshold_count = []\n",
    "    corsiv_count = []\n",
    "    control_count = []\n",
    "    corsiv_pct = []\n",
    "    control_pct = []\n",
    "    i = 1\n",
    "    if not count_dictionary:\n",
    "        return [], [], [], 0, 0\n",
    "    max_probe_count = max(count_dictionary.values())\n",
    "    probe_res_count = 0\n",
    "    corsiv_paper_set = set()\n",
    "    while i <= max_probe_count:\n",
    "        dummy_dict = {key:count for key, count in count_dictionary.items() if count == i}\n",
    "        logval = len(dummy_dict)\n",
    "        paper_threshold_count.append((i, logval))\n",
    "        i += 1\n",
    "    probe_cutoff = max_probe_count\n",
    "    for i in range(paper_threshold_count[-1][0], 0, -1):\n",
    "        if paper_threshold_count[i-1][1] < 10:\n",
    "            continue\n",
    "        probe_cutoff = i\n",
    "        break\n",
    "    paper_threshold_count = paper_threshold_count[:probe_cutoff]\n",
    "    i = 1\n",
    "    if isinstance(input_cat, str):\n",
    "        cat = \"metabolic_diseases\" if input_cat == \"metabolic\" else input_cat\n",
    "        df = pd.read_csv(f\"probe/{cat}_all_probes.csv\")\n",
    "    else:\n",
    "        df = input_cat\n",
    "    while i <= probe_cutoff:\n",
    "        dummy_dict = {key:count for key, count in count_dictionary.items() if count == i}\n",
    "        overlapping_probes = set(dummy_dict.keys()).intersection(CORSIV_PROBE_LIST)\n",
    "        corsiv_overlap_count = len(overlapping_probes)\n",
    "        corsiv_overlap = corsiv_overlap_count / len(dummy_dict) *100 if len(dummy_dict) > 0 else 0\n",
    "        corsiv_pct.append((i, corsiv_overlap))\n",
    "        corsiv_count.append((i, corsiv_overlap_count))\n",
    "        curr_control = []\n",
    "        curr_control_count = []\n",
    "        for control_set in CONTROLS:\n",
    "            control_overlap_count = len(set(dummy_dict.keys()).intersection(control_set))\n",
    "            control_overlap = control_overlap_count / len(dummy_dict) *100 if len(dummy_dict) > 0 else 0\n",
    "            curr_control.append(control_overlap)\n",
    "            curr_control_count.append(control_overlap_count)\n",
    "        control_pct.append((i, mean(curr_control)))\n",
    "        control_count.append((i, mean(curr_control_count)))\n",
    "        if corsiv_overlap > mean(curr_control):\n",
    "            probe_res_count += corsiv_overlap_count\n",
    "            corsiv_paper_set.update(df[df[\"probeId\"].isin(overlapping_probes)][\"pmcid\"].unique())\n",
    "        i += 1\n",
    "    return paper_threshold_count, corsiv_count, control_count, corsiv_pct, control_pct, probe_res_count, len(corsiv_paper_set)\n",
    "\n",
    "def plot_enrichment(counts, title_text, cat_index, output=None, show_ratio=True, format=\"svg\", show_legend=False, show_figure=True, show_y_label=True, box_placement=(0.15, 0.9), export_all=False):\n",
    "    if counts[0] == []:\n",
    "        return 0, 0\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[1, 2])\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax2 = fig.add_subplot(gs[1], sharex=ax1)     \n",
    "    \n",
    "    x_values, y_values = zip(*counts[0])\n",
    "    ax1.plot(x_values, y_values, marker='o', linestyle='-', color = COLOR_TEMPLATE[cat_index])\n",
    "    for x, y in zip(x_values, y_values):\n",
    "        ax1.annotate(f'{y:,}', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14)\n",
    "    ax1.set_title(title_text.capitalize() if \" \" not in title_text else title_text, fontsize=30)# .capitalize()\n",
    "    max_y = int(log10(max(y_values))) + 1\n",
    "    yticks = [10**i for i in range(1, max_y + 1)]\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_yticklabels([f'$10^{i}$' for i in range(1, max_y + 1)])\n",
    "    # ax1.yaxis.set_minor_locator(ticker.LogLocator(subs=range(2, 10)))\n",
    "    ax1.set_xticks(range(1, int(max(x_values))+1))\n",
    "    ax1.tick_params(axis='x', bottom=True, direction='inout', labelbottom=False, length=10)\n",
    "    ax1.tick_params(axis='y', which='both', left=True, labelleft=True)\n",
    "    x_values, y_values = zip(*counts[1])\n",
    "    x_values_, y_values_ = zip(*counts[5])\n",
    "    ax2.plot(x_values, y_values, marker='o', linestyle='-', color = COLOR_TEMPLATE[cat_index], label=\"CoRSIV\")\n",
    "    for i, (x, y) in enumerate(zip(x_values, y_values)):\n",
    "        # ax2.annotate(f'{y:.1f}%, {y_values_[i]:,} probes', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14)\n",
    "        ax2.annotate(f'{y:.1f}%', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14)\n",
    "        ax2.annotate(f'{y_values_[i]:,} probes', (x, y), textcoords=\"offset points\", xytext=(0,0), ha='center', fontsize=14)\n",
    "\n",
    "    x_values, y_values = zip(*counts[2])\n",
    "    x_values_, y_values_ = zip(*counts[6])\n",
    "    ax2.plot(x_values, y_values, marker='o', linestyle='-', color = \"grey\", label=\"Control\")\n",
    "    for i, (x, y) in enumerate(zip(x_values, y_values)):\n",
    "        # ax2.annotate(f'{y:.1f}%, {y_values_[i]:,} probes', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14)\n",
    "        ax2.annotate(f'{y:.2f}%' if y > 0.1 else f'{y:.3f}%', (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14)\n",
    "        ax2.annotate(f'{y_values_[i]:,} probes', (x, y), textcoords=\"offset points\", xytext=(0,0), ha='center', fontsize=14)    \n",
    "    ax2.set_xticks(range(1, int(max(x_values))+1))\n",
    "    ax2.set_xlabel('Number of Papers Reporting Probe', fontsize=18)\n",
    "    if show_y_label:\n",
    "        ax1.set_ylabel('Number of Probes', fontsize=16)\n",
    "        ax2.set_ylabel('Overlapping Probes (%)', fontsize=16)\n",
    "        ax2.tick_params(axis='y', labelsize=18)\n",
    "    ax2.tick_params(axis='x', which='both', bottom=True, labelbottom=True, labelsize=18)\n",
    "    if not show_y_label:\n",
    "        decimals = 1 if any(tick % 1 != 0 for tick in ax2.get_yticks()) else 0\n",
    "        ax2.yaxis.set_major_formatter(ticker.PercentFormatter(decimals=decimals))\n",
    "    enrichment_ratio = 0\n",
    "    if show_ratio:\n",
    "        corsiv_ratio = sum([i*pct for i, pct in counts[1]])\n",
    "        control_ratio = sum([i*pct for i, pct in counts[2]])\n",
    "        enrichment_ratio = round(corsiv_ratio / control_ratio, 1) if control_ratio != 0 else -1\n",
    "        middle_text = f\"Ratio = {enrichment_ratio}\\n{counts[3]:,} Probes\\n{counts[4]:,} Papers\" if enrichment_ratio > 1 else \"No Enrichment\"\n",
    "        \n",
    "        ax2.annotate(middle_text,\n",
    "                    xy=box_placement,  # Adjust position to account for bbox size\n",
    "                    xycoords='axes fraction',  # Use axes fraction for coordinates\n",
    "                    ha='center',  # Center the text horizontally\n",
    "                    va='top',     # Align text to the top of the box\n",
    "                    fontsize=16,  # Font size\n",
    "                    color=\"red\",\n",
    "                    bbox=dict(facecolor='white', edgecolor='red', linewidth=2, boxstyle='square,pad=0.5'))  # Add thicker square box around text\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    \n",
    "    if show_legend:\n",
    "        ax2.legend(bbox_to_anchor=(0.35, 0.5), shadow=False, frameon=False)\n",
    "\n",
    "    if output is None:\n",
    "        if show_figure:\n",
    "            plt.show() \n",
    "    else:\n",
    "        if export_all or (enrichment_ratio > 1 and len(counts[0]) > 1):\n",
    "            fig.savefig(output, format=format, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return len(counts[0]), enrichment_ratio\n",
    "total_probe, c1count, c2count, c1pct, c2pct, p, p2 = calculate_points(c, df)\n",
    "output = f\"{SFIG_PATH}/annotated_example.svg\"\n",
    "paper, r = plot_enrichment([total_probe, c1pct, c2pct, p, p2, c1count, c2count], \"Neurodevelopmental Disorders\", 6, output=output, show_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Initialize an empty dictionary to store the results\n",
    "mesh_ttoc = defaultdict(set) #term:code\n",
    "\n",
    "mesh_tree = {} #big category:set of subcategories\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_ttoc[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "            \n",
    "mesh_ctot =  {v:k for k, vs in mesh_ttoc.items() for v in vs} #code:term\n",
    "\n",
    "\n",
    "def next_layer(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix) and len(given_string) > len(prefix) and given_string[len(prefix)] == '.' and '.' not in given_string[len(prefix)+1:]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# keywords = [\"Endocrine System Diseases\"]\n",
    "keywords = [cc for c in CATEGORIES for cc in c]\n",
    "\n",
    "for kw in keywords:\n",
    "    mesh_tree[kw] = set([k for k, v in mesh_ttoc.items() for c in v if next_layer(c, mesh_ttoc[kw])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "for key_category in CATEGORY_NAMES:\n",
    "    if key_category == \"metabolic\":\n",
    "        df = pd.read_csv(\"probe/metabolic_diseases_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"probe/{key_category}_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    target_categories = set([])\n",
    "    for c in CATEGORIES[CATEGORY_NAMES.index(key_category)]:\n",
    "        target_categories |= mesh_tree[c]\n",
    "    df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term for term in x if term in target_categories])\n",
    "    c = Counter(df[\"probeId\"])\n",
    "    c = {k:v for k, v in c.items() if v >= 2 and k in CORSIV_PROBE_LIST}\n",
    "    df = df[df[\"probeId\"].isin(c)]\n",
    "    # categories = list(set([term for terms in df[\"Filtered Mesh Term\"] for term in terms]))\n",
    "    # probes = list(set(df[\"probeId\"].unique()))\n",
    "    affiliations = [(row['probeId'], term) \n",
    "                        for _, row in df.iterrows()\n",
    "                        for term in row['Filtered Mesh Term']]\n",
    "\n",
    "    nodes = list(set([aff[0] for aff in affiliations] + [aff[1] for aff in affiliations]))\n",
    "    node_indices = {node: i for i, node in enumerate(nodes)}\n",
    "    links = {\n",
    "        'source': [node_indices[aff[0]] for aff in affiliations],  # Student indices\n",
    "        'target': [node_indices[aff[1]] for aff in affiliations],  # Group indices\n",
    "        'value': [1 for _ in affiliations]  # All links have equal weight (1)\n",
    "    }\n",
    "\n",
    "    # Define the Sankey diagram\n",
    "    fig = go.Figure(go.Sankey(\n",
    "            node=dict(\n",
    "                pad=15,\n",
    "                thickness=20,\n",
    "                line=dict(color=\"black\", width=0.5),\n",
    "                label=nodes\n",
    "            ),\n",
    "            link=dict(\n",
    "                source=links['source'],\n",
    "                target=links['target'],\n",
    "                value=links['value']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout and display\n",
    "    fig.update_layout(title_text=key_category.capitalize(), font_size=10, width=1000, height=2000)\n",
    "    fig.write_html(f\"{SFIG_PATH}/alluvial/{key_category}.html\")\n",
    "    # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "dfs2 = []\n",
    "for key_category in [\"metabolic\", \"endocrine\"]:\n",
    "    if key_category == \"metabolic\":\n",
    "        df = pd.read_csv(\"probe/metabolic_diseases_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(eval)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"probe/{key_category}_all_probes.csv\")\n",
    "        df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])\n",
    "    target_categories = set([])\n",
    "    for c in CATEGORIES[CATEGORY_NAMES.index(key_category)]:\n",
    "        target_categories |= mesh_tree[c]\n",
    "    df[\"Filtered Mesh Term\"] = df[\"Filtered Mesh Term\"].apply(lambda x: [term for term in x if term in target_categories])\n",
    "    c = Counter(df[\"probeId\"])\n",
    "    c = {k:v for k, v in c.items() if v <= 5 and v >= 2 and k in CORSIV_PROBE_LIST}\n",
    "    df = df[df[\"probeId\"].isin(c)]\n",
    "    df = df.explode('Filtered Mesh Term')\n",
    "    dfs2.append(df)\n",
    "    df_pivoted = df.groupby(['probeId', 'Filtered Mesh Term']).size().reset_index(name='count')\n",
    "    df_pivoted = df_pivoted.pivot(index='probeId', columns='Filtered Mesh Term', values='count').fillna(0)\n",
    "    df_pivoted.rename_axis(index=None, columns=None, inplace=True)\n",
    "    dfs2.append(df_pivoted)\n",
    "    colors = [(1, 1, 1),\n",
    "            (0, 0, 1)]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_blue\", colors, N=100)\n",
    "    g = sns.clustermap(df_pivoted, method='ward', metric='euclidean', cmap=cmap, figsize=(8, 6), annot=False, vmax=5)\n",
    "    cbar = g.ax_heatmap.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 5])\n",
    "    cbar.set_ticklabels(['0', '5'])\n",
    "    g.ax_row_dendrogram.set_visible(False)\n",
    "    for line in g.ax_col_dendrogram.collections:\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    cbar.set_label(\"Number of \\nPapers\", rotation=90, fontsize=16)\n",
    "    g.ax_heatmap.set_yticks([])\n",
    "    g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=90, ha='center', va='top', fontsize=20)\n",
    "    g.ax_heatmap.tick_params(axis='x', which='major', pad=10)\n",
    "    g.figure.suptitle(f\"{len(df_pivoted):,} CoRSIV Probes Reported in ≥2 {key_category.capitalize()} Papers\", y=1.05, fontsize=26)\n",
    "    g.savefig(f\"{SFIG_PATH}/alluvial/{key_category}_subcategory_2papers.jpeg\", format=\"jpeg\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
