{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and main data files\n",
    "\n",
    "\"\"\"\n",
    "Initialization\n",
    "\"\"\"\n",
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from math import log10\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# constant, data\n",
    "os.chdir(\"/Users/antata/Library/CloudStorage/OneDrive-BaylorCollegeofMedicine/text-mining/categories/\")\n",
    "category_names = [\"obesity\", \"cancer\", \"cardiovascular\", \"digestive\", \"endocrine\", \"hematological\", \"immune\", \"metabolic\", \"neurological\", \"urogenital\", \"respiratory\"]#, \"T2D\"]\n",
    "color_template = ['#800000','#e6194B','#f58231','#f3c300','#469990','#808000','#2f8e3b','#0db7dd','#4363d8','#911eb4','#f032e6']#, \"#000075\"]#'#8298e5'\n",
    "controls = []\n",
    "corsiv_probe_df = pd.read_csv(\"../control/corsiv_all_probes_id.txt\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probeId\", \"corsiv_start\", \"corsiv_end\", \"corsiv_id\"])\n",
    "corsiv_probe_list = set(corsiv_probe_df.iloc[:,3])\n",
    "for i in range(1, 11):\n",
    "    control_probe_df = pd.read_csv(f\"../control/control_probes_{i}.txt\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probeId\", \"_\", \"corsiv_start\", \"corsiv_end\", \"corsiv_id\"])\n",
    "    control_probe_list = set(control_probe_df.iloc[:,3])\n",
    "    controls.append(control_probe_list)\n",
    "control_probe_df = pd.read_csv(\"../control/control_all_probes_id.txt\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probeId\", \"id\"])\n",
    "control_probe_list = set(control_probe_df.iloc[:,3])\n",
    "\n",
    "epic = pd.read_csv(\"../humanData/database/EPIC.hg38.txt\", sep=\"\\t\", header=None)\n",
    "epic_probe_list = set(epic.iloc[:,3])\n",
    "hm450 = pd.read_csv(\"../humanData/database/HM450.hg38.txt\", sep=\"\\t\", header=None)\n",
    "hm450_probe_list = set(hm450.iloc[:,3])\n",
    "illumina = epic_probe_list.union(hm450_probe_list)\n",
    "enrichment_cutoff = (len(corsiv_probe_list) / len(illumina)*1.5)\n",
    "enrichment_cutoff\n",
    "epic_hm450_probe = pd.read_csv(\"../control/humanData/EPIC_HM450.clean.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probeId\"])\n",
    "corsiv_genes = pd.read_csv(\"../control/corsiv_all_genes.csv\")\n",
    "corsiv_genes = corsiv_genes[corsiv_genes[\"id\"].isin(corsiv_probe_df[\"corsiv_id\"])]\n",
    "corsiv_genes.fillna(\"\", inplace=True)\n",
    "control_genes = pd.read_csv(\"../control/control_all_genes.csv\")\n",
    "control_genes = control_genes[control_genes[\"id\"].isin(control_probe_df[\"id\"])]\n",
    "control_genes.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obesity\n",
      "Time for obesity code to run:  0.02238917350769043\n",
      "cancer\n",
      "Time for cancer code to run:  0.17228388786315918\n",
      "cardiovascular\n",
      "Time for cardiovascular code to run:  0.023622989654541016\n",
      "digestive\n",
      "Time for digestive code to run:  0.0371401309967041\n",
      "endocrine\n",
      "Time for endocrine code to run:  0.03746509552001953\n",
      "hematological\n",
      "Time for hematological code to run:  0.02130579948425293\n",
      "immune\n",
      "Time for immune code to run:  0.04654693603515625\n",
      "metabolic\n",
      "Time for metabolic code to run:  0.050930023193359375\n",
      "neurological\n",
      "Time for neurological code to run:  0.11426830291748047\n",
      "urogenital\n",
      "Time for urogenital code to run:  0.1017148494720459\n",
      "respiratory\n",
      "Time for respiratory code to run:  0.03491997718811035\n"
     ]
    }
   ],
   "source": [
    "# read in probes\n",
    "\n",
    "\"\"\"\n",
    "read all probes if combined file alrdy exists\n",
    "\"\"\"\n",
    "cat_probes_dict = []\n",
    "# valid_studies = pd.read_csv(\"pubmed_search/valid_studies.csv\")\n",
    "def read_in_probes(input_cat):\n",
    "    if input_cat == \"metabolic\":\n",
    "        df = pd.read_csv(f\"probe/metabolic_diseases_all_probes.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"probe/{input_cat}_all_probes.csv\")\n",
    "    df.drop_duplicates(subset=[\"pmcid\", \"probeId\"], inplace=True)\n",
    "    probe_list = df[\"probeId\"].to_list()\n",
    "    c = dict(Counter(probe_list))\n",
    "    return c\n",
    "\n",
    "\n",
    "for cat in category_names:\n",
    "    start = time.time()\n",
    "    print(cat)\n",
    "    # if cat != \"anthropometric\":\n",
    "    #     continue\n",
    "    c = read_in_probes(cat)\n",
    "    cat_probes_dict.append(c)\n",
    "    end = time.time()\n",
    "    print(f'Time for {cat} code to run: ', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "15\n",
      "4\n",
      "6\n",
      "7\n",
      "3\n",
      "7\n",
      "7\n",
      "13\n",
      "8\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for c in cat_corsiv_dict:\n",
    "    print(max(c.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "m = 0\n",
    "for c in cat_probes_dict:\n",
    "    m = max(m, max(c.values()))\n",
    "\n",
    "cat_col = []\n",
    "paper_threshold_col = []\n",
    "probes_num_col = []\n",
    "unique_probes_num_col = []\n",
    "probes_num_col2 = []\n",
    "ratio_col = []\n",
    "for i in range(1, m+1):\n",
    "    curr_probes_dict = []\n",
    "    for j, c in enumerate(cat_probes_dict):\n",
    "        c = {k:v for k, v in c.items() if v >= i}\n",
    "        cat_col.append(category_names[j])\n",
    "        probes_num_col.append(len(c))\n",
    "        curr_probes_dict.append(c)\n",
    "    df = pd.DataFrame(curr_probes_dict)\n",
    "    df = df.fillna(0).transpose()\n",
    "    df.columns = category_names\n",
    "    for j, c in enumerate(cat_probes_dict):\n",
    "        unique_probes = set(df[(df[category_names[j]] != 0) & (df.drop(columns=[category_names[j]]) == 0).all(axis=1)].index)\n",
    "        total_probes = set(df[(df[category_names[j]] != 0)].index)\n",
    "        probes_num_col2.append(len(total_probes))\n",
    "        unique_probes_num_col.append(len(unique_probes))\n",
    "        r = round(len(unique_probes) / len(total_probes), 3) if len(total_probes) > 0 else math.nan\n",
    "        ratio_col.append(r*100)\n",
    "    paper_threshold_col += [i] * len(category_names)\n",
    "# probes_num_col == probes_num_col2\n",
    "# print(len(cat_col), len(paper_threshold_col), len(probes_num_col), len(unique_probes_num_col), len(probes_num_col2), len(ratio_col))\n",
    "res = pd.DataFrame({\"Categories\":cat_col, \"paper num\":paper_threshold_col, \"Total probes\": probes_num_col, \"Unique probes\": unique_probes_num_col, \"ratio%\": ratio_col})\n",
    "res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming res is already defined with the relevant columns.\n",
    "# Create the figure and axis objects\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Loop over each category\n",
    "for i, cat in enumerate(category_names):\n",
    "    group = res[(res[\"Categories\"]==cat) & (~res[\"ratio%\"].isna())]\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Plot the line for each category, NaNs will break the line automatically\n",
    "    ax.plot(group[\"paper num\"], group[\"ratio%\"], label=category_names[i], marker=\"o\", color=color_template[i])\n",
    "\n",
    "    # Set y-axis range from 0 to 100% and bin at 20%\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_yticks(range(0, 101, 20))  # y-ticks at every 20%\n",
    "    ax.set_xticks(range(0, int(max(group[\"paper num\"]))+1, 5))\n",
    "\n",
    "    # Label the axes\n",
    "    ax.set_xlabel(\"Number of Papers Reporting Probes\")\n",
    "    ax.set_ylabel(\"Unique to All Probes Ratio (%)\")\n",
    "\n",
    "    # Add title\n",
    "    ax.set_title(category_names[i])\n",
    "\n",
    "    # Add legend\n",
    "    # ax.legend(title=\"Categories\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(f\"/Users/antata/Desktop/text-mining-figures/final/stats/{category_names[i]}_ratio.jpeg\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sys\n",
    "# sys.setrecursionlimit(100000)\n",
    "# go heatmap for all probes by category\n",
    "paper_threshold = 2\n",
    "heatmap_df = []\n",
    "\n",
    "for c in cat_probes_dict:\n",
    "    c = {k:v for k, v in c.items() if v >= paper_threshold}\n",
    "    heatmap_df.append(c)\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_df)\n",
    "heatmap_df = heatmap_df.fillna(0).transpose()\n",
    "heatmap_df.columns = category_names\n",
    "# gr = sns.light_palette(\"red\", as_cmap=True)\n",
    "# ax = sns.clustermap(heatmap_df, cmap=gr, cbar_kws=dict(ticks=[0, 10, 20, 30, 40, 50]), yticklabels=False)\n",
    "# plt.setp(ax.ax_heatmap.get_xticklabels(), rotation=45)# ax.cax.set_visible(False)\n",
    "# ax.figure.axes[-1].set_ylabel('Number of Papers')\n",
    "heatmap_df.to_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers_0107.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obesity</th>\n",
       "      <th>cancer</th>\n",
       "      <th>cardiovascular</th>\n",
       "      <th>digestive</th>\n",
       "      <th>endocrine</th>\n",
       "      <th>hematological</th>\n",
       "      <th>immune</th>\n",
       "      <th>metabolic</th>\n",
       "      <th>neurological</th>\n",
       "      <th>urogenital</th>\n",
       "      <th>respiratory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cg12484113</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg08548559</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg26663590</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg07136133</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg18120259</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg06247406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg24753760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg02065151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg10411339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg26413528</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234586 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            obesity  cancer  cardiovascular  digestive  endocrine  \\\n",
       "cg12484113      3.0     1.0             1.0        0.0        1.0   \n",
       "cg08548559      4.0     1.0             3.0        1.0        2.0   \n",
       "cg26663590      7.0     2.0             2.0        3.0        3.0   \n",
       "cg07136133      5.0     0.0             1.0        0.0        3.0   \n",
       "cg18120259      4.0     0.0             4.0        2.0        2.0   \n",
       "...             ...     ...             ...        ...        ...   \n",
       "cg06247406      0.0     0.0             0.0        0.0        0.0   \n",
       "cg24753760      0.0     0.0             0.0        0.0        0.0   \n",
       "cg02065151      0.0     0.0             0.0        0.0        0.0   \n",
       "cg10411339      0.0     0.0             0.0        0.0        0.0   \n",
       "cg26413528      0.0     0.0             0.0        0.0        0.0   \n",
       "\n",
       "            hematological  immune  metabolic  neurological  urogenital  \\\n",
       "cg12484113            0.0     0.0        1.0           0.0         0.0   \n",
       "cg08548559            0.0     1.0        2.0           2.0         0.0   \n",
       "cg26663590            1.0     1.0        4.0           2.0         0.0   \n",
       "cg07136133            0.0     0.0        3.0           0.0         2.0   \n",
       "cg18120259            0.0     1.0        5.0           2.0         3.0   \n",
       "...                   ...     ...        ...           ...         ...   \n",
       "cg06247406            0.0     0.0        0.0           0.0         0.0   \n",
       "cg24753760            0.0     0.0        0.0           0.0         0.0   \n",
       "cg02065151            0.0     0.0        0.0           0.0         0.0   \n",
       "cg10411339            0.0     0.0        0.0           0.0         0.0   \n",
       "cg26413528            0.0     0.0        0.0           0.0         0.0   \n",
       "\n",
       "            respiratory  \n",
       "cg12484113          0.0  \n",
       "cg08548559          2.0  \n",
       "cg26663590          2.0  \n",
       "cg07136133          0.0  \n",
       "cg18120259          0.0  \n",
       "...                 ...  \n",
       "cg06247406          1.0  \n",
       "cg24753760          1.0  \n",
       "cg02065151          1.0  \n",
       "cg10411339          1.0  \n",
       "cg26413528          1.0  \n",
       "\n",
       "[234586 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column stats\n",
    "def generate_stats(df, cat, verbal=True):\n",
    "    probe_nums = []\n",
    "    max_probes = []\n",
    "    for i in range(len(cat)):\n",
    "        curr_probes = df[df[cat[i]]>0]\n",
    "        if curr_probes.empty:\n",
    "            if verbal:\n",
    "                print(f\"{cat[i]}: No probes showing up in ≥ {paper_threshold} papers\")\n",
    "            else:\n",
    "                probe_nums.append(0)\n",
    "                max_probes.append(0)\n",
    "            continue\n",
    "        probe_num = curr_probes.shape[0]\n",
    "        max_probe = int(curr_probes.iloc[:, i].max())\n",
    "        if verbal:\n",
    "            print(f\"{cat[i]}: {probe_num} probes in ≥ {paper_threshold} papers, max number of papers: {max_probe} papers\")\n",
    "        else:\n",
    "            probe_nums.append(probe_num)\n",
    "            max_probes.append(max_probe)\n",
    "    if not verbal:           \n",
    "        stat_df = pd.DataFrame({\"Categories\": cat, \"Probe Nums\": probe_nums, \"Max paper\": max_probes})\n",
    "        return stat_df\n",
    "    return 0\n",
    "generate_stats(heatmap_df, category_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neurological categories\n",
    "\n",
    "# Initialize an empty dictionary to store the results\n",
    "mesh_map = defaultdict(set) #term:code\n",
    "mesh_tree = {} #big category:set of subcategories\n",
    "file_path = '../humanData/database/mtrees2024.txt'\n",
    "\n",
    "# Read the lines from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into A and B\n",
    "        parts = line.strip().split(';')\n",
    "        if len(parts) == 2:\n",
    "            term, code = parts\n",
    "            mesh_map[term].add(code)\n",
    "        else:\n",
    "            print(parts)\n",
    "            \n",
    "def starts_with_any(given_string, string_list):\n",
    "    for prefix in string_list:\n",
    "        if given_string.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_mesh_list(input):\n",
    "    return any(input in sublist for sublist in mesh_tree.values())\n",
    "\n",
    "keywords = [\"Mental Disorders\", \"Nervous System Diseases\"]\n",
    "\n",
    "for kw in keywords:\n",
    "    mesh_tree[kw] = set([k for k, v in mesh_map.items() for c in v if starts_with_any(c, mesh_map[kw])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurological_df = pd.read_csv(\"probe/neurological_all_probes.csv\")\n",
    "neurological_df[\"Filtered Mesh Term\"] = neurological_df[\"Filtered Mesh Term\"].apply(lambda x: [term.strip() for term in x.split(\"|\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "temp = neurological_df\n",
    "temp1 = temp.drop_duplicates(subset=\"pmcid\")\n",
    "mesh_count_by_study = defaultdict(int)\n",
    "mesh_terms = list(temp1[\"Filtered Mesh Term\"])\n",
    "pmcids = list(temp1[\"pmcid\"])\n",
    "term_pmcid_map = defaultdict(set)\n",
    "for i in range(len(mesh_terms)):\n",
    "    m = mesh_terms[i]\n",
    "    # terms = [term.strip() for term in m.split(\"|\")]\n",
    "    for t in m:\n",
    "        mesh_count_by_study[t] += 1\n",
    "        term_pmcid_map[t].add(pmcids[i])\n",
    "mesh_count_by_study = {key:count for key, count in mesh_count_by_study.items() if filter_mesh_list(key) and count >= 14}\n",
    "print(len(mesh_count_by_study))\n",
    "mesh_count_by_study = dict(sorted(mesh_count_by_study.items(), reverse=True))\n",
    "categories = list(mesh_count_by_study.keys())\n",
    "counts = list(mesh_count_by_study.values())\n",
    "# sig_categories = [\"Schizophrenia Spectrum and Other Psychotic Disorders\", \"Schizophrenia\", \"Neurologic Manifestations\", \"Neurobehavioral Manifestations\",\"Nervous System Diseases\",\"Mental Disorders\",\"Intellectual Disability\"]\n",
    "# Plotting the horizontal histogram\n",
    "plt.figure(figsize=(8,8))\n",
    "bars = plt.barh(categories, counts, color=color_template[8])\n",
    "for bar, value in zip(bars, counts):\n",
    "    plt.text(bar.get_width()+15, bar.get_y() + bar.get_height()/2, value, ha='center', va='center')\n",
    "plt.ylim(-0.5, len(categories))\n",
    "plt.xlabel('Number of Papers')\n",
    "plt.ylabel('MeSH Categories')\n",
    "plt.title('Distribution of Neurological Papers by MeSH Categories, papers ≥ 14')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"figures/cancer_paper_by_mesh_>=10.jpeg\", format=\"jpeg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# mesh_count_by_study = plot_categories(\"neurological\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_threshold = 3\n",
    "def get_neurological_probe(disease):\n",
    "    df_categorized = temp[temp[\"pmcid\"].isin(set().union(*[term_pmcid_map[d] for d in disease]))]\n",
    "    probe_list = df_categorized[\"probeId\"].to_list()\n",
    "    probe_list = [s for s in probe_list if (str(s).startswith(\"cg\") or str(s).startswith(\"ch.\"))]\n",
    "    c = Counter(probe_list)\n",
    "    c = {key:count for key, count in c.items() if (key in epic_probe_list) or (key in hm450_probe_list)}\n",
    "    c = {key:count for key, count in c.items() if count >= paper_threshold}\n",
    "    return c\n",
    "\n",
    "neuro_heatmap = []\n",
    "neuro_categories = list(mesh_count_by_study.keys())\n",
    "for term in neuro_categories:\n",
    "    probes = get_neurological_probe([term])\n",
    "    neuro_heatmap.append(probes)\n",
    "\n",
    "neuro_heatmap = pd.DataFrame(neuro_heatmap)\n",
    "neuro_heatmap = neuro_heatmap.fillna(0).transpose()\n",
    "neuro_heatmap.columns = neuro_categories\n",
    "neuro_heatmap\n",
    "# gr = sns.light_palette(\"red\", as_cmap=True)\n",
    "# ax = sns.clustermap(heatmap_df, cmap=gr, cbar_kws=dict(ticks=[0, 10, 20, 30, 40, 50]), yticklabels=False)\n",
    "# plt.setp(ax.ax_heatmap.get_xticklabels(), rotation=45)# ax.cax.set_visible(False)\n",
    "# ax.figure.axes[-1].set_ylabel('Number of Papers')\n",
    "neuro_heatmap.to_csv(f\"heatmap/neuro_probe_based_heatmap_{paper_threshold}papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_stats(neuro_heatmap, neuro_categories, False)\n",
    "df.sort_values(by=\"Probe Nums\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column stats\n",
    "df = generate_stats(neuro_heatmap, neuro_categories, False)\n",
    "target = df[(df[\"Probe Nums\"]>=10) & (df[\"Probe Nums\"]<= 300)][\"Categories\"] # & (df[\"Probe Nums\"]<= 300)\n",
    "target_df = neuro_heatmap[target]\n",
    "df_no_zero_rows = target_df[(target_df != 0).any(axis=1)]\n",
    "df_no_zero_rows.to_csv(\"heatmap/neuro_probe_based_heatmap_10-300probes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all genes related to corsivs that were covered on illumina\n",
    "corsiv_illumina_overlap = set(corsiv_probe_df[corsiv_probe_df[\"probeId\"].isin(hm450_probe_list) | corsiv_probe_df[\"probeId\"].isin(epic_probe_list)][\"corsiv_id\"])\n",
    "gene_names = corsiv_genes[corsiv_genes[\"id\"].isin(corsiv_illumina_overlap)][\"gene_name\"]\n",
    "res = []\n",
    "for names in gene_names:\n",
    "    names = names.split(\";\")\n",
    "    res += names\n",
    "corsiv_illumina_genes = set(res)\n",
    "corsiv_illumina_genes.discard('')\n",
    "# target_libraries = [\"Jensen_DISEASES\", \"DisGeNET\", \"GO_Biological_Process_2023\", \"Human_Phenotype_Ontology\"]\n",
    "# run_enrichr(corsiv_illumina_genes, 1, target_libraries, f\"go_probe/go_results/go_corsiv_illumina_overlap.csv\")\n",
    "\n",
    "# # get all genes related to control that were covered on illumina\n",
    "control_illumina_overlap = set(control_probe_df[control_probe_df[\"probeId\"].isin(hm450_probe_list) | control_probe_df[\"probeId\"].isin(epic_probe_list)][\"id\"])\n",
    "gene_names = control_genes[control_genes[\"id\"].isin(control_illumina_overlap)][\"gene_name\"]\n",
    "res = []\n",
    "for names in gene_names:\n",
    "    names = names.split(\";\")\n",
    "    res += names\n",
    "control_illumina_genes = set(res)\n",
    "control_illumina_genes.discard('')\n",
    "# target_libraries = [\"Jensen_DISEASES\", \"DisGeNET\", \"GO_Biological_Process_2023\", \"Human_Phenotype_Ontology\"]\n",
    "# run_enrichr(control_illumina_genes.union(corsiv_illumina_genes), 1, target_libraries, f\"go_probe/go_results/go_corsiv_control_illumina_overlap.csv\")\n",
    "background_genes = control_illumina_genes.union(corsiv_illumina_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corsiv_illumina_genes), len(control_illumina_genes), len(background_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "ref = pd.concat([e, hm])\n",
    "ref[\"Unique Gene\"] = ref[\"UCSC_RefGene_Name\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "ref.drop_duplicates(inplace=True)\n",
    "ref = ref[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"Unique Gene\"]]\n",
    "\n",
    "def group_probes_GREAT(cat):\n",
    "    df = pd.read_csv(f\"go_probe/{cat}_3papers_unique_all.txt\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probe_id\"])\n",
    "    df = ref[ref[\"Probe_ID\"].isin(df[\"probe_id\"])]\n",
    "    df = df.sort_values(by=['Probe_Start', 'Probe_End'])\n",
    "\n",
    "    chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "    df = df.sort_values(\n",
    "        by=['Probe_Chr', 'Probe_Start'],\n",
    "        key=lambda x: x.map(chr_order) if x.name == 'Probe_Chr' else x\n",
    "    )\n",
    "\n",
    "    # Assign a unique index to consecutive rows sharing the same Unique Gene\n",
    "    df['gene_group'] = ((df['Unique Gene'] != df['Unique Gene'].shift()) | (df['Probe_Chr'] != df['Probe_Chr'].shift())).cumsum()\n",
    "    grouped = df.groupby(\"gene_group\")\n",
    "    # # Aggregate the grouped data\n",
    "    df_grouped = grouped.agg({\n",
    "        'Probe_Chr': 'first',\n",
    "        'Probe_Start': 'min',\n",
    "        'Probe_End': 'max',\n",
    "        'Probe_ID': lambda x: ';'.join(x),\n",
    "        'Unique Gene': 'first',\n",
    "    })\n",
    "    df_grouped = df_grouped.reset_index(drop=True)\n",
    "    df_grouped = df_grouped.sort_values(\n",
    "        by=['Probe_Chr', 'Probe_Start'],\n",
    "        key=lambda x: x.map(chr_order) if x.name == 'Probe_Chr' else x\n",
    "    )\n",
    "    df_grouped[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\"]].to_csv(f\"go_probe/GREAT_{cat}.txt\", index=0, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in category_names:\n",
    "    group_probes_GREAT(cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, math\n",
    "\n",
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "ref = pd.concat([e, hm])\n",
    "ref.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "target_libraries = [\"Jensen_DISEASES\", \"DisGeNET\", \"GO_Biological_Process_2023\",  \"GWAS_Catalog_2023\", \"Human_Gene_Atlas\", \"Human_Phenotype_Ontology\"] #\"GO_Cellular_Component_2023\", \"GO_Molecular_Function_2023\",\n",
    "\n",
    "def get_gene_set(target_id, gene_num=None):\n",
    "    # if not gene_num:\n",
    "        # corsiv_overlap_probes = set(count_dictionary.keys()).intersection(corsiv_probe_list)\n",
    "        # corsivs = set(corsiv_probe_df[corsiv_probe_df[\"probeId\"].isin(corsiv_overlap_probes)][\"corsiv_id\"])\n",
    "    gene_names = corsiv_genes[corsiv_genes[\"id\"].isin(target_id)][\"gene_name\"]\n",
    "    res = []\n",
    "    for names in gene_names:\n",
    "        names = names.split(\";\")\n",
    "        res += names\n",
    "    res = set(res)\n",
    "    res.discard('')\n",
    "    return res, len(target_id)\n",
    "\n",
    "def get_gene_illumina(target_id):\n",
    "    tmp = ref[ref[\"Probe_ID\"].isin(target_id)]\n",
    "    res = []\n",
    "    for names in tmp[\"UCSC_RefGene_Name\"]:\n",
    "        if isinstance(names, float) and math.isnan(names):\n",
    "            continue\n",
    "        names = names.split(\";\")\n",
    "        res += names\n",
    "    res = set(res)\n",
    "    res.discard('')\n",
    "    return res, len(target_id)\n",
    "\n",
    "def run_enrichr(input_genes, pval=0.05, input_libraries=target_libraries, output_fp=None):\n",
    "    if len(input_genes) == 0:\n",
    "        return\n",
    "    # input genes\n",
    "    ENRICHR_URL = 'https://maayanlab.cloud/Enrichr/addList'\n",
    "    genes_str = '\\n'.join(input_genes)\n",
    "    description = 'Gene list for obesity'\n",
    "    payload = {\n",
    "        'list': (None, genes_str),\n",
    "        'description': (None, description)\n",
    "    }\n",
    "    response = requests.post(ENRICHR_URL, files=payload)\n",
    "    if not response.ok:\n",
    "        raise Exception('Error analyzing gene list')\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    # get results for each library\n",
    "    ENRICHR_URL = 'https://maayanlab.cloud/Enrichr/enrich'\n",
    "    query_string = '?userListId=%s&backgroundType=%s'\n",
    "    user_list_id = data[\"userListId\"]\n",
    "    res = []\n",
    "    for lib in input_libraries:\n",
    "        gene_set_library = lib\n",
    "        response = requests.get(\n",
    "            ENRICHR_URL + query_string % (user_list_id, gene_set_library)\n",
    "        )\n",
    "        if not response.ok:\n",
    "            raise Exception('Error fetching enrichment results')\n",
    "        data = json.loads(response.text)[lib]\n",
    "        data = [r for r in data if r[6]<pval]\n",
    "        temp = pd.DataFrame(data, columns=[\"Index\", \"Name\", \"P-value\", \"Odds Ratio\", \"Combined score\", \"Genes\", \"Adjusted p-value\", \"unknown1\", \"unknown2\"])\n",
    "        temp = temp[[\"Name\", \"P-value\", \"Adjusted p-value\", \"Odds Ratio\", \"Combined score\", \"Genes\"]]\n",
    "        temp[\"Adjusted p-value\"] = temp[\"Adjusted p-value\"].apply(lambda x: round_to_significant_figures(x, 3))\n",
    "        temp[\"Odds Ratio\"] = temp[\"Odds Ratio\"].apply(lambda x: round_to_significant_figures(x, 3))\n",
    "        temp[\"Combined score\"] = temp[\"Combined score\"].apply(lambda x: round_to_significant_figures(x, 3))\n",
    "        temp[\"P-value\"] = temp[\"P-value\"].apply(lambda x: round_to_significant_figures(x, 3))\n",
    "        temp[\"Genes\"] = temp[\"Genes\"].apply(lambda x: \"; \".join(x))\n",
    "        temp[\"Database\"] = lib\n",
    "        temp.sort_values(by=\"Adjusted p-value\", ascending=True, inplace=True)\n",
    "        res.append(temp)\n",
    "    result_df = pd.concat(res, ignore_index=True)\n",
    "\n",
    "    if output_fp:\n",
    "        result_df.to_csv(output_fp, index=0)\n",
    "    return result_df\n",
    "\n",
    "# import numpy as np\n",
    "def round_to_significant_figures(x, sig):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(x, sig-int(np.floor(np.log10(abs(x))))-1)\n",
    "    \n",
    "def run_enrichr_with_background(input_genes, background_genes, pval, input_libraries, output_fp=None):\n",
    "    base_url = \"https://maayanlab.cloud/speedrichr\"\n",
    "    description = ''\n",
    "    # input test gene list\n",
    "    res = requests.post(\n",
    "        base_url+'/api/addList',\n",
    "        files=dict(\n",
    "        list=(None, '\\n'.join(input_genes)),\n",
    "        description=(None, description),\n",
    "        )\n",
    "    )\n",
    "    if res.ok:\n",
    "        userlist_response = res.json()\n",
    "    else:\n",
    "        raise Exception(\"Error adding gene list.\")\n",
    "        \n",
    "    # input background gene list\n",
    "    res = requests.post(\n",
    "        base_url+'/api/addbackground',\n",
    "        data=dict(background='\\n'.join(background_genes)),\n",
    "    )\n",
    "\n",
    "    if res.ok:\n",
    "        background_response = res.json()\n",
    "    else:\n",
    "        raise Exception(\"Error adding background list.\")\n",
    "    result_df = []\n",
    "    # get enrichment results\n",
    "    for lib in input_libraries:\n",
    "        res = requests.post(\n",
    "                base_url+'/api/backgroundenrich',\n",
    "                data=dict(\n",
    "                userListId=userlist_response[\"userListId\"],\n",
    "                backgroundid=background_response[\"backgroundid\"],\n",
    "                backgroundType=lib,\n",
    "                )\n",
    "            )\n",
    "        if not res.ok:\n",
    "            raise Exception(\"Error analyzing data.\")\n",
    "        # else:\n",
    "            # print(f\"{lib} done.\")\n",
    "        data = json.loads(res.text)[lib]\n",
    "        data = [r for r in data if r[6]<pval]\n",
    "        temp = pd.DataFrame(data, columns=[\"Index\", \"Name\", \"P-value\", \"Odds Ratio\", \"Combined score\", \"Genes\", \"Adjusted p-value\", \"unknown1\", \"unknown2\"])\n",
    "        temp = temp[[\"Name\",\"P-value\", \"Odds Ratio\", \"Combined score\", \"Genes\", \"Adjusted p-value\", \"Genes\"]]\n",
    "        temp[\"Adjusted p-value\"] = temp[\"Adjusted p-value\"].apply(lambda x: round_to_significant_figures(x, 3))\n",
    "        temp[\"Genes\"] = temp[\"Genes\"].apply(lambda x: \"; \".join(x))\n",
    "        temp[\"Database\"] = lib\n",
    "        result_df.append(temp)\n",
    "    result_df = pd.concat(result_df, ignore_index=True)\n",
    "    if output_fp:\n",
    "        if not result_df.empty:\n",
    "            result_df.to_csv(output_fp, index=0)\n",
    "        else:\n",
    "            print(f\"No significant result for {output_fp}\")\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go on neuro probes\n",
    "# paper_threshold = 3\n",
    "cats =[]\n",
    "thresh = []\n",
    "gnum = []\n",
    "pnum = []\n",
    "for cat in neuro_categories:\n",
    "    target_category = cat\n",
    "    df = pd.read_csv(f\"heatmap/neuro_probe_based_heatmap_10-300probes.csv\", index_col=0)\n",
    "    if target_category not in df.columns:\n",
    "        continue\n",
    "    unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "\n",
    "    g, l = get_gene_illumina(unique_probes)\n",
    "    print(f\"{cat} ≥ {paper_threshold} papers: {len(g)} genes associated with {l} probes\")\n",
    "    cats.append(cat)\n",
    "    thresh.append(paper_threshold)\n",
    "    gnum.append(len(g))\n",
    "    pnum.append(l)\n",
    "    # run_enrichr(g, output_fp=f\"go_probe/go_results/{target_category}_all_{paper_threshold}papers_unique.csv\")\n",
    "output_df = pd.DataFrame({\"Categories\": cats, \"Paper cutoff\": thresh, \"Number of Genes\": gnum, \"Number of Unqiue Probes\": pnum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corsiv_probe_list), len(control_probe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heatmap/probe_based_heatmap_3papers.csv\", index_col=0)\n",
    "target_category=\"obesity\"\n",
    "df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "ddf = epic_hm450_probe[epic_hm450_probe['probeId'].isin(unique_probes)]\n",
    "ddf[ddf.duplicated(subset=\"probeId\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_threshold = 3\n",
    "df = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "# for cat in category_names:\n",
    "#     target_category = cat\n",
    "#     unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "#     l1 = len(unique_probes)\n",
    "#     l2 = len(unique_probes.intersection(corsiv_probe_list))\n",
    "#     print(cat, l1, l2, l2/l1)\n",
    "print(df[df.index.isin(corsiv_probe_list)].shape[0], df.shape[0])\n",
    "print(df[df.index.isin(corsiv_probe_list)].shape[0] / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_threshold = 3\n",
    "df = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "for cat in category_names:\n",
    "    target_category = cat\n",
    "    # all probes unique to each category\n",
    "    unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "    probe_output_df = epic_hm450_probe[epic_hm450_probe['probeId'].isin(unique_probes)]\n",
    "    unique_probes\n",
    "    print(len(unique_probes), probe_output_df.shape[0])\n",
    "    probe_output_df.to_csv(f\"go_probe/{target_category}_{paper_threshold}papers_unique_all.txt\", sep=\"\\t\", header=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go on probes\n",
    "paper_threshold = 1\n",
    "cats =[]\n",
    "thresh = []\n",
    "gnum = []\n",
    "pnum = []\n",
    "cnum = []\n",
    "df = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "for cat in category_names:\n",
    "    if cat != \"cancer\":\n",
    "        continue\n",
    "    target_category = cat\n",
    "    unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "    g, l = get_gene_illumina(unique_probes)   \n",
    "    cnum.append(len(set(corsiv_probe_df[corsiv_probe_df[\"probeId\"].isin(unique_probes)][\"corsiv_id\"])))\n",
    "    # print(f\"{cat} ≥ {paper_threshold} papers: {len(g)} genes associated with {l} probes\")\n",
    "    cats.append(cat)\n",
    "    thresh.append(paper_threshold)\n",
    "    gnum.append(len(g))\n",
    "    pnum.append(l)\n",
    "    run_enrichr(g, output_fp=f\"go_probe/go_results/manifest/{target_category}_all_{paper_threshold}papers_unique_0117.csv\")\n",
    "output_df = pd.DataFrame({\"Categories\": cats, \"Paper cutoff\": thresh, \"Number of Genes\": gnum, \"Number of Unique Probes\": pnum, \"Number of CoRSIVs\": cnum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Paper cutoff</th>\n",
       "      <th>Number of Genes</th>\n",
       "      <th>Number of Unique Probes</th>\n",
       "      <th>Number of CoRSIVs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>8162</td>\n",
       "      <td>18132</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories  Paper cutoff  Number of Genes  Number of Unique Probes  \\\n",
       "0     cancer             1             8162                    18132   \n",
       "\n",
       "   Number of CoRSIVs  \n",
       "0                152  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print genes for enrichr-kg web\n",
    "paper_threshold = 3\n",
    "target_category = \"neurological\"\n",
    "\n",
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "ref = pd.concat([e, hm])\n",
    "ref.drop_duplicates(inplace=True)\n",
    "\n",
    "df = pd.read_csv(f\"heatmap/probe_based_heatmap_{paper_threshold}papers.csv\", index_col=0)\n",
    "unique_probes = set(df[(df[target_category] != 0) & (df.drop(columns=[target_category]) == 0).all(axis=1)].index)\n",
    "g, l = get_gene_illumina(unique_probes)\n",
    "for gg in g:\n",
    "    print(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = [\"#ae3c60\",\"#f3d83c\", \"#df473c\",\"#f3c33c\",\"#255e79\",\"#267778\"]\n",
    "database_colors = dict(zip(target_libraries, color_map))\n",
    "database_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "paper_threshold = 3\n",
    "for category in category_names:\n",
    "    df = pd.read_csv(f\"go_probe/go_results/{category}_all_{paper_threshold}papers_unique.csv\")\n",
    "    df = df[(df[\"Database\"] == \"Jensen_DISEASES\") | (df[\"Database\"] == \"DisGeNET\")]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    # Group by Database and get top 10 terms for each\n",
    "    grouped = df.groupby('Database')\n",
    "    top_10_per_db = [group.nsmallest(10, 'Adjusted p-value') for _, group in grouped]\n",
    "\n",
    "    # Combine all top 10 lists and sort by adjusted p-value\n",
    "    combined_top = pd.concat(top_10_per_db).sort_values('Adjusted p-value')\n",
    "\n",
    "    # Calculate log of adjusted p-value\n",
    "    log_p = -np.log10(combined_top['Adjusted p-value'])\n",
    "\n",
    "    # Create a single figure\n",
    "    fig, ax = plt.subplots(figsize=(8, len(combined_top) * 0.3))\n",
    "    plt.rcParams['font.family'] = 'Helvetica'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # Create horizontal bar plot with color coding\n",
    "    bars = ax.barh(range(len(combined_top)), log_p, height=0.8, \n",
    "                color=[(*matplotlib.colors.to_rgb(database_colors[db]), 0.6) for db in combined_top['Database']])\n",
    "\n",
    "    # Add labels to the bars\n",
    "    for i, (_, row) in enumerate(combined_top.iterrows()):\n",
    "        ax.text(0.05, i, f\"{row['Name']}\", ha='left', va='center', fontsize=10)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_title(f'Top 10 Terms from Each Database - {category.capitalize()}')\n",
    "    ax.set_xlabel('-log10(Adjusted P-value)')\n",
    "    ax.set_yticks(range(len(combined_top)))\n",
    "    ax.set_yticklabels(combined_top['Database'])  # Set database names as y-axis labels\n",
    "    ax.invert_yaxis()  # Invert y-axis to show highest significance at the top\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"/Users/antata/Desktop/text-mining-figures/final/go/{category}_{paper_threshold}papers_all_databases.jpeg\", format=\"jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category = \"neurological\"\n",
    "df = pd.read_csv(f\"go_probe/go_results/{category}_all_3papers_unique.csv\")\n",
    "\n",
    "\n",
    "# Group by Database and sort within each group by adjusted p-value\n",
    "grouped = df.groupby('Database')\n",
    "\n",
    "fig, axs = plt.subplots(len(grouped), 1, figsize=(12, 6*len(grouped)), squeeze=False)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, (database, group) in enumerate(grouped):\n",
    "    # Sort by adjusted p-value and get top 10\n",
    "    top_10 = group.sort_values('Adjusted p-value').head(10)\n",
    "    \n",
    "    # Calculate log of adjusted p-value\n",
    "    log_p = -np.log10(top_10['Adjusted p-value'])\n",
    "    \n",
    "    # Create horizontal bar plot\n",
    "    bars = axs[i].barh(top_10['Name'], log_p)\n",
    "    \n",
    "    # Add labels to the bars\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        axs[i].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.2f}', ha='left', va='center')\n",
    "    \n",
    "    # Customize the plot\n",
    "    axs[i].set_title(f'Top 10 Terms for {database}')\n",
    "    axs[i].set_xlabel('-log10(Adjusted P-value)')\n",
    "    axs[i].invert_yaxis()  # Invert y-axis to show highest significance at the top\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = pd.read_csv(\"../humanData/humanmethylation450_15017482_v1-2.csv\", skiprows=7)\n",
    "hm = hm[hm[\"IlmnID\"].isin(hm450_probe_list)]\n",
    "assert len(set(hm[\"IlmnID\"])) == hm.shape[0]\n",
    "hm = hm[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Accession',\n",
    "       'UCSC_RefGene_Group', 'UCSC_CpG_Islands_Name',\n",
    "       'Relation_to_UCSC_CpG_Island']]\n",
    "hm2 = pd.read_csv(\"../humanData/database/HM450.hg38.txt\", sep=\"\\t\", names=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\"])\n",
    "m = pd.merge(hm, hm2, left_on=\"Name\", right_on=\"Probe_ID\")\n",
    "assert m.shape[0] == hm2.shape[0]\n",
    "m = m[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"UCSC_RefGene_Name\", \"UCSC_RefGene_Group\"]]\n",
    "m.to_csv(\"../humanData/HM450_manifest_cleaned.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pd.read_csv(\"../humanData/infinium-methylationepic-v-1-0-b5-manifest-file.csv\", skiprows=7)\n",
    "e = e[e[\"IlmnID\"].isin(epic_probe_list)]\n",
    "assert len(set(e[\"IlmnID\"])) == e.shape[0]\n",
    "e = e[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group', 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "e2 = pd.read_csv(\"../humanData/database/EPIC.hg38.txt\", sep=\"\\t\", names=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\"])\n",
    "m = pd.merge(e, e2, left_on=\"Name\", right_on=\"Probe_ID\")\n",
    "assert m.shape[0] == e2.shape[0]\n",
    "# m = m[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"UCSC_RefGene_Name\", \"UCSC_RefGene_Group\", 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "# m[\"Start_hg38\"] = m[\"Start_hg38\"].astype(int)\n",
    "# m[\"End_hg38\"] = m[\"End_hg38\"].astype(int)\n",
    "# m[m[\"Start_hg38\"] != m[\"Probe_Start\"]]\n",
    "# m[m[\"End_hg38\"] != m[\"Probe_End\"]]\n",
    "m = m[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"UCSC_RefGene_Name\", \"UCSC_RefGene_Group\"]]\n",
    "m.to_csv(\"../humanData/EPIC_manifest_cleaned.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epic_hm450_probe = pd.read_csv(\"../control/humanData/EPIC_HM450.clean.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"probeId\"])\n",
    "epic_hm450_probe = epic_hm450_probe[epic_hm450_probe[\"probeId\"].isin(corsiv_probe_list)]\n",
    "df = epic_hm450_probe[epic_hm450_probe.duplicated(subset=\"probeId\", keep=False)]\n",
    "df.sort_values(by=\"probeId\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genic feature\n",
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "ref = pd.concat([e, hm])\n",
    "ref.drop_duplicates(inplace=True)\n",
    "ref.loc[\n",
    "    (ref[\"UCSC_RefGene_Name\"].isna()) & (ref[\"UCSC_RefGene_Group\"].isna()),\n",
    "    \"UCSC_RefGene_Group\"\n",
    "] = \"Intergenic\"\n",
    "ref\n",
    "m = pd.merge(ref, corsiv_probe_df[[\"chr\", \"start\", \"end\", \"probeId\", \"corsiv_id\"]], left_on=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\"], right_on=[\"chr\", \"start\", \"end\", \"probeId\"])\n",
    "m = m[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"UCSC_RefGene_Name\", \"UCSC_RefGene_Group\", \"corsiv_id\"]]\n",
    "m.to_csv(\"../humanData/corsiv_manifest.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genic feature\n",
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "ref = pd.concat([e, hm])\n",
    "ref.drop_duplicates(inplace=True)\n",
    "ref.loc[\n",
    "    (ref[\"UCSC_RefGene_Name\"].isna()) & (ref[\"UCSC_RefGene_Group\"].isna()),\n",
    "    \"UCSC_RefGene_Group\"\n",
    "] = \"Intergenic\"\n",
    "ref\n",
    "m = pd.merge(ref, control_probe_df[[\"chr\", \"start\", \"end\", \"probeId\", \"id\"]], left_on=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\"], right_on=[\"chr\", \"start\", \"end\", \"probeId\"])\n",
    "m = m[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"UCSC_RefGene_Name\", \"UCSC_RefGene_Group\", \"id\"]]\n",
    "m.to_csv(\"../humanData/control_manifest.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../humanData/corsiv_manifest.csv\")\n",
    "df[\"Unique Gene\"] = df[\"UCSC_RefGene_Name\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "tmp = corsiv_probe_df[[\"chr\", \"corsiv_start\", \"corsiv_end\", \"corsiv_id\"]]\n",
    "tmp = tmp.drop_duplicates(\"corsiv_id\")\n",
    "df = pd.merge(df, tmp, on=\"corsiv_id\")\n",
    "df.rename(columns={\"chr\": \"CoRSIV_Chr\", \"corsiv_start\": \"CoRSIV_Start\", \"corsiv_end\": \"CoRSIV_End\", \"corsiv_id\": \"CoRSIV_ID\"}, inplace=True)\n",
    "df = df[[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"Unique Gene\", \"CoRSIV_Chr\", \"CoRSIV_Start\", \"CoRSIV_End\", \"CoRSIV_ID\"]]\n",
    "# Create boolean columns for EPIC and HM450\n",
    "e = pd.read_csv(\"../humanData/EPIC_manifest_cleaned.csv\")\n",
    "hm = pd.read_csv(\"../humanData/HM450_manifest_cleaned.csv\")\n",
    "e = e[e[\"Probe_ID\"].isin(corsiv_probe_list)]\n",
    "hm = hm[hm[\"Probe_ID\"].isin(corsiv_probe_list)]\n",
    "df['EPIC'] = df.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, e[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']].values)), axis=1)\n",
    "df['HM450'] = df.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, hm[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']].values)), axis=1)\n",
    "# sort by chr\n",
    "df = df.sort_values(by=['Probe_Start', 'Probe_End'])\n",
    "chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "\n",
    "# Sort the DataFrame using the custom chromosome order\n",
    "df = df.sort_values(\n",
    "    by=['Probe_Chr', 'Probe_Start'],\n",
    "    key=lambda x: x.map(chr_order) if x.name == 'Probe_Chr' else x\n",
    ")\n",
    "\n",
    "df.to_csv(\"../humanData/corsiv_probe_manifest_annotated.csv\", index=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../humanData/corsiv_probe_manifest_annotated.csv\")[[\"Probe_ID\", \"Unique Gene\"]]\n",
    "df2 = pd.read_excel(\"../gunasekara-2023.xlsx\", sheet_name=\"S18\")[[\"EPIC_probe_ID\", \"EPIC_gene\"]]\n",
    "df3 = pd.read_csv(\"/Users/antata/Downloads/EPIC.hg38.manifest.gencode.v36.tsv\", header=0, sep=\"\\t\")\n",
    "m = pd.merge(df1, df2, left_on=\"Probe_ID\", right_on=\"EPIC_probe_ID\")\n",
    "df3 = df3[df3[\"probeID\"].isin(m[\"EPIC_probe_ID\"])][[\"probeID\", \"genesUniq\"]]\n",
    "m = pd.merge(m, df3, left_on=\"Probe_ID\", right_on=\"probeID\")\n",
    "m.columns = [\"Probe_ID\", \"manifest\", \"EPIC_probe_ID\", \"S18\", \"probeID\", \"gencodev22\"]\n",
    "m = m[[\"Probe_ID\", \"manifest\", \"S18\", \"gencodev22\"]]\n",
    "m\n",
    "# m[\"S18\"] = m[\"S18\"].apply(lambda x: set(x.split(\";\")) if isinstance(x, str) else set([]))\n",
    "# m[\"gencodev22\"] = m[\"gencodev22\"].apply(lambda x: set(x.split(\";\")) if isinstance(x, str) else set([]))\n",
    "# m[m[\"S18\"] != m[\"gencodev22\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/antata/Downloads/EPIC.hg38.manifest.gencode.v22.tsv\", header=0, sep=\"\\t\")\n",
    "df[df[\"probeID\"].isin(m[\"EPIC_probe_ID\"])][[\"probeID\", \"genesUniq\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../humanData/corsiv_manifest.csv\")\n",
    "\n",
    "def parse_gene_group(row):\n",
    "    if row[\"UCSC_RefGene_Group\"] == \"Intergenic\":\n",
    "        return pd.Series([set([(\"_\", \"Intergenic\")]), set([(\"Intergenic\")])])\n",
    "    names = row[\"UCSC_RefGene_Name\"].split(\";\")\n",
    "    groups = row[\"UCSC_RefGene_Group\"].split(\";\")\n",
    "    gene_groups = set(zip(names, groups))\n",
    "    group_set = set(groups)\n",
    "    return pd.Series([gene_groups, group_set])\n",
    "\n",
    "def cleanup(row):\n",
    "    if len(row) > 1:\n",
    "        row.discard(\"Intergenic\")\n",
    "    return row\n",
    "\n",
    "df[[\"gene_groups\", \"groups\"]] = df.apply(parse_gene_group, axis=1)\n",
    "df = df[[\"corsiv_id\", \"Probe_ID\", \"gene_groups\", \"groups\"]]\n",
    "all_corsiv_df = df.groupby('corsiv_id')['groups'].apply(lambda x: set().union(*x)).reset_index()\n",
    "all_corsiv_df[\"groups\"] = all_corsiv_df[\"groups\"].apply(cleanup)\n",
    "illumina_covered_corsiv = all_corsiv_df.shape[0]\n",
    "all_corsiv_tally = {}\n",
    "for row in all_corsiv_df['groups']:\n",
    "    for group in row:\n",
    "        all_corsiv_tally[group] = all_corsiv_tally.get(group, 0) + 1\n",
    "if \"ExonBnd\" in all_corsiv_tally:\n",
    "    del all_corsiv_tally[\"ExonBnd\"]\n",
    "\n",
    "def tally_count(category, paper_threshold=3):\n",
    "    c = read_in_probes(category)\n",
    "    c = {k:v for k, v in c.items() if v >= paper_threshold}\n",
    "    cat_df = df[df[\"Probe_ID\"].isin(c)]\n",
    "    cat_df = cat_df.groupby('corsiv_id')['groups'].apply(lambda x: set().union(*x)).reset_index()\n",
    "    cat_df[\"groups\"] = cat_df[\"groups\"].apply(cleanup)\n",
    "    target_corsiv_tally = {}\n",
    "    for row in cat_df['groups']:\n",
    "        for group in row:\n",
    "            target_corsiv_tally[group] = target_corsiv_tally.get(group, 0) + 1\n",
    "    if \"ExonBnd\" in target_corsiv_tally:\n",
    "        del target_corsiv_tally[\"ExonBnd\"]\n",
    "    return target_corsiv_tally, cat_df.shape[0]\n",
    "\n",
    "def plot_gene_hist(cat, all, specific, count, output_path=None):\n",
    "    keys = sorted(all.keys())\n",
    "    s = [specific.get(key,0) for key in keys]\n",
    "    a = [all[key] for key in keys]\n",
    "    s_total = sum(s)\n",
    "    all_total = sum(a)\n",
    "    s_pct = [value / s_total * 100 for value in s]\n",
    "    a_pct = [value / all_total * 100 for value in a]\n",
    "\n",
    "    # Plotting\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(keys))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Bar chart for CORSIV tally\n",
    "    plt.bar(index, a_pct, bar_width, color='#55a868', label=f'All CoRSIVs ({illumina_covered_corsiv})')\n",
    "    plt.bar(index+bar_width, s_pct, bar_width, color='#4c72b0', label=f'{cat.capitalize()} CoRSIVs ({count})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Gene Region')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.title(f'All CoRSIVs vs CoRSIVs Showed up in {cat.capitalize()} Papers')\n",
    "\n",
    "    # Add xticks and legend\n",
    "    plt.xticks(index + bar_width / 2, keys)\n",
    "    plt.legend()\n",
    "    if output_path == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(output_path, format=\"jpeg\")\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in category_names:\n",
    "    d, count = tally_count(name)\n",
    "    output_path = f\"/Users/antata/Desktop/text-mining-figures/final/gene_hist/{name}_histograms.jpeg\"\n",
    "    plot_gene_hist(name, all_corsiv_tally, d, count, None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corsiv_probe_df[[\"probeId\", \"corsiv_id\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
